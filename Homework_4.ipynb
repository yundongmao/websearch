{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Language Modelling in Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Student Name:Mao Yundong\n",
    "\n",
    "Student ID:882542\n",
    "\n",
    "Python version used:2.7.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Due date</b>: 11pm, Wednesday May 2nd\n",
    "\n",
    "<b>Submission method</b>: see LMS\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day\n",
    "\n",
    "<b>Marks</b>: 5% of mark for class\n",
    "\n",
    "<b>Overview</b>: In this homework, you'll be creating an 'artificial intelligence' player for the classic Hangman word guessing game. You will need to implement several different automatic strategies based on character level language models, ranging from unigram approaches to higher over n-gram models. Your objective is to create an automatic player which makes the fewest mistakes.\n",
    "\n",
    "<b>Materials</b>: See the main class LMS page for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn, and Gensim. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks.  \n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Extra credit</b>: Each homework has a task which is optional with respect to getting full marks on the assignment, but that can be used to offset any points lost on this or any other homework assignment (but not the final project or the exam). We recommend you skip over this step on your first pass, and come back if you have time: the amount of effort required to receive full marks (1 point) on an extra credit question will be substantially more than earning the same amount of credit on other parts of the homework.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via LMS. Minor changes and clarifications will be announced in the forum on LMS, we recommend you check the forum regularly.\n",
    "\n",
    "<b>Academic Misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hangman Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n",
    "\n",
    "Here's a simple version of the game, and a method allowing interactive play. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowing better python 2 & python 3 compatibility \n",
    "# from __future__ import print_function \n",
    "\n",
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print \"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word)\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print \"You have\", (max_mistakes-mistakes), \"attempts remaining.\"\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print 'Guess is', guess\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print 'Already guessed this before.'\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print 'Good guess:', ' '.join(mask)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print 'Sorry, try again.'\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print 'Congratulations, you won.'\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print 'Out of guesses. The word was', secret_word\n",
    "    return mistakes\n",
    "\n",
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    simple function for manual play\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return raw_input().lower().strip() # python 3\n",
    "    except NameError:\n",
    "        return input().lower().strip() # python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play the game interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ length 8\n",
      "You have 8 attempts remaining.\n",
      "w\n",
      "Guess is w\n",
      "Good guess: w _ _ _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "a\n",
      "Guess is a\n",
      "Good guess: w _ a _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "e\n",
      "Guess is e\n",
      "Good guess: w _ a _ e _ e _\n",
      "You have 8 attempts remaining.\n",
      "r\n",
      "Guess is r\n",
      "Good guess: w _ a _ e _ e r\n",
      "You have 8 attempts remaining.\n",
      "h\n",
      "Guess is h\n",
      "Good guess: w h a _ e _ e r\n",
      "You have 8 attempts remaining.\n",
      "v\n",
      "Guess is v\n",
      "Good guess: w h a _ e v e r\n",
      "You have 8 attempts remaining.\n",
      "t\n",
      "Guess is t\n",
      "Good guess: w h a t e v e r\n",
      "Congratulations, you won.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Instructions</b>: We will be using the words occurring in the *Brown* corpus for *training* an artificial intelligence guessing algorithm, and for *evaluating* the quality of the method. Note that we are intentionally making the hangman game hard, as the AI will need to cope with test words that it has not seen before, hence it will need to learn generalisable patterns of characters to make reasonable predictions.\n",
    "\n",
    "Your first task is to compute the unique word types occurring in the *Brown* corpus, using `nltk.corpus.Brown`, selecting only words that are entirely comprised of alphabetic characters, and lowercasing the words. Finally, randomly shuffle (`numpy.random.shuffle`) this collection of word types, and split them into disjoint training and testing sets. The test set should contain 1000 word types, and the rest should be in the training set. Your code should print the sizes of the training and test sets.\n",
    "\n",
    "Feel free to test your own Hangman performance using `hangman(numpy.random.choice(test_set), human, 8, True)`. It is surprisingly difficult (and addictive)!\n",
    "\n",
    "(0.5 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39234\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "typeList = list(set([word.lower() for para in brown.paras() for sent in para for word in sent if word.isalpha()]))\n",
    "np.random.shuffle(typeList)\n",
    "typeTrainList = typeList[:len(typeList)-1000]\n",
    "typeTestList = typeList[len(typeList)-1000:]\n",
    "print len(typeTrainList)\n",
    "print len(typeTestList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instructions</b>: To set a baseline, your first *AI* attempt will be a trivial random method. For this you should implement a guessing method, similar to the `human` method above, i.e., using the same input arguments and returning a character. Your method should randomly choose a character from the range `'a'...'z'` after excluding the characters that have already been guessed in the current game (all subsequent AI approaches should also exclude previous guesses). You might want to use `numpy.random.choice` for this purpose.\n",
    "\n",
    "To measure the performance of this (and later) techiques, implement a method that measures the average number of mistakes made by this technique over all the words in the `test_set`. You will want to turn off the printouts for this, using the `verbose=False` option, and increase the cap on the game length to `max_mistakes=26`. Print the average number of mistakes for the random AI, which will become a baseline for the following steps.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.841\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "alphaSet = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "def baselineGusser(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    return list(temps)[random.randint(0,len(temps)-1)]\n",
    "total = 0\n",
    "for secretWord in typeTestList:\n",
    "    total+= hangman(secretWord, baselineGusser, 26, False,alphaSet=alphaSet)\n",
    "print total/float(len(typeTestList))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** As your first real AI, you should train a *unigram* model over the training set.  This requires you to find the frequencies of characters over all training words. Using this model, you should write a guess function that returns the character with the highest probability, after aggregating (summing) the probability of each blank character in the secret word. Print the average number of mistakes the unigram method makes over the test set. Remember to exclude already guessed characters, and use the same evaluation method as above, so the results are comparable. (Hint: it should be much lower than for random).\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.253\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "charProDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    for c in trainWord:\n",
    "        charProDic[c]+=1\n",
    "\n",
    "alphaSet = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "def unigramGusser(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    charProDic= kwargs[\"charProDic\"]\n",
    "    return max([(charProDic[c],c) for c in temps])[1]\n",
    "total = 0\n",
    "for secretWord in typeTestList:\n",
    "    total+= hangman(secretWord, unigramGusser, 26, False,alphaSet=alphaSet,charProDic=charProDic)\n",
    "print total/float(len(typeTestList))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** The length of the secret word is an important clue that we might exploit. Different length words tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. Your job now is to incorporate this idea by conditioning the unigram model on the length of the secret word, i.e., having *different* unigram models for each length of word. You will need to be a little careful at test time, to be robust to the (unlikely) situation that you encounter a word length that you didn't see in training. Create another AI guessing function using this new model, and print its test performance.   \n",
    "\n",
    "(0.5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.193\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "charLenProDic = {}\n",
    "# charProDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    charLenProDic.setdefault(len(trainWord),collections.defaultdict(int))\n",
    "    for c in trainWord:\n",
    "        charLenProDic[len(trainWord)][c]+=1\n",
    "\n",
    "alphaSet = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "def unigramLengthGusser(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    charLenProDic= kwargs[\"charLenProDic\"]\n",
    "    length = kwargs[\"length\"]\n",
    "    return max([(charLenProDic[length][c],c) for c in temps])[1]\n",
    "total = 0\n",
    "for secretWord in typeTestList:\n",
    "    total+= hangman(secretWord, unigramLengthGusser, 26, False,alphaSet=alphaSet,charLenProDic=charLenProDic,length=len(secretWord))\n",
    "print total/float(len(typeTestList))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Now for the main challenge, using a *ngram* language model over characters. The order of characters is obviously important, yet this wasn't incorporated in any of the above models. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly the distribution over characters that start or end a word are highly biased (e.g., toward common prefixes and suffixes, like *un-*, *-ed* and *-ly*).\n",
    "\n",
    "Your job is to develop a *ngram* language model over characters, train this over the training words (being careful to handle the start of each word properly, e.g., by padding with sentinel symbols.) You should use linear interpolation to smooth between the higher order and lower order models, and you will have to decide how to weight each component. \n",
    "\n",
    "Your guessing AI algorithm should apply your language model to each blank position in the secret word by using as much of the left context as is known. E.g., in `_ e c _ e _ _` we know the full left context for the first blank (context=start of word), we have a context of two characters for the second blank (context=ec), one character for the second last blank (context=e), and no known context for the last one. If we were using a *n=3* order model, we would be able to apply it to the first and second blanks, but would only be able to use the bigram or unigram distributions for the subsequent blanks. As with the unigram model, you should sum over the probability distributions for each blank to find the expected count for each character type, then select the  character with the highest expected count.\n",
    "\n",
    "Implement the ngram method for *n=3,4* and *5* and evaluate each of these three models over the test set. Do you see any improvement over the unigram methods above?\n",
    "\n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 gram :8.346\n",
      "4 gram :8.008\n",
      "5 gram :7.803\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "        \n",
    "    \n",
    "uniGramCountDic = collections.defaultdict(int)\n",
    "total = 0\n",
    "for trainWord in typeTrainList:\n",
    "    total +=(len(trainWord)+2)\n",
    "    tempword = \"*\"+trainWord+\"*\"\n",
    "    for i in range(len(tempword)-1):\n",
    "        uniGramCountDic[tempword[i]]+=1\n",
    "uniGramProDic = collections.defaultdict(int)\n",
    "uniGramCondProDic = collections.defaultdict(int)\n",
    "for c in uniGramCountDic:\n",
    "    uniGramProDic[c] = uniGramCountDic[c]/float(total)\n",
    "    uniGramCondProDic[c] = uniGramProDic[c]\n",
    "    \n",
    "\n",
    "\n",
    "twoGramCountDic = collections.defaultdict(int)\n",
    "total = 0\n",
    "for trainWord in typeTrainList:\n",
    "    total += (len(tempword)+1)\n",
    "    tempword = \"*\"+trainWord+\"*\"\n",
    "    for i in range(len(tempword)-1):\n",
    "        twoGramCountDic[tempword[i:i+2]]+=1\n",
    "twoGramProDic = collections.defaultdict(int)\n",
    "twoGramCondProDic = collections.defaultdict(int)\n",
    "for c in twoGramCountDic:\n",
    "    twoGramProDic[c] = twoGramCountDic[c]/float(total)\n",
    "    twoGramCondProDic[c] = twoGramProDic[c]/uniGramProDic[c[0]]\n",
    "# print twoGramProDic\n",
    "    \n",
    "total = 0\n",
    "threeGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    total += len(trainWord)\n",
    "    tempword = \"**\"+trainWord+\"**\"\n",
    "    for i in range(len(tempword)-2):\n",
    "        threeGramCountDic[tempword[i:i+3]]+=1\n",
    "threeGramProDic = collections.defaultdict(int)\n",
    "threeGramCondProDic = collections.defaultdict(int)\n",
    "for c in threeGramCountDic:\n",
    "    if c[0:2] == \"**\":\n",
    "        continue\n",
    "    threeGramProDic[c] = threeGramCountDic[c]/float(total)\n",
    "    threeGramCondProDic[c] = threeGramProDic[c]/twoGramProDic[c[0:2]]\n",
    "        \n",
    "total = 0\n",
    "fourGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    total += (len(trainWord)-1)\n",
    "    tempword = \"***\"+trainWord+\"***\"\n",
    "    for i in range(len(tempword)-3):\n",
    "        fourGramCountDic[tempword[i:i+4]]+=1\n",
    "fourGramProDic = collections.defaultdict(int)\n",
    "fourGramCondProDic = collections.defaultdict(int)\n",
    "for c in fourGramCountDic:\n",
    "    if c[0:2] == \"**\":\n",
    "        continue\n",
    "    fourGramProDic[c] = fourGramCountDic[c]/float(total)\n",
    "    fourGramCondProDic[c] = fourGramProDic[c]/threeGramProDic[c[0:3]]\n",
    "        \n",
    "total = 0\n",
    "fiveGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    total += (len(trainWord)-2)\n",
    "    tempword = \"****\"+trainWord+\"****\"\n",
    "    for i in range(len(tempword)-4):\n",
    "        fiveGramCountDic[tempword[i:i+5]]+=1\n",
    "fiveGramProDic = collections.defaultdict(int)\n",
    "fiveGramCondProDic = collections.defaultdict(int)\n",
    "for c in fiveGramCountDic:\n",
    "    if c[0:2] == \"**\":\n",
    "        continue\n",
    "    fiveGramProDic[c] = fiveGramCountDic[c]/float(total)\n",
    "    fiveGramCondProDic[c] = fiveGramProDic[c]/fourGramProDic[c[0:4]]\n",
    "proDic = {}\n",
    "\n",
    "\n",
    "proDic[\"uniGramCondProDic\"] = uniGramCondProDic\n",
    "proDic[\"twoGramCondProDic\"] = twoGramCondProDic\n",
    "proDic[\"threeGramCondProDic\"] = threeGramCondProDic\n",
    "proDic[\"fourGramCondProDic\"] = fourGramCondProDic\n",
    "proDic[\"fiveGramCondProDic\"] = fiveGramCondProDic\n",
    "\n",
    "nGramCondProDicList = []\n",
    "nGramCondProDicList.append(uniGramCondProDic)\n",
    "nGramCondProDicList.append(twoGramCondProDic)\n",
    "nGramCondProDicList.append(threeGramCondProDic)\n",
    "nGramCondProDicList.append(fourGramCondProDic)\n",
    "nGramCondProDicList.append(fiveGramCondProDic)\n",
    "\n",
    "alphaSet = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "\n",
    "\n",
    "def ngramGusserMix2(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    n = kwargs[\"n\"]\n",
    "    nGramCondProDicList = kwargs[\"nGramCondProDicList\"]\n",
    "    tempmask = \"*\"+\"\".join(mask)+\"*\"\n",
    "    m = collections.defaultdict(int)\n",
    "    precount = 0\n",
    "    for i in range(len(tempmask)-1):\n",
    "        if tempmask[i] == \"_\":\n",
    "            for c in temps:\n",
    "                m[c]+=nGramCondProDicList[precount][tempmask[i-precount:i]+c]\n",
    "            precount = 0\n",
    "        else:\n",
    "            precount+=1\n",
    "            precount = min(precount,n-1)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "#add smoothing\n",
    "def ngramGusserMix3(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    n = kwargs[\"n\"]\n",
    "    mylambda =  kwargs[\"mylambda\"]\n",
    "    nGramCondProDicList = kwargs[\"nGramCondProDicList\"]\n",
    "    tempmask = \"*\"+\"\".join(mask)+\"*\"\n",
    "    m = collections.defaultdict(int)\n",
    "    precount = 0\n",
    "    for i in range(len(tempmask)-1):\n",
    "        if tempmask[i] == \"_\":\n",
    "            for c in temps:\n",
    "                temp_lambda = 1\n",
    "                for k in range(precount,-1,-1):\n",
    "                    temp = nGramCondProDicList[k][tempmask[i-k:i]+c]\n",
    "                    if temp > 0:\n",
    "                        m[c]+= temp*mylambda*temp_lambda\n",
    "                        break\n",
    "                    temp_lambda = temp_lambda*(1-mylambda)\n",
    "            precount = 0\n",
    "        else:\n",
    "            precount+=1\n",
    "            precount = min(precount,n-1)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "\n",
    "# typeTestList3 = typeTestList[:50]\n",
    "\n",
    "for n in range(3,6):\n",
    "    total = 0\n",
    "    for i,secretWord in enumerate(typeTestList):\n",
    "        temp = hangman(secretWord, ngramGusserMix3, 26, False,alphaSet=alphaSet,nGramCondProDicList=nGramCondProDicList,n=n,mylambda = 0.5)\n",
    "        total+=temp\n",
    "    print str(n)+\" gram :\" +str(total/float(len(typeTestList)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Improving the AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** To get the extra credit, you should try to develop a more effective AI for hangman. Feel free to engage your creativity here! Possibilities include better conditioning on the length of the word and the parts that are known, fancier smoothing methods, using backwards ngram models, or a fancier inference algorithm like forward-back using a HMM. Ensure you report the test performance of your method.\n",
    "\n",
    "You will be marked based on the ambition of your approach and on its accuracy. If you have tried some truly spectacular method but it didn't really work, then please include your implementation and an explanation, which will still attract marks for ambition.\n",
    "\n",
    "(1 bonus mark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because my method is slow, So I choose just 50 testcase to check\n",
      "\n",
      "origin version ------------------\n",
      "3 gram :6.8\n",
      "4 gram :6.4\n",
      "5 gram :6.6\n",
      "\n",
      "we know the origin version _b_ _ we can just guess the second blank from b, but actually, the first and the third blank should also related to the character \"b\"\n",
      "then my improvement try to use all the information between not only the left char but also the right char.\n",
      "And my improvement also consider the character's effect on the unadjacented blank\n",
      "\n",
      "\n",
      "improve version -------------------\n",
      "0 6 spate\n",
      "1 8 schoolroom\n",
      "2 9 archeological\n",
      "3 9 intensifiers\n",
      "4 14 magwitch\n",
      "5 2 anson\n",
      "6 4 chattels\n",
      "7 4 rarity\n",
      "8 13 overlooked\n",
      "9 4 reproducible\n",
      "2gram : 7.3\n",
      "------------------------------------\n",
      "\n",
      "0 6 spate\n",
      "1 8 schoolroom\n",
      "2 4 archeological\n",
      "3 3 intensifiers\n",
      "4 12 magwitch\n",
      "5 1 anson\n",
      "6 4 chattels\n",
      "7 4 rarity\n",
      "8 7 overlooked\n",
      "9 4 reproducible\n",
      "3gram : 5.3\n",
      "------------------------------------\n",
      "\n",
      "0 4 spate\n",
      "1 8 schoolroom\n",
      "2 4 archeological\n",
      "3 1 intensifiers\n",
      "4 8 magwitch\n",
      "5 1 anson\n",
      "6 4 chattels\n",
      "7 4 rarity\n",
      "8 5 overlooked\n",
      "9 4 reproducible\n",
      "4gram : 4.3\n",
      "------------------------------------\n",
      "\n",
      "0 2 spate\n",
      "1 8 schoolroom\n",
      "2 4 archeological\n",
      "3 1 intensifiers\n",
      "4 8 magwitch\n",
      "5 2 anson\n",
      "6 3 chattels\n",
      "7 4 rarity\n",
      "8 5 overlooked\n",
      "9 4 reproducible\n",
      "5gram : 4.1\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "        \n",
    "twoGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"*\"+trainWord+\"*\"\n",
    "    for i in range(len(tempword)-1):\n",
    "        twoGramCountDic[tempword[i:i+2]]+=1\n",
    "\n",
    "threeGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"**\"+trainWord+\"**\"\n",
    "    for i in range(len(tempword)-2):\n",
    "        threeGramCountDic[tempword[i:i+3]]+=1\n",
    "\n",
    "        \n",
    "fourGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"***\"+trainWord+\"***\"\n",
    "    for i in range(len(tempword)-3):\n",
    "        fourGramCountDic[tempword[i:i+4]]+=1\n",
    "        \n",
    "fiveGramCountDic = collections.defaultdict(int)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"****\"+trainWord+\"****\"\n",
    "    for i in range(len(tempword)-4):\n",
    "        fiveGramCountDic[tempword[i:i+5]]+=1\n",
    "\n",
    "# print len(twoGramCountDic)\n",
    "# print len(threeGramCountDic)\n",
    "# print len(fourGramCountDic)\n",
    "# print len(fiveGramCountDic)\n",
    "\n",
    "\n",
    "twoGramCountTrie = collections.defaultdict(dict)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"*\"+trainWord+\"*\"\n",
    "    for i in range(len(tempword)-1):\n",
    "        temptrie = twoGramCountTrie[tempword[i]]\n",
    "        temptrie[tempword[i+1]] = temptrie.get(tempword[i+1],0) +1\n",
    "\n",
    "threeGramCountTrie = collections.defaultdict(dict)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"**\"+trainWord+\"**\"\n",
    "    for i in range(len(tempword)-2):\n",
    "        temptrie = threeGramCountTrie[tempword[i]]\n",
    "        temptrie[tempword[i+1]] = temptrie.get(tempword[i+1],{})\n",
    "        temptrie = temptrie[tempword[i+1]]\n",
    "        temptrie[tempword[i+2]] = temptrie.get(tempword[i+2],0)+1\n",
    "        \n",
    "\n",
    "fourGramCountTrie = collections.defaultdict(dict)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"***\"+trainWord+\"***\"\n",
    "    for i in range(len(tempword)-3):\n",
    "        temptrie = fourGramCountTrie[tempword[i]]\n",
    "        temptrie[tempword[i+1]] = temptrie.get(tempword[i+1],{})\n",
    "        temptrie = temptrie[tempword[i+1]]\n",
    "        temptrie[tempword[i+2]] = temptrie.get(tempword[i+2],{})\n",
    "        temptrie = temptrie[tempword[i+2]]\n",
    "        temptrie[tempword[i+3]] = temptrie.get(tempword[i+3],0)+1\n",
    "             \n",
    "        \n",
    "fiveGramCountTrie = collections.defaultdict(dict)\n",
    "for trainWord in typeTrainList:\n",
    "    tempword = \"****\"+trainWord+\"****\"\n",
    "    for i in range(len(tempword)-4):\n",
    "        temptrie = fiveGramCountTrie[tempword[i]]\n",
    "        temptrie[tempword[i+1]] = temptrie.get(tempword[i+1],{})\n",
    "        temptrie = temptrie[tempword[i+1]]\n",
    "        temptrie[tempword[i+2]] = temptrie.get(tempword[i+2],{})\n",
    "        temptrie = temptrie[tempword[i+2]]\n",
    "        temptrie[tempword[i+3]] = temptrie.get(tempword[i+3],{})\n",
    "        temptrie = temptrie[tempword[i+3]] \n",
    "        temptrie[tempword[i+4]] = temptrie.get(tempword[i+4],0)+1\n",
    "        \n",
    "        \n",
    "        \n",
    "alphaSet = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "def compareTwo(word1,word2):\n",
    "    for i in range(len(word1)):\n",
    "        if word2[i] != word1[i] and word2[i]!=\"_\":\n",
    "            return False;\n",
    "    return True;\n",
    "            \n",
    "        \n",
    "def twogramGusser(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    twoGramCountDic= kwargs[\"twoGramCountDic\"]\n",
    "    tempmask = \"*\"+\"\".join(mask)+\"*\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(1,len(tempmask)):\n",
    "        temp2gram = tempmask[i-1:i+1]\n",
    "#         print temp2gram\n",
    "        for target in twoGramCountDic.keys():\n",
    "            if compareTwo(target,temp2gram):\n",
    "                m[target[0]]+= twoGramCountDic[target]\n",
    "                m[target[1]]+= twoGramCountDic[target]\n",
    "#     print m\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "\n",
    "\n",
    "def twogramGusser2(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    twoGramCountTrie= kwargs[\"twoGramCountTrie\"]\n",
    "    tempmask = \"*\"+\"\".join(mask)+\"*\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(len(tempmask)-1):\n",
    "        if tempmask[i] == \"_\":\n",
    "            for key1 in twoGramCountTrie.keys():\n",
    "                temptrie = twoGramCountTrie[key1]\n",
    "                if tempmask[i+1] == \"_\":\n",
    "                    for key2 in temptrie.keys():\n",
    "                        m[key1]+=temptrie[key2]\n",
    "                        m[key2]+=temptrie[key2]\n",
    "                else:\n",
    "                    key2 = tempmask[i+1]\n",
    "                    m[key1]+= temptrie.get(key2,0)\n",
    "                    m[key2]+= temptrie.get(key2,0)\n",
    "        else:\n",
    "            key1 = tempmask[i]\n",
    "            temptrie = twoGramCountTrie.get(key1,{})\n",
    "            if tempmask[i+1] == \"_\":\n",
    "                for key2 in temptrie.keys():\n",
    "                    m[key1]+=temptrie[key2]\n",
    "                    m[key2]+=temptrie[key2]\n",
    "            else:\n",
    "                key2 = tempmask[i+1]\n",
    "                m[key1]+= temptrie.get(key2,0)\n",
    "                m[key2] += temptrie.get(key2,0)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "def handle(tempmask,index,trie,m,keyList,remainLevel):\n",
    "    if remainLevel == 1:\n",
    "        if tempmask[index] == \"_\":\n",
    "            for keyt in trie.keys():\n",
    "                for key in keyList:\n",
    "                    m[key]+=trie[keyt]\n",
    "                m[keyt] += trie[keyt]\n",
    "        else:\n",
    "            keyt = tempmask[index]\n",
    "            for key in keyList:\n",
    "                m[key]+=trie.get(keyt,0)\n",
    "            m[keyt]+=trie.get(keyt,0)\n",
    "    else:\n",
    "        if tempmask[index] == \"_\":\n",
    "            for key2 in trie.keys():\n",
    "                temptrie = trie[key2]\n",
    "                handle(tempmask,index+1,temptrie,m,keyList+[key2],remainLevel-1)\n",
    "        else:\n",
    "            key2 = tempmask[index]\n",
    "            temptrie = trie.get(key2,{})\n",
    "            handle(tempmask,index+1,temptrie,m,keyList+[key2],remainLevel-1)\n",
    "            \n",
    "def twogramGusser3(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    twoGramCountTrie= kwargs[\"twoGramCountTrie\"]\n",
    "    tempmask = \"*\"+\"\".join(mask)+\"*\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(len(tempmask)-1):\n",
    "        handle(tempmask,i,twoGramCountTrie,m,[],2)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "def threegramGusser3(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    threeGramCountTrie= kwargs[\"threeGramCountTrie\"]\n",
    "    tempmask = \"**\"+\"\".join(mask)+\"**\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(len(tempmask)-2):\n",
    "        handle(tempmask,i,threeGramCountTrie,m,[],3)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "def fourgramGusser3(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    fourGramCountTrie= kwargs[\"fourGramCountTrie\"]\n",
    "    tempmask = \"***\"+\"\".join(mask)+\"***\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(len(tempmask)-3):\n",
    "        handle(tempmask,i,fourGramCountTrie,m,[],4)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "def fivegramGusser3(mask, guessed, **kwargs):\n",
    "    temps = kwargs[\"alphaSet\"] - guessed\n",
    "    fiveGramCountTrie= kwargs[\"fiveGramCountTrie\"]\n",
    "    tempmask = \"****\"+\"\".join(mask)+\"****\"\n",
    "    m = collections.defaultdict(int)\n",
    "    for i in range(len(tempmask)-4):\n",
    "        handle(tempmask,i,fiveGramCountTrie,m,[],5)\n",
    "    return max([(m[c],c) for c in temps])[1]\n",
    "np.random.shuffle(typeTestList)\n",
    "typeTestList2 = typeTestList[0:10]\n",
    "\n",
    "print \"because my method is slow, So I choose just 50 testcase to check\"\n",
    "print \"\"\n",
    "print \"origin version ------------------\"\n",
    "for n in range(3,6):\n",
    "    total = 0\n",
    "    for i,secretWord in enumerate(typeTestList2):\n",
    "        temp = hangman(secretWord, ngramGusserMix3, 26, False,alphaSet=alphaSet,nGramCondProDicList=nGramCondProDicList,n=n,mylambda = 0.5)\n",
    "        total+=temp\n",
    "    print str(n)+\" gram :\" +str(total/float(len(typeTestList2)))\n",
    "print \"\"\n",
    "print \"we know the origin version _b_ _ we can just guess the second blank from b, but actually, the first and the third blank should also related to the character \\\"b\\\"\"\n",
    "print \"then my improvement try to use all the information between not only the left char but also the right char.\"\n",
    "print \"And my improvement also consider the character's effect on the unadjacented blank\"\n",
    "print \"\"\n",
    "print \"\"\n",
    "print \"improve version -------------------\"\n",
    "total = 0\n",
    "for i,secretWord in enumerate(typeTestList2):\n",
    "    temp = hangman(secretWord, twogramGusser3, 26, False,alphaSet=alphaSet,twoGramCountTrie=twoGramCountTrie)\n",
    "    print i,temp,secretWord\n",
    "    total+=temp\n",
    "print \"2gram : \" +str(total/float(len(typeTestList2)))\n",
    "print  \"------------------------------------\"\n",
    "print \"\"\n",
    "\n",
    "total = 0\n",
    "for i,secretWord in enumerate(typeTestList2):\n",
    "    temp = hangman(secretWord, threegramGusser3, 26, False,alphaSet=alphaSet,threeGramCountTrie=threeGramCountTrie)\n",
    "    print i,temp,secretWord\n",
    "    total+=temp\n",
    "print \"3gram : \" +str(total/float(len(typeTestList2)))\n",
    "print  \"------------------------------------\"\n",
    "print \"\"\n",
    "\n",
    "total = 0\n",
    "for i,secretWord in enumerate(typeTestList2):\n",
    "    temp = hangman(secretWord, fourgramGusser3, 26, False,alphaSet=alphaSet,fourGramCountTrie=fourGramCountTrie)\n",
    "    print i,temp,secretWord\n",
    "    total+=temp\n",
    "print \"4gram : \" +str(total/float(len(typeTestList2)))\n",
    "print  \"------------------------------------\"\n",
    "print \"\"\n",
    "\n",
    "total = 0\n",
    "for i,secretWord in enumerate(typeTestList2):\n",
    "    temp = hangman(secretWord, fivegramGusser3, 26, False,alphaSet=alphaSet,fiveGramCountTrie=fiveGramCountTrie)\n",
    "    print i,temp,secretWord\n",
    "    total+=temp\n",
    "print \"5gram : \" +str(total/float(len(typeTestList2)))\n",
    "print  \"------------------------------------\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def threegramGusser(mask, guessed, **kwargs):\n",
    "#     temps = kwargs[\"alphaSet\"] - guessed\n",
    "#     threeGramCountDic= kwargs[\"threeGramCountDic\"]\n",
    "#     tempmask = \"**\"+\"\".join(mask)+\"**\"\n",
    "#     m = collections.defaultdict(int)\n",
    "#     for i in range(len(tempmask)-2):\n",
    "#         temp3gram = tempmask[i:i+3]\n",
    "#         for target in threeGramCountDic.keys():\n",
    "#             if compareTwo(target,temp3gram):\n",
    "#                 m[target[0]]+= threeGramCountDic[target]\n",
    "#                 m[target[1]]+= threeGramCountDic[target]\n",
    "#                 m[target[2]]+= threeGramCountDic[target]\n",
    "#     return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "# def fourgramGusser(mask, guessed, **kwargs):\n",
    "#     temps = kwargs[\"alphaSet\"] - guessed\n",
    "#     fourGramCountDic= kwargs[\"fourGramCountDic\"]\n",
    "#     tempmask = \"***\"+\"\".join(mask)+\"***\"\n",
    "#     m = collections.defaultdict(int)\n",
    "#     for i in range(len(tempmask)-3):\n",
    "#         temp4gram = tempmask[i:i+4]\n",
    "#         for target in fourGramCountDic.keys():\n",
    "#             if compareTwo(target,temp4gram):\n",
    "#                 m[target[0]]+= fourGramCountDic[target]\n",
    "#                 m[target[1]]+= fourGramCountDic[target]\n",
    "#                 m[target[2]]+= fourGramCountDic[target]\n",
    "#                 m[target[3]]+= fourGramCountDic[target]\n",
    "#     return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "# def fivegramGusser(mask, guessed, **kwargs):\n",
    "#     temps = kwargs[\"alphaSet\"] - guessed\n",
    "#     fiveGramCountDic= kwargs[\"fiveGramCountDic\"]\n",
    "#     tempmask = \"***\"+\"\".join(mask)+\"***\"\n",
    "#     m = collections.defaultdict(int)\n",
    "#     for i in range(len(tempmask)-4):\n",
    "#         temp5gram = tempmask[i:i+5]\n",
    "#         for target in fiveGramCountDic.keys():\n",
    "#             if compareTwo(target,temp5gram):\n",
    "#                 m[target[0]]+= fiveGramCountDic[target]\n",
    "#                 m[target[1]]+= fiveGramCountDic[target]\n",
    "#                 m[target[2]]+= fiveGramCountDic[target]\n",
    "#                 m[target[3]]+= fiveGramCountDic[target]\n",
    "#                 m[target[4]]+= fiveGramCountDic[target]\n",
    "#     return max([(m[c],c) for c in temps])[1]\n",
    "\n",
    "\n",
    "# total = 0\n",
    "# for i,secretWord in enumerate(typeTestList):\n",
    "#     temp = hangman(secretWord, threegramGusser, 26, False,alphaSet=alphaSet,threeGramCountDic=threeGramCountDic)\n",
    "# #     temp = hangman(secretWord, twogramGusser2, 26, False,alphaSet=alphaSet,twoGramCountTrie=twoGramCountTrie)\n",
    "#     total+=temp\n",
    "#     print i,temp,secretWord\n",
    "#     if i % 10==9:    \n",
    "# #         print i,temp\n",
    "#         break\n",
    "# # print total/float(len(typeTestList))\n",
    "# print \"3gram : \"+str(total/10.0)\n",
    "\n",
    "\n",
    "# # total = 0\n",
    "# # for i,secretWord in enumerate(typeTestList):\n",
    "# #     temp = hangman(secretWord, fourgramGusser, 26, False,alphaSet=alphaSet,fourGramCountDic=fourGramCountDic)\n",
    "# # #     temp = hangman(secretWord, twogramGusser2, 26, False,alphaSet=alphaSet,twoGramCountTrie=twoGramCountTrie)\n",
    "# #     total+=temp\n",
    "# #     if i % 10==9:    \n",
    "# #         print i,temp\n",
    "# #         break\n",
    "# # # print total/float(len(typeTestList))\n",
    "# # print \"4gram : \"+str(total/10.0)\n",
    "\n",
    "\n",
    "# # total = 0\n",
    "# # for i,secretWord in enumerate(typeTestList):\n",
    "# #     temp = hangman(secretWord, fivegramGusser, 26, False,alphaSet=alphaSet,fiveGramCountDic=fiveGramCountDic)\n",
    "# # #     temp = hangman(secretWord, twogramGusser2, 26, False,alphaSet=alphaSet,twoGramCountTrie=twoGramCountTrie)\n",
    "# #     total+=temp\n",
    "# #     print \"111111111111\"\n",
    "# #     if i % 10==9:    \n",
    "# #         print i,temp\n",
    "# #         break\n",
    "# # # print total/float(len(typeTestList))\n",
    "# # print \"5gram : \"+str(total/10.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print total/100.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
