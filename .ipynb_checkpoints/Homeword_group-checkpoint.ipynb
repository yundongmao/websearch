{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Student Name:Mao Yundong\n",
    "\n",
    "Student ID:882542\n",
    "\n",
    "Python version used:3.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "doc_dict = json.loads(a)\n",
    "# print (doc_dict[0])\n",
    "print(len(doc_dict[422][\"text\"]))\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdffds\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "import json\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print (\"asdffds\")\n",
    "def myLemmatize(lemmatizer,tWord):\n",
    "    temp = lemmatizer.lemmatize(tWord)\n",
    "    if len(temp) < len(tWord):\n",
    "        return temp\n",
    "    return lemmatizer.lemmatize(tWord,\"v\")\n",
    "# f = open(\"./assignment_group/project_files/testing.json\")\n",
    "# a = f.readline()\n",
    "# dict = json.loads(a)\n",
    "# print (len(dict))\n",
    "# print (dict[0])\n",
    "\n",
    "\n",
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "doc_dict = json.loads(a)\n",
    "# print (doc_dict[0])\n",
    "\n",
    "\n",
    "word_numbers = {}\n",
    "num_docs = []\n",
    "num_paras = [] \n",
    "para_doc = {}\n",
    "doc_para = {}\n",
    "wordnum_freq_doc = collections.defaultdict(list)\n",
    "wordnum_freq_para = collections.defaultdict(list)\n",
    "for i,doc in enumerate(doc_dict):\n",
    "    temp_doc = []\n",
    "    temp_doc_set = set()\n",
    "    doc_para[i] = [len(num_paras)]\n",
    "    for j,para in enumerate(doc[\"text\"]):\n",
    "        temp_para_set = set()\n",
    "        temp_para = []\n",
    "        words = re.split(\",|\\.| |\\?|!\",para)\n",
    "        for word in words:\n",
    "            if word.isalnum():\n",
    "                tempword = myLemmatize(lemmatizer,word.lower())\n",
    "                if tempword not in stopWords:\n",
    "                    wi = word_numbers.setdefault(tempword,len(word_numbers))\n",
    "                    temp_para.append(wi)\n",
    "                    temp_doc_set.add(wi)\n",
    "                    temp_para_set.add(wi)\n",
    "        para_doc[len(num_paras)] = (i,j)\n",
    "        num_paras.append(temp_para)\n",
    "        temp_doc.append(temp_para)\n",
    "        for wordnum in temp_para_set:\n",
    "            wordnum_freq_para[wordnum].append((i,j))\n",
    "    doc_para[i].append(len(num_paras))\n",
    "    for wordnum in temp_doc_set:\n",
    "        wordnum_freq_doc[wordnum].append(i)\n",
    "    if i% 50 == 0:\n",
    "        print (i)\n",
    "    num_docs.append(temp_doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave', ' In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself', ' The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave', ' It was eventually called the photon', '']\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# doct_para_sentence = [sent for doc in doc_dict for para in doc[\"text\"] for sent in re.split(\"\\.|\\?|\\!|;\",para)]\n",
    "doct_para_sentence = []\n",
    "doc_para_sentence_number = []\n",
    "for doc in doc_dict:\n",
    "    temppara = []\n",
    "    tempparas_number = []\n",
    "    for para in doc[\"text\"]:\n",
    "        sentences = re.split(\"\\.|\\?|\\!|;\",para)\n",
    "        temppara.append(sentences)\n",
    "        temp_sentences_number = []\n",
    "        for sentence in sentences:\n",
    "            temp_sentence_number = []\n",
    "            words = re.split(\",|\\.| |\\?|!\",sentence)\n",
    "            for word in words:\n",
    "                if word.isalnum():\n",
    "                    tempword = myLemmatize(lemmatizer,word.lower())\n",
    "                    if tempword not in stopWords:\n",
    "                        wi = word_numbers.setdefault(tempword,len(word_numbers))\n",
    "                        temp_para.append(wi)\n",
    "                        temp_doc_set.add(wi)\n",
    "                        temp_para_set.add(wi)\n",
    "                        temp_sentence_number.append(wi)\n",
    "            temp_sentences_number.append(temp_sentence_number)\n",
    "        tempparas_number.append(temp_sentences_number)\n",
    "            \n",
    "    doct_para_sentence.append(temppara)\n",
    "    doc_para_sentence_number.append(tempparas_number)\n",
    "    \n",
    "print(doct_para_sentence[0][0])\n",
    "print(doct_para_sentence[0][0][0])\n",
    "print(doc_para_sentence_number[0][23][5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[618, 619, 159, 508, 588, 581, 620, 621, 428, 622, 210, 82, 623, 624, 625, 245, 578, 333, 626], [627, 628, 629, 588, 508], [4, 8, 149, 630, 183, 483, 631, 508, 264, 104], [632, 631, 508, 459, 136, 20, 633, 342, 617, 11, 551, 11, 41, 342, 22, 344, 634, 588, 49, 4, 8, 551], [], []]\n"
     ]
    }
   ],
   "source": [
    "print(doc_para_sentence_number[0][23])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getSparseMatrix(list2D,feature_number):\n",
    "    row,column,data = [],[],[]\n",
    "\n",
    "    for j,numList in enumerate(list2D):\n",
    "        tempm = collections.defaultdict(int)\n",
    "        for i in numList:\n",
    "            tempm[i]+=1\n",
    "        for i in tempm.keys():\n",
    "            column.append(i)\n",
    "            data.append(tempm[i])\n",
    "        row.extend([j]*len(tempm))\n",
    "    return coo_matrix((data,(row,column)),shape=(len(list2D),feature_number+1))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33455\n",
      "29186\n"
     ]
    }
   ],
   "source": [
    "keyword_doc_numset = set([wi for wi in wordnum_freq_doc.keys() if len(wordnum_freq_doc[wi])<=1])\n",
    "keyword_para_numset = set([wi for wi in wordnum_freq_para.keys() if len(wordnum_freq_para[wi])<=1])\n",
    "print (len(keyword_doc_numset))\n",
    "print (len(keyword_para_numset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n",
      "59028\n",
      "['first', 'recognize', '1900', 'max', 'planck', 'wa', 'originally', 'proportionality', 'constant', 'minimal', 'increment', 'energy', 'e', 'hypothetical', 'electrically', 'charge', 'oscillator', 'cavity', 'contain', 'black', 'body', 'radiation', 'frequency', 'f', 'associate', 'electromagnetic', 'wave', '1905', 'value', 'theoretically', 'einstein', 'element', 'light', 'quantum', 'behave', 'respect', 'neutral', 'particle', 'oppose', 'eventually', 'call', 'photon', 'classical', 'statistical', 'mechanic', 'require', 'existence', 'h', 'doe', 'define', 'follow', 'upon', 'discovery', 'physical', 'action', 'cannot', 'take', 'arbitrary', 'instead', 'must', 'multiple', 'small', 'quantity', 'physic', 'explain', 'fact', 'many', 'case', 'monochromatic', 'atom', 'also', 'imply', 'certain', 'level', 'allow', 'forbid', 'equivalently', 'smallness', 'reflect', 'everyday', 'object', 'system', 'make', 'large', 'number', 'example', 'green', 'wavelength', '555', 'nanometre', 'approximate', 'human', 'eye', 'ha', 'thz', 'hf', 'j', 'amount', 'term', 'experience']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "row,column,data = [],[],[]\n",
    "for j,num_para in enumerate(num_paras):\n",
    "    tempm = collections.defaultdict(int)\n",
    "    for i in num_para:\n",
    "        tempm[i]+=1\n",
    "    for i in tempm.keys():\n",
    "        column.append(i)\n",
    "        data.append(tempm[i])\n",
    "    row.extend([j]*len(tempm))\n",
    "matr_doc = coo_matrix((data,(row,column)),shape=(len(num_paras),len(word_numbers)+1))\n",
    "\n",
    "print (len(doc_dict))\n",
    "print (len(word_numbers))\n",
    "print (list(word_numbers.keys())[:100])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('D:/websearch/stanford/stanford-ner-2015-12-09/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "                       ,'D:/websearch/stanford/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "print (\"asdfasdddf\")\n",
    "text = 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "text = \"Classical statistical mechanics requires the existence of h (but does not define its value\"\n",
    "text = \"The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\"\n",
    "text = \"The photoelectric effect is the emission of electrons (called \\\"photoelectrons\\\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\"\n",
    "\n",
    "# text = 'While in France'\n",
    "print(\"asdfasdf\")\n",
    "\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "count_doc = 0\n",
    "count_para = 0\n",
    "print (len(devel))\n",
    "for j,qa in enumerate(devel[:100]):\n",
    "    question = qa[\"question\"]\n",
    "    paraid = qa[\"answer_paragraph\"]\n",
    "    docid = qa[\"docid\"]\n",
    "    answer = qa[\"text\"]\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_para)\n",
    "    sentenceid = np.argmax(cos_sims[0])\n",
    "    tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    \n",
    "    \n",
    "\n",
    "    if j%30==0:\n",
    "        print (j)\n",
    "print (count_doc)\n",
    "print (count_para)\n",
    "print (len(devel))\n",
    "#     print cos_sims[0][paraindex:paraindex+10]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097\n",
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "8\n",
      "66\n",
      "3097\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "count_doc = 0\n",
    "count_para = 0\n",
    "print (len(devel))\n",
    "for j,qa in enumerate(devel[:100]):\n",
    "    question = qa[\"question\"]\n",
    "    paraid = qa[\"answer_paragraph\"]\n",
    "    docid = qa[\"docid\"]\n",
    "    answer = qa[\"text\"]\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_doc)\n",
    "    paraindex = np.argmax(cos_sims[0])\n",
    "    for wi in num_question:\n",
    "        if wi in keyword_para_numset:\n",
    "            paraindex = wordnum_freq_para[wi][0][1]\n",
    "            if docid ==  wordnum_freq_para[wi][0][0]:\n",
    "                count_doc+=1\n",
    "#                 if paraid == wordnum_freq_para[wi][0][1]:\n",
    "#                     count_para+=1\n",
    "                break\n",
    "    else:\n",
    "        start = doc_para[docid][0]\n",
    "        end = doc_para[docid][1]\n",
    "        paraindex = np.argmax(cos_sims[0][start:end])\n",
    "        paraindex = para_doc[paraindex+start][1]\n",
    "#     paraindex2 = np.argmax(np.concatenate((cos_sims[0][start:end][:paraindex],cos_sims[0][start:end][paraindex+1:])))\n",
    "#         paraindex2 = np.argmax(cos_sims[0][start:end][:paraindex]+cos_sims[0][start:end][paraindex+1:])\n",
    "#         if paraid == para_doc[paraindex+start][1]:\n",
    "#             count_para+=1\n",
    "#     elif paraid == para_doc[paraindex2+start][1]:\n",
    "#         count_para+=1\n",
    "    if paraid == paraindex:\n",
    "        count_para+=1\n",
    "    \n",
    "\n",
    "    if j%30==0:\n",
    "        print (j)\n",
    "print (count_doc)\n",
    "print (count_para)\n",
    "print (len(devel))\n",
    "#     print cos_sims[0][paraindex:paraindex+10]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "count_doc = 0\n",
    "count_para = 0\n",
    "print (len(devel))\n",
    "\n",
    "for j,qa in enumerate(devel[:100]):\n",
    "    question = qa[\"question\"]\n",
    "    paraid = qa[\"answer_paragraph\"]\n",
    "    docid = qa[\"docid\"]\n",
    "    answer = qa[\"text\"]\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    row,column,data = [],[],[]\n",
    "    tempm = collections.defaultdict(int)\n",
    "    for i in num_question:\n",
    "        tempm[i]+=1\n",
    "    for i in tempm.keys():\n",
    "        column.append(i)\n",
    "        data.append(tempm[i])\n",
    "    row.extend([0]*len(tempm))\n",
    "    matr = coo_matrix((data,(row,column)),shape=(1,len(word_numbers)+1))\n",
    "    cos_sims = cosine_similarity(matr,matr_doc)\n",
    "    paraindex = np.argmax(cos_sims[0])\n",
    "    for wi in num_question:\n",
    "        if wi in keyword_para_numset:\n",
    "            if docid ==  wordnum_freq_para[wi][0][0]:\n",
    "                count_doc+=1\n",
    "                if paraid == wordnum_freq_para[wi][0][1]:\n",
    "                    count_para+=1\n",
    "            break\n",
    "    else:\n",
    "        start = doc_para[docid][0]\n",
    "        end = doc_para[docid][1]\n",
    "        paraindex = np.argmax(cos_sims[0][start:end])\n",
    "#     paraindex2 = np.argmax(np.concatenate((cos_sims[0][start:end][:paraindex],cos_sims[0][start:end][paraindex+1:])))\n",
    "#         paraindex2 = np.argmax(cos_sims[0][start:end][:paraindex]+cos_sims[0][start:end][paraindex+1:])\n",
    "        if paraid == para_doc[paraindex+start][1]:\n",
    "            count_para+=1\n",
    "#     elif paraid == para_doc[paraindex2+start][1]:\n",
    "#         count_para+=1\n",
    "    \n",
    "#     for wi in num_question:\n",
    "#         if wi in keyword_para_numset:\n",
    "#             if docid ==  wordnum_freq_para[wi][0][0]:\n",
    "#                 count_doc+=1\n",
    "#                 if paraid == wordnum_freq_para[wi][0][1]:\n",
    "#                     count_para+=1\n",
    "#             break\n",
    "#     else:\n",
    "#         for wi in num_question:\n",
    "#             if wi in keyword_doc_numset:\n",
    "#     #             print wordnum_freq_doc[wi][0]\n",
    "#                 start = doc_para[wordnum_freq_doc[wi][0]][0]\n",
    "#                 end = doc_para[wordnum_freq_doc[wi][0]][1]\n",
    "#                 paraindex = np.argmax(cos_sims[0][start:end])\n",
    "#                 if docid ==  para_doc[paraindex+start][0]:\n",
    "#                     count_doc+=1\n",
    "#                     if paraid == para_doc[paraindex+start][1]:\n",
    "#                         count_para+=1\n",
    "#                 break\n",
    "#         else:\n",
    "#             if docid ==  para_doc[paraindex][0]:\n",
    "#                 count_doc+=1\n",
    "#                 if paraid == para_doc[paraindex][1]:\n",
    "#                     count_para+=1\n",
    "    if j%30==0:\n",
    "        print (j)\n",
    "print (count_doc)\n",
    "print (count_para)\n",
    "print (len(devel))\n",
    "#     print cos_sims[0][paraindex:paraindex+10]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\毛东东\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\毛东东\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\毛东东\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\毛东东\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "# print nltk.ne_chunk(nltk.corpus.treebank.tagged_sents()[11])\n",
    "nltk.download('punkt')\n",
    "# from nltk.tag import pos_tag\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# print pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"))\n",
    "# import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On what date did the companies that became the Computing-Tabulating-Recording Company get consolidated?\n",
      "[('The', 'DT'), ('black-body', 'NN'), ('problem', 'NN'), ('was', 'VBD'), ('revisited', 'VBN'), ('in', 'IN'), ('1905', 'CD'), (',', ','), ('when', 'WRB'), ('Rayleigh', 'NNP'), ('and', 'CC'), ('Jeans', 'NNP'), ('(', '('), ('on', 'IN'), ('the', 'DT'), ('one', 'CD'), ('hand', 'NN'), (')', ')'), ('and', 'CC'), ('Einstein', 'NNP'), ('(', '('), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), (')', ')'), ('independently', 'RB'), ('proved', 'VBD'), ('that', 'DT'), ('classical', 'JJ'), ('electromagnetism', 'NN'), ('could', 'MD'), ('never', 'RB'), ('account', 'VB'), ('for', 'IN'), ('the', 'DT'), ('observed', 'JJ'), ('spectrum', 'NN'), ('.', '.')]\n",
      "(S\n",
      "  The/DT\n",
      "  black-body/NN\n",
      "  problem/NN\n",
      "  was/VBD\n",
      "  revisited/VBN\n",
      "  in/IN\n",
      "  1905/CD\n",
      "  ,/,\n",
      "  when/WRB\n",
      "  (PERSON Rayleigh/NNP)\n",
      "  and/CC\n",
      "  (GPE Jeans/NNP)\n",
      "  (/(\n",
      "  on/IN\n",
      "  the/DT\n",
      "  one/CD\n",
      "  hand/NN\n",
      "  )/)\n",
      "  and/CC\n",
      "  (GPE Einstein/NNP)\n",
      "  (/(\n",
      "  on/IN\n",
      "  the/DT\n",
      "  other/JJ\n",
      "  hand/NN\n",
      "  )/)\n",
      "  independently/RB\n",
      "  proved/VBD\n",
      "  that/DT\n",
      "  classical/JJ\n",
      "  electromagnetism/NN\n",
      "  could/MD\n",
      "  never/RB\n",
      "  account/VB\n",
      "  for/IN\n",
      "  the/DT\n",
      "  observed/JJ\n",
      "  spectrum/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (NP The/DT black-body/NN problem/NN)\n",
      "  was/VBD\n",
      "  revisited/VBN\n",
      "  in/IN\n",
      "  (NP 1905/CD)\n",
      "  ,/,\n",
      "  when/WRB\n",
      "  (NP Rayleigh/NNP and/CC Jeans/NNP)\n",
      "  (/(\n",
      "  on/IN\n",
      "  (NP the/DT one/CD hand/NN)\n",
      "  )/)\n",
      "  (NP and/CC Einstein/NNP)\n",
      "  (/(\n",
      "  on/IN\n",
      "  (NP the/DT other/JJ hand/NN)\n",
      "  )/)\n",
      "  independently/RB\n",
      "  proved/VBD\n",
      "  (NP that/DT classical/JJ electromagnetism/NN)\n",
      "  could/MD\n",
      "  never/RB\n",
      "  account/VB\n",
      "  for/IN\n",
      "  (NP the/DT observed/JJ spectrum/NN)\n",
      "  ./.)\n",
      "Label: NP\n",
      "Leaves: [('The', 'DT'), ('black-body', 'NN'), ('problem', 'NN')]\n",
      "Word: ('The', 'DT')\n",
      "Word: ('black-body', 'NN')\n",
      "Word: ('problem', 'NN')\n",
      "Word: ('was', 'VBD')\n",
      "Word: ('revisited', 'VBN')\n",
      "Word: ('in', 'IN')\n",
      "Label: NP\n",
      "Leaves: [('1905', 'CD')]\n",
      "Word: ('1905', 'CD')\n",
      "Word: (',', ',')\n",
      "Word: ('when', 'WRB')\n",
      "Label: NP\n",
      "Leaves: [('Rayleigh', 'NNP'), ('and', 'CC'), ('Jeans', 'NNP')]\n",
      "Word: ('Rayleigh', 'NNP')\n",
      "Word: ('and', 'CC')\n",
      "Word: ('Jeans', 'NNP')\n",
      "Word: ('(', '(')\n",
      "Word: ('on', 'IN')\n",
      "Label: NP\n",
      "Leaves: [('the', 'DT'), ('one', 'CD'), ('hand', 'NN')]\n",
      "Word: ('the', 'DT')\n",
      "Word: ('one', 'CD')\n",
      "Word: ('hand', 'NN')\n",
      "Word: (')', ')')\n",
      "Label: NP\n",
      "Leaves: [('and', 'CC'), ('Einstein', 'NNP')]\n",
      "Word: ('and', 'CC')\n",
      "Word: ('Einstein', 'NNP')\n",
      "Word: ('(', '(')\n",
      "Word: ('on', 'IN')\n",
      "Label: NP\n",
      "Leaves: [('the', 'DT'), ('other', 'JJ'), ('hand', 'NN')]\n",
      "Word: ('the', 'DT')\n",
      "Word: ('other', 'JJ')\n",
      "Word: ('hand', 'NN')\n",
      "Word: (')', ')')\n",
      "Word: ('independently', 'RB')\n",
      "Word: ('proved', 'VBD')\n",
      "Label: NP\n",
      "Leaves: [('that', 'DT'), ('classical', 'JJ'), ('electromagnetism', 'NN')]\n",
      "Word: ('that', 'DT')\n",
      "Word: ('classical', 'JJ')\n",
      "Word: ('electromagnetism', 'NN')\n",
      "Word: ('could', 'MD')\n",
      "Word: ('never', 'RB')\n",
      "Word: ('account', 'VB')\n",
      "Word: ('for', 'IN')\n",
      "Label: NP\n",
      "Leaves: [('the', 'DT'), ('observed', 'JJ'), ('spectrum', 'NN')]\n",
      "Word: ('the', 'DT')\n",
      "Word: ('observed', 'JJ')\n",
      "Word: ('spectrum', 'NN')\n",
      "Word: ('.', '.')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\"\n",
    "b = pos_tag(word_tokenize(devel[1][\"question\"]))\n",
    "b = pos_tag(word_tokenize(text))\n",
    "print (devel[0][\"question\"])\n",
    "print (b)\n",
    "print (nltk.ne_chunk(b))\n",
    "root  = nltk.ne_chunk(b)\n",
    "# if type(root) is nltk.Tree:\n",
    "#     print \"------\"\n",
    "#     print root.label()\n",
    "#     print \"------\"\n",
    "#     print root.leaves()\n",
    "grammar = r\"NP: {<[CDJNP].*>+}\"\n",
    "#TODO\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(b)\n",
    "print (result)\n",
    "\n",
    "def getNodes(parent):\n",
    "    for node in parent:\n",
    "#         print type(node)\n",
    "        if type(node) is nltk.Tree:\n",
    "            if node.label() == node:\n",
    "                print (\"======== Sentence =========\")\n",
    "                print (\"Sentence:\", \" \".join(node.leaves()))\n",
    "            else:\n",
    "                print (\"Label:\", node.label())\n",
    "                print (\"Leaves:\", node.leaves())\n",
    "\n",
    "            getNodes(node)\n",
    "        else:\n",
    "            print (\"Word:\", node)\n",
    "\n",
    "getNodes(result)\n",
    "# print devel[0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "28\n",
      "[-2.4183218  -0.7700025   0.39351952  2.6235843   1.995839   -1.3643907\n",
      " -0.5738242   1.155701   -1.0765399   1.7825425  -1.1697105   0.06971284\n",
      " -2.0900254  -0.07137149  0.70699847 -0.7539422   3.4551535   0.6422943\n",
      "  0.43637753 -0.47551757  0.40616605 -1.6444353  -1.9553356   1.3957288\n",
      " -0.6918805  -0.16163789 -0.95779884 -0.39391643]\n",
      "[ 0.25520676 -0.02365677  0.2524145   0.20869294 -0.04920257  0.07489824\n",
      "  0.16527224  0.03057414  0.14632986  0.02486908 -0.06877342 -0.04316078\n",
      " -0.04470331  0.10107683 -0.21038398 -0.2549741   0.21840368 -0.19712389\n",
      "  0.04263122 -0.26919296  0.0542332  -0.06757405 -0.07743678 -0.1689456\n",
      " -0.17024069  0.05495913  0.08258761  0.02054949]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "# import json\n",
    "# f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "# a = f2.readline()\n",
    "# f2.close()\n",
    "# doc_dict = json.loads(a)\n",
    "# temp_corpus = [word_tokenize(para) for doc in doc_dict for para in doc[\"text\"]]\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)\n",
    "# temp_corpus += [word_tokenize(question) for devel in devels for question in devel[\"question\"]]\n",
    "\n",
    "# f1 = open(\"./assignment_group/project_files/testing.json\")\n",
    "# a = f1.readline()\n",
    "# f1.close()\n",
    "# tests = json.loads(a)\n",
    "# temp_corpus += [word_tokenize(question) for test in tests for question in test[\"question\"]]\n",
    "\n",
    "# model = gensim.models.Word2Vec(temp_corpus,size = 28)\n",
    "# model.save('document.embedding')\n",
    "new_model = []\n",
    "new_model = gensim.models.Word2Vec.load('d:/websearch/websearch/document.embedding')\n",
    "print (\"--------------------\")\n",
    "print (len(new_model.wv[\"company\"]))\n",
    "print (new_model.wv[\"company\"])\n",
    "print (new_model.wv[\"liked\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'The', u'Fulton', u'County', u'Grand', u'Jury', u'said', u'Friday', u'an', u'investigation', u'of', u\"Atlanta's\", u'recent', u'primary', u'election', u'produced', u'``', u'no', u'evidence', u\"''\", u'that', u'any', u'irregularities', u'took', u'place', u'.']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CategorizedTaggedCorpusReader' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a1ba4f8cc67b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = gensim.models.Word2Vec(brown.sents())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.save('brown.embedding')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CategorizedTaggedCorpusReader' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "print brown.sents()[0]\n",
    "print brown.vocab\n",
    "# model = gensim.models.Word2Vec(brown.sents())\n",
    "# model.save('brown.embedding')\n",
    "# new_model = gensim.models.Word2Vec.load('brown.embedding')\n",
    "# print len(new_model[\"university\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43379\n",
      "The legal process to change the definition of the kilogram is already underway, but it had been decided that no final decision would be made before the next meeting of the General Conference on Weights and Measures in 2011. (For more detailed information, see kilogram definitions.) The Planck constant is a leading contender to form the basis of the new definition, although not the only one. Possible new definitions include \"the mass of a body at rest whose equivalent energy equals the energy of photons whose frequencies sum to 7050135639273999999♠135639274×1042 Hz\", or simply \"the kilogram is defined so that the Planck constant equals 6966662606895999999♠6.62606896×10−34 J⋅s\".\n",
      "There are a number of proposals to redefine certain of the SI base units in terms of fundamental physical constants. This has already been done for the metre, which is defined in terms of a fixed value of the speed of light. The most urgent unit on the list for redefinition is the kilogram, whose value has been fixed for all science (since 1889) by the mass of a small cylinder of platinum–iridium alloy kept in a vault just outside Paris. While nobody knows if the mass of the International Prototype Kilogram has changed since 1889 – the value 1 kg of its mass expressed in kilograms is by definition unchanged and therein lies one of the problems – it is known that over such a timescale the many similar Pt–Ir alloy cylinders kept in national laboratories around the world, have changed their relative mass by several tens of parts per million, however carefully they are stored, and the more so the more they have been taken out and used as mass standards. A change of several tens of micrograms in one kilogram is equivalent to the current uncertainty in the value of the Planck constant in SI units.\n",
      "-------------- ('cylinder', 'NN')\n",
      "where the uncertainty is given as the standard deviation of the measured value from its expected value. There are a number of other such pairs of physically measurable values which obey a similar rule. One example is time vs. energy. The either-or nature of uncertainty forces measurement attempts to choose between trade offs, and given that they are quanta, the trade offs often take the form of either-or (as in Fourier analysis), rather than the compromises and gray areas of time series analysis.\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "Niels Bohr introduced the first quantized model of the atom in 1913, in an attempt to overcome a major shortcoming of Rutherford's classical model. In classical electrodynamics, a charge moving in a circle should radiate electromagnetic radiation. If that charge were to be an electron orbiting a nucleus, the radiation would cause it to lose energy and spiral down into the nucleus. Bohr solved this paradox with explicit reference to Planck's work: an electron in a Bohr atom could only have certain defined energies En\n",
      "-------------- ('1913', 'CD')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "-------------- ('Kirchhoff', 'NNP')\n",
      "-------------- PERSON kirchhoff\n",
      "Bohr also introduced the quantity , now known as the reduced Planck constant, as the quantum of angular momentum. At first, Bohr thought that this was the angular momentum of each electron in an atom: this proved incorrect and, despite developments by Sommerfeld and others, an accurate description of the electron angular momentum proved beyond the Bohr model. The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum. In modern terms, if J is the total angular momentum of a system with rotational invariance, and Jz the angular momentum measured along any given direction, these quantities can only take on the values\n",
      "-------------- ('Schrödinger', 'NNP')\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "-------------- ('h', 'NN')\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "-------------- ('h', 'NN')\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "-------------- ('f', 'NN')\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- ('1839', 'CD')\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- ('1911', 'CD')\n",
      "-------------- ('1911', 'CD')\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- PERSON heinrich hertz\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- PERSON alexandre edmond becquerel\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "-------------- PERSON paul ehrenfest\n",
      "The \"photoelectrons\" emitted as a result of the photoelectric effect have a certain kinetic energy, which can be measured. This kinetic energy (for each photoelectron) is independent of the intensity of the light, but depends linearly on the frequency; and if the frequency is too low (corresponding to a photon energy that is less than the work function of the material), no photoelectrons are emitted at all, unless a plurality of photons, whose energetic sum is greater than the energy of the photoelectrons, acts virtually simultaneously (multiphoton effect)  Assuming the frequency is high enough to cause the photoelectric effect, a rise in intensity of the light source causes more photoelectrons to be emitted with the same kinetic energy, rather than the same number of photoelectrons to be emitted with higher kinetic energy.\n",
      "The Bohr magneton and the nuclear magneton are units which are used to describe the magnetic properties of the electron and atomic nuclei respectively. The Bohr magneton is the magnetic moment which would be expected for an electron if it behaved as a spinning charge according to classical electrodynamics. It is defined in terms of the reduced Planck constant, the elementary charge and the electron mass, all of which depend on the Planck constant: the final dependence on h1/2 (r2 > 0.995) can be found by expanding the variables.\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "-------------- ('Einstein', 'NNP')\n",
      "-------------- PERSON einstein\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- PERSON alexandre edmond becquerel\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "-------------- ('1911', 'CD')\n",
      "-------------- ('1911', 'CD')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- ('Einstein', 'NNP')\n",
      "-------------- PERSON einstein\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "-------------- ('thermal', 'JJ')\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "-------------- ('quantum', 'NN')\n",
      "-------------- ('quantum', 'NN')\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "-------------- ('forbidden', 'JJ')\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- ('particles', 'NNS')\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "-------------- ('green', 'JJ')\n",
      "-------------- ('green', 'JJ')\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "-------------- ('Einstein', 'NNP')\n",
      "-------------- PERSON einstein\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "-------------- ('colour', 'NN')\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "There are a number of proposals to redefine certain of the SI base units in terms of fundamental physical constants. This has already been done for the metre, which is defined in terms of a fixed value of the speed of light. The most urgent unit on the list for redefinition is the kilogram, whose value has been fixed for all science (since 1889) by the mass of a small cylinder of platinum–iridium alloy kept in a vault just outside Paris. While nobody knows if the mass of the International Prototype Kilogram has changed since 1889 – the value 1 kg of its mass expressed in kilograms is by definition unchanged and therein lies one of the problems – it is known that over such a timescale the many similar Pt–Ir alloy cylinders kept in national laboratories around the world, have changed their relative mass by several tens of parts per million, however carefully they are stored, and the more so the more they have been taken out and used as mass standards. A change of several tens of micrograms in one kilogram is equivalent to the current uncertainty in the value of the Planck constant in SI units.\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "-------------- ('intensity', 'NN')\n",
      "-------------- ('intensity', 'NN')\n",
      "In principle, the Planck constant could be determined by examining the spectrum of a black-body radiator or the kinetic energy of photoelectrons, and this is how its value was first calculated in the early twentieth century. In practice, these are no longer the most accurate methods. The CODATA value quoted here is based on three watt-balance measurements of KJ2RK and one inter-laboratory determination of the molar volume of silicon, but is mostly determined by a 2007 watt-balance measurement made at the U.S. National Institute of Standards and Technology (NIST). Five other measurements by three different methods were initially considered, but not included in the final refinement as they were too imprecise to affect the result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theoretical difficulties arise from the fact that all of the methods except the X-ray crystal density method rely on the theoretical basis of the Josephson effect and the quantum Hall effect. If these theories are slightly inaccurate – though there is no evidence at present to suggest they are – the methods would not give accurate values for the Planck constant. More importantly, the values of the Planck constant obtained in this way cannot be used as tests of the theories without falling into a circular argument. Fortunately, there are other statistical ways of testing the theories, and the theories have yet to be refuted.\n",
      "The legal process to change the definition of the kilogram is already underway, but it had been decided that no final decision would be made before the next meeting of the General Conference on Weights and Measures in 2011. (For more detailed information, see kilogram definitions.) The Planck constant is a leading contender to form the basis of the new definition, although not the only one. Possible new definitions include \"the mass of a body at rest whose equivalent energy equals the energy of photons whose frequencies sum to 7050135639273999999♠135639274×1042 Hz\", or simply \"the kilogram is defined so that the Planck constant equals 6966662606895999999♠6.62606896×10−34 J⋅s\".\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "The \"photoelectrons\" emitted as a result of the photoelectric effect have a certain kinetic energy, which can be measured. This kinetic energy (for each photoelectron) is independent of the intensity of the light, but depends linearly on the frequency; and if the frequency is too low (corresponding to a photon energy that is less than the work function of the material), no photoelectrons are emitted at all, unless a plurality of photons, whose energetic sum is greater than the energy of the photoelectrons, acts virtually simultaneously (multiphoton effect)  Assuming the frequency is high enough to cause the photoelectric effect, a rise in intensity of the light source causes more photoelectrons to be emitted with the same kinetic energy, rather than the same number of photoelectrons to be emitted with higher kinetic energy.\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "The X-ray crystal density method is primarily a method for determining the Avogadro constant NA but as the Avogadro constant is related to the Planck constant it also determines a value for h. The principle behind the method is to determine NA as the ratio between the volume of the unit cell of a crystal, measured by X-ray crystallography, and the molar volume of the substance. Crystals of silicon are used, as they are available in high quality and purity by the technology developed for the semiconductor industry. The unit cell volume is calculated from the spacing between two crystal planes referred to as d220. The molar volume Vm(Si) requires a knowledge of the density of the crystal and the atomic weight of the silicon used. The Planck constant is given by\n",
      "where the uncertainty is given as the standard deviation of the measured value from its expected value. There are a number of other such pairs of physically measurable values which obey a similar rule. One example is time vs. energy. The either-or nature of uncertainty forces measurement attempts to choose between trade offs, and given that they are quanta, the trade offs often take the form of either-or (as in Fourier analysis), rather than the compromises and gray areas of time series analysis.\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "-------------- ('sound', 'NN')\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "-------------- ('thermal', 'JJ')\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "where the uncertainty is given as the standard deviation of the measured value from its expected value. There are a number of other such pairs of physically measurable values which obey a similar rule. One example is time vs. energy. The either-or nature of uncertainty forces measurement attempts to choose between trade offs, and given that they are quanta, the trade offs often take the form of either-or (as in Fourier analysis), rather than the compromises and gray areas of time series analysis.\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- ('relativity', 'NN')\n",
      "-------------- ('relativity', 'NN')\n",
      "Bohr also introduced the quantity , now known as the reduced Planck constant, as the quantum of angular momentum. At first, Bohr thought that this was the angular momentum of each electron in an atom: this proved incorrect and, despite developments by Sommerfeld and others, an accurate description of the electron angular momentum proved beyond the Bohr model. The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum. In modern terms, if J is the total angular momentum of a system with rotational invariance, and Jz the angular momentum measured along any given direction, these quantities can only take on the values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "-------------- ('1918', 'CD')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "-------------- ('black-body', 'NN')\n",
      "Prior to Planck's work, it had been assumed that the energy of a body could take on any value whatsoever – that it was a continuous variable. The Rayleigh–Jeans law makes close predictions for a narrow range of values at one limit of temperatures, but the results diverge more and more strongly as temperatures increase. To make Planck's law, which correctly predicts blackbody emissions, it was necessary to multiply the classical expression by a complex factor that involves h in both the numerator and the denominator. The influence of h in this complex factor would not disappear if it were set to zero or to any other value. Making an equation out of Planck's law that would reproduce the Rayleigh–Jeans law could not be done by changing the values of h, of the Boltzmann constant, or of any other constant or variable in the equation. In this case the picture given by classical physics is not duplicated by a range of results in the quantum picture.\n",
      "-------------- ('h', 'NN')\n",
      "-------------- ('h', 'NN')\n",
      "-------------- ('h', 'NN')\n",
      "Classical statistical mechanics requires the existence of h (but does not define its value). Eventually, following upon Planck's discovery, it was recognized that physical action cannot take on an arbitrary value. Instead, it must be some multiple of a very small quantity, the \"quantum of action\", now called the Planck constant. Classical physics cannot explain this fact. In many cases, such as for monochromatic light or for atoms, this quantum of action also implies that only certain energy levels are allowed, and values in between are forbidden.\n",
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "-------------- PERSON wilhelm wien\n",
      "Bohr also introduced the quantity , now known as the reduced Planck constant, as the quantum of angular momentum. At first, Bohr thought that this was the angular momentum of each electron in an atom: this proved incorrect and, despite developments by Sommerfeld and others, an accurate description of the electron angular momentum proved beyond the Bohr model. The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum. In modern terms, if J is the total angular momentum of a system with rotational invariance, and Jz the angular momentum measured along any given direction, these quantities can only take on the values\n",
      "-------------- ('Bohr', 'NNP')\n",
      "-------------- PERSON bohr\n",
      "-------------- ('Bohr', 'NNP')\n",
      "-------------- PERSON bohr\n",
      "-------------- ('Bohr', 'NNP')\n",
      "-------------- ORGANIZATION bohr\n",
      "-------------- ('Bohr', 'NNP')\n",
      "-------------- ORGANIZATION bohr\n",
      "Bohr also introduced the quantity , now known as the reduced Planck constant, as the quantum of angular momentum. At first, Bohr thought that this was the angular momentum of each electron in an atom: this proved incorrect and, despite developments by Sommerfeld and others, an accurate description of the electron angular momentum proved beyond the Bohr model. The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum. In modern terms, if J is the total angular momentum of a system with rotational invariance, and Jz the angular momentum measured along any given direction, these quantities can only take on the values\n",
      "-------------- ('Heisenberg', 'NNP')\n",
      "-------------- PERSON heisenberg\n",
      "Prior to Planck's work, it had been assumed that the energy of a body could take on any value whatsoever – that it was a continuous variable. The Rayleigh–Jeans law makes close predictions for a narrow range of values at one limit of temperatures, but the results diverge more and more strongly as temperatures increase. To make Planck's law, which correctly predicts blackbody emissions, it was necessary to multiply the classical expression by a complex factor that involves h in both the numerator and the denominator. The influence of h in this complex factor would not disappear if it were set to zero or to any other value. Making an equation out of Planck's law that would reproduce the Rayleigh–Jeans law could not be done by changing the values of h, of the Boltzmann constant, or of any other constant or variable in the equation. In this case the picture given by classical physics is not duplicated by a range of results in the quantum picture.\n",
      "There are a number of proposals to redefine certain of the SI base units in terms of fundamental physical constants. This has already been done for the metre, which is defined in terms of a fixed value of the speed of light. The most urgent unit on the list for redefinition is the kilogram, whose value has been fixed for all science (since 1889) by the mass of a small cylinder of platinum–iridium alloy kept in a vault just outside Paris. While nobody knows if the mass of the International Prototype Kilogram has changed since 1889 – the value 1 kg of its mass expressed in kilograms is by definition unchanged and therein lies one of the problems – it is known that over such a timescale the many similar Pt–Ir alloy cylinders kept in national laboratories around the world, have changed their relative mass by several tens of parts per million, however carefully they are stored, and the more so the more they have been taken out and used as mass standards. A change of several tens of micrograms in one kilogram is equivalent to the current uncertainty in the value of the Planck constant in SI units.\n",
      "-------------- ('platinum–iridium', 'NN')\n",
      "Prior to Planck's work, it had been assumed that the energy of a body could take on any value whatsoever – that it was a continuous variable. The Rayleigh–Jeans law makes close predictions for a narrow range of values at one limit of temperatures, but the results diverge more and more strongly as temperatures increase. To make Planck's law, which correctly predicts blackbody emissions, it was necessary to multiply the classical expression by a complex factor that involves h in both the numerator and the denominator. The influence of h in this complex factor would not disappear if it were set to zero or to any other value. Making an equation out of Planck's law that would reproduce the Rayleigh–Jeans law could not be done by changing the values of h, of the Boltzmann constant, or of any other constant or variable in the equation. In this case the picture given by classical physics is not duplicated by a range of results in the quantum picture.\n",
      "Niels Bohr introduced the first quantized model of the atom in 1913, in an attempt to overcome a major shortcoming of Rutherford's classical model. In classical electrodynamics, a charge moving in a circle should radiate electromagnetic radiation. If that charge were to be an electron orbiting a nucleus, the radiation would cause it to lose energy and spiral down into the nucleus. Bohr solved this paradox with explicit reference to Planck's work: an electron in a Bohr atom could only have certain defined energies En\n",
      "In principle, the Planck constant could be determined by examining the spectrum of a black-body radiator or the kinetic energy of photoelectrons, and this is how its value was first calculated in the early twentieth century. In practice, these are no longer the most accurate methods. The CODATA value quoted here is based on three watt-balance measurements of KJ2RK and one inter-laboratory determination of the molar volume of silicon, but is mostly determined by a 2007 watt-balance measurement made at the U.S. National Institute of Standards and Technology (NIST). Five other measurements by three different methods were initially considered, but not included in the final refinement as they were too imprecise to affect the result.\n",
      "-------------- ('2007', 'CD')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalently, the smallness of the Planck constant reflects the fact that everyday objects and systems are made of a large number of particles. For example, green light with a wavelength of 555 nanometres (the approximate wavelength to which human eyes are most sensitive) has a frequency of 7014540000000000000♠540 THz (7014540000000000000♠540×1012 Hz). Each photon has an energy E = hf = 6981358000000000000♠3.58×10−19 J. That is a very small amount of energy in terms of everyday experience, but everyday experience is not concerned with individual photons any more than with individual atoms or molecules. An amount of light compatible with everyday experience is the energy of one mole of photons; its energy can be computed by multiplying the photon energy by the Avogadro constant, NA ≈ 7023602200000000000♠6.022×1023 mol−1. The result is that green light of wavelength 555 nm has an energy of 7005216000000000000♠216 kJ/mol, a typical energy of everyday life.\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "-------------- ('intensity', 'NN')\n",
      "-------------- ('intensity', 'NN')\n",
      "The photoelectric effect is the emission of electrons (called \"photoelectrons\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\n",
      "-------------- ('1921', 'CD')\n",
      "Bohr also introduced the quantity , now known as the reduced Planck constant, as the quantum of angular momentum. At first, Bohr thought that this was the angular momentum of each electron in an atom: this proved incorrect and, despite developments by Sommerfeld and others, an accurate description of the electron angular momentum proved beyond the Bohr model. The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum. In modern terms, if J is the total angular momentum of a system with rotational invariance, and Jz the angular momentum measured along any given direction, these quantities can only take on the values\n",
      "-------------- ('Heisenberg', 'NNP')\n",
      "-------------- PERSON heisenberg\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "Niels Bohr introduced the first quantized model of the atom in 1913, in an attempt to overcome a major shortcoming of Rutherford's classical model. In classical electrodynamics, a charge moving in a circle should radiate electromagnetic radiation. If that charge were to be an electron orbiting a nucleus, the radiation would cause it to lose energy and spiral down into the nucleus. Bohr solved this paradox with explicit reference to Planck's work: an electron in a Bohr atom could only have certain defined energies En\n",
      "First recognized in 1900 by Max Planck, it was originally the proportionality constant between the minimal increment of energy, E, of a hypothetical electrically charged oscillator in a cavity that contained black body radiation, and the frequency, f, of its associated electromagnetic wave. In 1905 the value E, the minimal energy increment of a hypothetical oscillator, was theoretically associated by Einstein with a \"quantum\" or minimal element of the energy of the electromagnetic wave itself. The light quantum behaved in some respects as an electrically neutral particle, as opposed to an electromagnetic wave. It was eventually called the photon.\n",
      "-------------- ('1905', 'CD')\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "-------------- PERSON max planck\n",
      "Prior to Einstein's paper, electromagnetic radiation such as visible light was considered to behave as a wave: hence the use of the terms \"frequency\" and \"wavelength\" to characterise different types of radiation. The energy transferred by a wave in a given time is called its intensity. The light from a theatre spotlight is more intense than the light from a domestic lightbulb; that is to say that the spotlight gives out more energy per unit time and per unit space(and hence consumes more electricity) than the ordinary bulb, even though the colour of the light might be very similar. Other waves, such as sound or the waves crashing against a seafront, also have their own intensity. However, the energy account of the photoelectric effect didn't seem to agree with the wave description of light.\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "-------------- ('forty', 'NN')\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum. These proofs are commonly known as the \"ultraviolet catastrophe\", a name coined by Paul Ehrenfest in 1911. They contributed greatly (along with Einstein's work on the photoelectric effect) to convincing physicists that Planck's postulate of quantized energy levels was more than a mere mathematical formalism. The very first Solvay Conference in 1911 was devoted to \"the theory of radiation and quanta\". Max Planck received the 1918 Nobel Prize in Physics \"in recognition of the services he rendered to the advancement of Physics by his discovery of energy quanta\".\n",
      "-------------- ('1911', 'CD')\n",
      "-------------- ('1911', 'CD')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- ('light', 'JJ')\n",
      "-------------- ('light', 'NN')\n",
      "-------------- ('light', 'JJ')\n",
      "-------------- ('light', 'JJ')\n",
      "In the last years of the nineteenth century, Planck was investigating the problem of black-body radiation first posed by Kirchhoff some forty years earlier. It is well known that hot objects glow, and that hotter objects glow brighter than cooler ones. The electromagnetic field obeys laws of motion similarly to a mass on a spring, and can come to thermal equilibrium with hot atoms. The hot object in equilibrium with light absorbs just as much light as it emits. If the object is black, meaning it absorbs all the light that hits it, then its thermal light emission is maximized.\n",
      "-------------- ('hotter', 'JJR')\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "-------------- ('accurate', 'JJ')\n",
      "In principle, the Planck constant could be determined by examining the spectrum of a black-body radiator or the kinetic energy of photoelectrons, and this is how its value was first calculated in the early twentieth century. In practice, these are no longer the most accurate methods. The CODATA value quoted here is based on three watt-balance measurements of KJ2RK and one inter-laboratory determination of the molar volume of silicon, but is mostly determined by a 2007 watt-balance measurement made at the U.S. National Institute of Standards and Technology (NIST). Five other measurements by three different methods were initially considered, but not included in the final refinement as they were too imprecise to affect the result.\n",
      "-------------- ('silicon', 'NN')\n",
      "The assumption that black-body radiation is thermal leads to an accurate prediction: the total amount of emitted energy goes up with the temperature according to a definite rule, the Stefan–Boltzmann law (1879–84). But it was also known that the colour of the light given off by a hot object changes with the temperature, so that \"white hot\" is hotter than \"red hot\". Nevertheless, Wilhelm Wien discovered the mathematical relationship between the peaks of the curves at different temperatures, by using the principle of adiabatic invariance. At each different temperature, the curve is moved over by Wien's displacement law (1893). Wien also proposed an approximation for the spectrum of the object, which was correct at high frequencies (short wavelength) but not at low frequencies (long wavelength). It still was not clear why the spectrum of a hot object had the form that it has (see diagram).\n",
      "Some of the second-generation renewables, such as wind power, have high potential and have already realised relatively low production costs. Global wind power installations increased by 35,800 MW in 2010, bringing total installed capacity up to 194,400 MW, a 22.5% increase on the 158,700 MW installed at the end of 2009. The increase for 2010 represents investments totalling €47.3 billion (US$65 billion) and for the first time more than half of all new wind power was added outside of the traditional markets of Europe and North America, mainly driven, by the continuing boom in China which accounted for nearly half of all of the installations at 16,500 MW. China now has 42,300 MW of wind power installed. Wind power accounts for approximately 19% of electricity generated in Denmark, 9% in Spain and Portugal, and 6% in Germany and the Republic of Ireland. In Australian state of South Australia wind power, championed by Premier Mike Rann (2002–2011), now comprises 26% of the state's electricity generation, edging out coal fired power. At the end of 2011 South Australia, with 7.2% of Australia's population, had 54%of the nation's installed wind power capacity. Wind power's share of worldwide electricity usage at the end of 2014 was 3.1%. These are some of the largest wind farms in the world:\n",
      "According to a 2011 projection by the International Energy Agency, solar power plants may produce most of the world's electricity within 50 years, significantly reducing the emissions of greenhouse gases that harm the environment. The IEA has said: \"Photovoltaic and solar-thermal plants may meet most of the world's demand for electricity by 2060 – and half of all energy needs – with wind, hydropower and biomass plants supplying much of the remaining generation\". \"Photovoltaic and concentrated solar power together can become the major source of electricity\".\n",
      "-------------- ORGANIZATION international energy agency\n",
      "A number of events in 2006 pushed renewable energy up the political agenda, including the US mid-term elections in November, which confirmed clean energy as a mainstream issue. Also in 2006, the Stern Review made a strong economic case for investing in low carbon technologies now, and argued that economic growth need not be incompatible with cutting energy consumption. According to a trend analysis from the United Nations Environment Programme, climate change concerns coupled with recent high oil prices and increasing government support are driving increasing rates of investment in the renewable energy and energy efficiency industries.\n",
      "-------------- LOCATION stern review\n",
      "Renewable energy technologies are getting cheaper, through technological change and through the benefits of mass production and market competition. A 2011 IEA report said: \"A portfolio of renewable energy technologies is becoming cost-competitive in an increasingly broad range of circumstances, in some cases providing investment opportunities without the need for specific economic support,\" and added that \"cost reductions in critical technologies, such as wind and solar, are set to continue.\" As of 2011[update], there have been substantial reductions in the cost of solar and wind technologies:\n",
      "Public policy determines the extent to which renewable energy (RE) is to be incorporated into a developed or developing country's generation mix. Energy sector regulators implement that policy—thus affecting the pace and pattern of RE investments and connections to the grid. Energy regulators often have authority to carry out a number of functions that have implications for the financial feasibility of renewable energy projects. Such functions include issuing licenses, setting performance standards, monitoring the performance of regulated firms, determining the price level and structure of tariffs, establishing uniform systems of accounts, arbitrating stakeholder disputes (like interconnection cost allocations), performing management audits, developing agency human resources (expertise), reporting sector and commission activities to government authorities, and coordinating decisions with other government agencies. Thus, regulators make a wide range of decisions that affect the financial outcomes associated with RE investments. In addition, the sector regulator is in a position to give advice to the government regarding the full implications of focusing on climate change or energy security. The energy sector regulator is the natural advocate for efficiency and cost-containment throughout the process of designing and implementing RE policies. Since policies are not self-implementing, energy sector regulators become a key facilitator (or blocker) of renewable energy investments.\n",
      "As of 2008[update], geothermal power development was under way in more than 40 countries, partially attributable to the development of new technologies, such as Enhanced Geothermal Systems. The development of binary cycle power plants and improvements in drilling and extraction technology may enable enhanced geothermal systems over a much greater geographical range than \"traditional\" Geothermal systems. Demonstration EGS projects are operational in the USA, Australia, Germany, France, and The United Kingdom.\n",
      "EU member countries have shown support for ambitious renewable energy goals. In 2010, Eurobarometer polled the twenty-seven EU member states about the target \"to increase the share of renewable energy in the EU by 20 percent by 2020\". Most people in all twenty-seven countries either approved of the target or called for it to go further. Across the EU, 57 percent thought the proposed goal was \"about right\" and 16 percent thought it was \"too modest.\" In comparison, 19 percent said it was \"too ambitious\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of events in 2006 pushed renewable energy up the political agenda, including the US mid-term elections in November, which confirmed clean energy as a mainstream issue. Also in 2006, the Stern Review made a strong economic case for investing in low carbon technologies now, and argued that economic growth need not be incompatible with cutting energy consumption. According to a trend analysis from the United Nations Environment Programme, climate change concerns coupled with recent high oil prices and increasing government support are driving increasing rates of investment in the renewable energy and energy efficiency industries.\n",
      "-------------- ('2006', 'CD')\n",
      "-------------- ('2006', 'CD')\n",
      "New government spending, regulation, and policies helped the industry weather the 2009 economic crisis better than many other sectors. Most notably, U.S. President Barack Obama's American Recovery and Reinvestment Act of 2009 included more than $70 billion in direct spending and tax credits for clean energy and associated transportation programs. This policy-stimulus combination represents the largest federal commitment in U.S. history for renewables, advanced transportation, and energy conservation initiatives. Based on these new rules, many more utilities strengthened their clean-energy programs. Clean Edge suggests that the commercialization of clean energy will help countries around the world deal with the current economic malaise. Once-promising solar energy company, Solyndra, became involved in a political controversy involving U.S. President Barack Obama's administration's authorization of a $535 million loan guarantee to the Corporation in 2009 as part of a program to promote alternative energy growth. The company ceased all business activity, filed for Chapter 11 bankruptcy, and laid-off nearly all of its employees in early September 2011.\n",
      "-------------- ('Solyndra', 'NNP')\n",
      "-------------- GPE solyndra\n",
      "Worldwide use of solar power and wind power continued to grow significantly in 2012. Solar electricity consumption increased by 58 percent, to 93 terawatt-hours (TWh). Use of wind power in 2012 increased by 18.1 percent, to 521.3 TWh. Global solar and wind energy installed capacities continued to expand even though new investments in these technologies declined during 2012. Worldwide investment in solar power in 2012 was $140.4 billion, an 11 percent decline from 2011, and wind power investment was down 10.1 percent, to $80.3 billion. But due to lower production costs for both technologies, total installed capacities grew sharply. This investment decline, but growth in installed capacity, may again occur in 2013. Analysts expect the market to triple by 2030. In 2015, investment in renewables exceeded fossils.\n",
      "The incentive to use 100% renewable energy, for electricity, transport, or even total primary energy supply globally, has been motivated by global warming and other ecological as well as economic concerns. The Intergovernmental Panel on Climate Change has said that there are few fundamental technological limits to integrating a portfolio of renewable energy technologies to meet most of total global energy demand. In reviewing 164 recent scenarios of future renewable energy growth, the report noted that the majority expected renewable sources to supply more than 17% of total energy by 2030, and 27% by 2050; the highest forecast projected 43% supplied by renewables by 2030 and 77% by 2050. Renewable energy use has grown much faster than even advocates anticipated. At the national level, at least 30 nations around the world already have renewable energy contributing more than 20% of energy supply. Also, Professors S. Pacala and Robert H. Socolow have developed a series of \"stabilization wedges\" that can allow us to maintain our quality of life while avoiding catastrophic climate change, and \"renewable energy sources,\" in aggregate, constitute the largest number of their \"wedges.\"\n",
      "Some countries are eliminating or reducing climate disrupting subsidies and Belgium, France, and Japan have phased out all subsidies for coal. Germany is reducing its coal subsidy. The subsidy dropped from $5.4 billion in 1989 to $2.8 billion in 2002, and in the process Germany lowered its coal use by 46 percent. China cut its coal subsidy from $750 million in 1993 to $240 million in 1995 and more recently has imposed a high-sulfur coal tax. However, the United States has been increasing its support for the fossil fuel and nuclear industries.\n",
      "-------------- ('Germany', 'NNP')\n",
      "-------------- GPE germany\n",
      "-------------- ('Germany', 'NNP')\n",
      "-------------- GPE germany\n",
      "Hydropower is produced in 150 countries, with the Asia-Pacific region generating 32 percent of global hydropower in 2010. China is the largest hydroelectricity producer, with 721 terawatt-hours of production in 2010, representing around 17 percent of domestic electricity use. There are now three hydroelectricity plants larger than 10 GW: the Three Gorges Dam in China, Itaipu Dam across the Brazil/Paraguay border, and Guri Dam in Venezuela. The cost of hydroelectricity is low, making it a competitive source of renewable electricity. The average cost of electricity from a hydro plant larger than 10 megawatts is 3 to 5 U.S. cents per kilowatt-hour.\n",
      "-------------- ('three', 'CD')\n",
      "-------------- ('Three', 'NNP')\n",
      "Mark Z. Jacobson, professor of civil and environmental engineering at Stanford University and director of its Atmosphere and Energy Program says producing all new energy with wind power, solar power, and hydropower by 2030 is feasible and existing energy supply arrangements could be replaced by 2050. Barriers to implementing the renewable energy plan are seen to be \"primarily social and political, not technological or economic\". Jacobson says that energy costs with a wind, solar, water system should be similar to today's energy costs.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "def getNodes(parent,target):\n",
    "    result = []\n",
    "    lalalala = 0\n",
    "    for node in parent:\n",
    "        if type(node) is nltk.Tree:\n",
    "            if node.label() == node:\n",
    "                print (\"======== Sentence =========\")\n",
    "#                 print (\"Sentence:\", \" \".join(node.leaves()))\n",
    "            else:\n",
    "                lalalala+=1\n",
    "#                 print (\"Label:\", node.label())\n",
    "#                 print (\"Leaves:\", node.leaves())\n",
    "            text = getNodes(node,target)\n",
    "            if text.lower() == target:\n",
    "                print (\"--------------\",node.label(),target)\n",
    "            result.append(text)\n",
    "            result.append(\" \")\n",
    "        else:\n",
    "#             print (\"Word:\", node)\n",
    "            if node[0].lower() == target:\n",
    "                print (\"--------------\",node)\n",
    "            result.append(node[0])\n",
    "            result.append(\" \")\n",
    "    result.pop()\n",
    "    return \"\".join(result)\n",
    "\n",
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "f2.close()\n",
    "doc_dict = json.loads(a)\n",
    "\n",
    "f4 = open(\"./assignment_group/project_files/training.json\")\n",
    "a = f4.readline()\n",
    "f4.close()\n",
    "trains = json.loads(a)\n",
    "print (len(trains))\n",
    "# print (trains[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for train in trains:\n",
    "    question = train[\"question\"]\n",
    "    paraid = train[\"answer_paragraph\"]\n",
    "    docid = train[\"docid\"]\n",
    "    answer = train[\"text\"]\n",
    "    para = doc_dict[docid][\"text\"][paraid]\n",
    "#     print (question,answer)\n",
    "    print(para)\n",
    "    temp_tag_para = pos_tag(word_tokenize(para))\n",
    "    root = nltk.ne_chunk(temp_tag_para)\n",
    "    getNodes(root,answer)\n",
    "    \n",
    "    count+=1\n",
    "    if count >100:\n",
    "        break\n",
    "\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasdddf\n",
      "asdfasdf\n",
      "[('The', 'O'), ('photoelectric', 'O'), ('effect', 'O'), ('is', 'O'), ('the', 'O'), ('emission', 'O'), ('of', 'O'), ('electrons', 'O'), ('(', 'O'), ('called', 'O'), ('``', 'O'), ('photoelectrons', 'O'), (\"''\", 'O'), (')', 'O'), ('from', 'O'), ('a', 'O'), ('surface', 'O'), ('when', 'O'), ('light', 'O'), ('is', 'O'), ('shone', 'O'), ('on', 'O'), ('it', 'O'), ('.', 'O'), ('It', 'O'), ('was', 'O'), ('first', 'O'), ('observed', 'O'), ('by', 'O'), ('Alexandre', 'PERSON'), ('Edmond', 'PERSON'), ('Becquerel', 'PERSON'), ('in', 'O'), ('1839', 'O'), (',', 'O'), ('although', 'O'), ('credit', 'O'), ('is', 'O'), ('usually', 'O'), ('reserved', 'O'), ('for', 'O'), ('Heinrich', 'PERSON'), ('Hertz', 'PERSON'), (',', 'O'), ('who', 'O'), ('published', 'O'), ('the', 'O'), ('first', 'O'), ('thorough', 'O'), ('investigation', 'O'), ('in', 'O'), ('1887', 'O'), ('.', 'O'), ('Another', 'O'), ('particularly', 'O'), ('thorough', 'O'), ('investigation', 'O'), ('was', 'O'), ('published', 'O'), ('by', 'O'), ('Philipp', 'PERSON'), ('Lenard', 'PERSON'), ('in', 'O'), ('1902', 'O'), ('.', 'O'), ('Einstein', 'PERSON'), (\"'s\", 'O'), ('1905', 'O'), ('paper', 'O'), ('discussing', 'O'), ('the', 'O'), ('effect', 'O'), ('in', 'O'), ('terms', 'O'), ('of', 'O'), ('light', 'O'), ('quanta', 'O'), ('would', 'O'), ('earn', 'O'), ('him', 'O'), ('the', 'O'), ('Nobel', 'O'), ('Prize', 'O'), ('in', 'O'), ('1921', 'O'), (',', 'O'), ('when', 'O'), ('his', 'O'), ('predictions', 'O'), ('had', 'O'), ('been', 'O'), ('confirmed', 'O'), ('by', 'O'), ('the', 'O'), ('experimental', 'O'), ('work', 'O'), ('of', 'O'), ('Robert', 'PERSON'), ('Andrews', 'PERSON'), ('Millikan', 'PERSON'), ('.', 'O'), ('The', 'O'), ('Nobel', 'O'), ('committee', 'O'), ('awarded', 'O'), ('the', 'O'), ('prize', 'O'), ('for', 'O'), ('his', 'O'), ('work', 'O'), ('on', 'O'), ('the', 'O'), ('photo-electric', 'O'), ('effect', 'O'), (',', 'O'), ('rather', 'O'), ('than', 'O'), ('relativity', 'O'), (',', 'O'), ('both', 'O'), ('because', 'O'), ('of', 'O'), ('a', 'O'), ('bias', 'O'), ('against', 'O'), ('purely', 'O'), ('theoretical', 'O'), ('physics', 'O'), ('not', 'O'), ('grounded', 'O'), ('in', 'O'), ('discovery', 'O'), ('or', 'O'), ('experiment', 'O'), (',', 'O'), ('and', 'O'), ('dissent', 'O'), ('amongst', 'O'), ('its', 'O'), ('members', 'O'), ('as', 'O'), ('to', 'O'), ('the', 'O'), ('actual', 'O'), ('proof', 'O'), ('that', 'O'), ('relativity', 'O'), ('was', 'O'), ('real', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('D:/websearch/stanford/stanford-ner-2015-12-09/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "                       ,'D:/websearch/stanford/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "print (\"asdfasdddf\")\n",
    "text = 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "text = \"Classical statistical mechanics requires the existence of h (but does not define its value\"\n",
    "text = \"The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\"\n",
    "text = \"The photoelectric effect is the emission of electrons (called \\\"photoelectrons\\\") from a surface when light is shone on it. It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887. Another particularly thorough investigation was published by Philipp Lenard in 1902. Einstein's 1905 paper discussing the effect in terms of light quanta would earn him the Nobel Prize in 1921, when his predictions had been confirmed by the experimental work of Robert Andrews Millikan. The Nobel committee awarded the prize for his work on the photo-electric effect, rather than relativity, both because of a bias against purely theoretical physics not grounded in discovery or experiment, and dissent amongst its members as to the actual proof that relativity was real.\"\n",
    "\n",
    "# text = 'While in France'\n",
    "print(\"asdfasdf\")\n",
    "\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asldkjfkas\n"
     ]
    }
   ],
   "source": [
    "print(\"asldkjfkas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasdf\n",
      "Loaded model 'en'\n",
      "Processing 1 texts\n",
      "The black-body problem was revisited in June 16,1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\n",
      "(June 16,1905, Rayleigh and Jeans, Einstein)\n",
      "<generator object at 0x0000026C2787B438>\n",
      "[June 16,1905, Rayleigh and Jeans, Einstein, The black-body problem, June, Rayleigh, Jeans, the one hand, Einstein, the other hand, classical electromagnetism, the observed spectrum]\n",
      "June 16,1905 PROPN NNP pobj\n",
      "June 16,1905 ------------- in ------ []\n",
      "Rayleigh and Jeans PROPN NNP nsubj\n",
      "Rayleigh and Jeans ------------- proved ------ [when, Rayleigh and Jeans, independently]\n",
      "Einstein PROPN NNP conj\n",
      "Einstein ------------- Rayleigh and Jeans ------ []\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\"\"\"A simple example of extracting relations between phrases and entities using\n",
    "spaCy's named entity recognizer and the dependency parse. Here, we extract\n",
    "money and currency values (entities labelled as MONEY) and then check the\n",
    "dependency tree to find the noun phrase they are referring to – for example:\n",
    "$9.4 million --> Net income.\n",
    "\n",
    "Compatible with: spaCy v2.0.0+\n",
    "\"\"\"\n",
    "import plac\n",
    "import spacy\n",
    "\n",
    "\n",
    "TEXTS = [\n",
    "    'Net income was $9.4 million compared to the prior year of $2.7 million.',\n",
    "    'Revenue exceeded twelve billion dollars, with a loss of $1b.',\n",
    "]\n",
    "\n",
    "\n",
    "TEXTS = [\"The black-body problem was revisited in June 16,1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @plac.annotations(\n",
    "#     model=(\"Model to load (needs parser and NER)\", \"positional\", None, str))\n",
    "def main():\n",
    "    model='en'\n",
    "    print(\"asdfasdf\")\n",
    "    nlp = spacy.load(model)\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "    print(\"Processing %d texts\" % len(TEXTS))\n",
    "\n",
    "    for text in TEXTS:\n",
    "        doc = nlp(text)\n",
    "        relations = extract_currency_relations(doc)\n",
    "        for r1, r2 in relations:\n",
    "            print('{:<10}\\t{}\\t{}'.format(r1.text, r2.ent_type_, r2.text))\n",
    "\n",
    "\n",
    "def extract_currency_relations(doc):\n",
    "    print(doc)\n",
    "    # merge entities and noun chunks into one token\n",
    "    print(doc.ents)\n",
    "    print(doc.noun_chunks)\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    print(spans)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = []\n",
    "    for money in doc:\n",
    "        if money.ent_type_ != \"\":\n",
    "            print(money.text, money.pos_,money.tag_, money.dep_)\n",
    "            print(money,\"-------------\",money.head,\"------\",list(money.head.lefts))\n",
    "#         print(money,money.ent_type_)\n",
    "    \n",
    "\n",
    "    \n",
    "#     for money in filter(lambda w: w.ent_type_ == 'MONEY', doc):\n",
    "#         if money.dep_ in ('attr', 'dobj'):\n",
    "#             subject = [w for w in money.head.lefts if w.dep_ == 'nsubj']\n",
    "#             if subject:\n",
    "#                 subject = subject[0]\n",
    "#                 relations.append((subject, money))\n",
    "#         elif money.dep_ == 'pobj' and money.head.dep_ == 'prep':\n",
    "#             relations.append((money.head.head, money))\n",
    "    return relations\n",
    "\n",
    "main()\n",
    "\n",
    "    # Expected output:\n",
    "    # Net income      MONEY   $9.4 million\n",
    "    # the prior year  MONEY   $2.7 million\n",
    "    # Revenue         MONEY   twelve billion dollars\n",
    "    # a loss          MONEY   1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43379\n",
      "The\n",
      "legal\n",
      "process\n",
      "to\n",
      "change\n",
      "the\n",
      "definition\n",
      "of\n",
      "the\n",
      "kilogram\n",
      "is\n",
      "already\n",
      "underway\n",
      ",\n",
      "but\n",
      "it\n",
      "had\n",
      "been\n",
      "decided\n",
      "that\n",
      "no\n",
      "final\n",
      "decision\n",
      "would\n",
      "be\n",
      "made\n",
      "before\n",
      "the\n",
      "next\n",
      "meeting\n",
      "of\n",
      "the\n",
      "General\n",
      "Conference\n",
      "on\n",
      "Weights\n",
      "and\n",
      "Measures\n",
      "in\n",
      "2011\n",
      ".\n",
      "(\n",
      "For\n",
      "more\n",
      "detailed\n",
      "information\n",
      ",\n",
      "see\n",
      "kilogram\n",
      "definitions\n",
      ".\n",
      ")\n",
      "The\n",
      "Planck\n",
      "constant\n",
      "is\n",
      "a\n",
      "leading\n",
      "contender\n",
      "to\n",
      "form\n",
      "the\n",
      "basis\n",
      "of\n",
      "the\n",
      "new\n",
      "definition\n",
      ",\n",
      "although\n",
      "not\n",
      "the\n",
      "only\n",
      "one\n",
      ".\n",
      "Possible\n",
      "new\n",
      "definitions\n",
      "include\n",
      "\"\n",
      "the\n",
      "mass\n",
      "of\n",
      "a\n",
      "body\n",
      "at\n",
      "rest\n",
      "whose\n",
      "equivalent\n",
      "energy\n",
      "equals\n",
      "the\n",
      "energy\n",
      "of\n",
      "photons\n",
      "whose\n",
      "frequencies\n",
      "sum\n",
      "to\n",
      "7050135639273999999\n",
      "♠\n",
      "135639274×1042\n",
      "Hz\n",
      "\"\n",
      ",\n",
      "or\n",
      "simply\n",
      "\"\n",
      "the\n",
      "kilogram\n",
      "is\n",
      "defined\n",
      "so\n",
      "that\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "equals\n",
      "6966662606895999999\n",
      "♠\n",
      "6.62606896×10−34\n",
      "J⋅s\n",
      "\"\n",
      ".\n",
      "There\n",
      "are\n",
      "a\n",
      "number\n",
      "of\n",
      "proposals\n",
      "to\n",
      "redefine\n",
      "certain\n",
      "of\n",
      "the\n",
      "SI\n",
      "base\n",
      "units\n",
      "in\n",
      "terms\n",
      "of\n",
      "fundamental\n",
      "physical\n",
      "constants\n",
      ".\n",
      "This\n",
      "has\n",
      "already\n",
      "been\n",
      "done\n",
      "for\n",
      "the\n",
      "metre\n",
      ",\n",
      "which\n",
      "is\n",
      "defined\n",
      "in\n",
      "terms\n",
      "of\n",
      "a\n",
      "fixed\n",
      "value\n",
      "of\n",
      "the\n",
      "speed\n",
      "of\n",
      "light\n",
      ".\n",
      "The\n",
      "most\n",
      "urgent\n",
      "unit\n",
      "on\n",
      "the\n",
      "list\n",
      "for\n",
      "redefinition\n",
      "is\n",
      "the\n",
      "kilogram\n",
      ",\n",
      "whose\n",
      "value\n",
      "has\n",
      "been\n",
      "fixed\n",
      "for\n",
      "all\n",
      "science\n",
      "(\n",
      "since\n",
      "1889\n",
      ")\n",
      "by\n",
      "the\n",
      "mass\n",
      "of\n",
      "a\n",
      "small\n",
      "cylinder\n",
      "of\n",
      "platinum\n",
      "–\n",
      "iridium\n",
      "alloy\n",
      "kept\n",
      "in\n",
      "a\n",
      "vault\n",
      "just\n",
      "outside\n",
      "Paris\n",
      ".\n",
      "While\n",
      "nobody\n",
      "knows\n",
      "if\n",
      "the\n",
      "mass\n",
      "of\n",
      "the\n",
      "International\n",
      "Prototype\n",
      "Kilogram\n",
      "has\n",
      "changed\n",
      "since\n",
      "1889\n",
      "–\n",
      "the\n",
      "value\n",
      "1\n",
      "kg\n",
      "of\n",
      "its\n",
      "mass\n",
      "expressed\n",
      "in\n",
      "kilograms\n",
      "is\n",
      "by\n",
      "definition\n",
      "unchanged\n",
      "and\n",
      "therein\n",
      "lies\n",
      "one\n",
      "of\n",
      "the\n",
      "problems\n",
      "–\n",
      "it\n",
      "is\n",
      "known\n",
      "that\n",
      "over\n",
      "such\n",
      "a\n",
      "timescale\n",
      "the\n",
      "many\n",
      "similar\n",
      "Pt\n",
      "–\n",
      "Ir\n",
      "alloy\n",
      "cylinders\n",
      "kept\n",
      "in\n",
      "national\n",
      "laboratories\n",
      "around\n",
      "the\n",
      "world\n",
      ",\n",
      "have\n",
      "changed\n",
      "their\n",
      "relative\n",
      "mass\n",
      "by\n",
      "several\n",
      "tens\n",
      "of\n",
      "parts\n",
      "per\n",
      "million\n",
      ",\n",
      "however\n",
      "carefully\n",
      "they\n",
      "are\n",
      "stored\n",
      ",\n",
      "and\n",
      "the\n",
      "more\n",
      "so\n",
      "the\n",
      "more\n",
      "they\n",
      "have\n",
      "been\n",
      "taken\n",
      "out\n",
      "and\n",
      "used\n",
      "as\n",
      "mass\n",
      "standards\n",
      ".\n",
      "A\n",
      "change\n",
      "of\n",
      "several\n",
      "tens\n",
      "of\n",
      "micrograms\n",
      "in\n",
      "one\n",
      "kilogram\n",
      "is\n",
      "equivalent\n",
      "to\n",
      "the\n",
      "current\n",
      "uncertainty\n",
      "in\n",
      "the\n",
      "value\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "in\n",
      "SI\n",
      "units\n",
      ".\n",
      "where\n",
      "the\n",
      "uncertainty\n",
      "is\n",
      "given\n",
      "as\n",
      "the\n",
      "standard\n",
      "deviation\n",
      "of\n",
      "the\n",
      "measured\n",
      "value\n",
      "from\n",
      "its\n",
      "expected\n",
      "value\n",
      ".\n",
      "There\n",
      "are\n",
      "a\n",
      "number\n",
      "of\n",
      "other\n",
      "such\n",
      "pairs\n",
      "of\n",
      "physically\n",
      "measurable\n",
      "values\n",
      "which\n",
      "obey\n",
      "a\n",
      "similar\n",
      "rule\n",
      ".\n",
      "One\n",
      "example\n",
      "is\n",
      "time\n",
      "vs.\n",
      "energy\n",
      ".\n",
      "The\n",
      "either\n",
      "-\n",
      "or\n",
      "nature\n",
      "of\n",
      "uncertainty\n",
      "forces\n",
      "measurement\n",
      "attempts\n",
      "to\n",
      "choose\n",
      "between\n",
      "trade\n",
      "offs\n",
      ",\n",
      "and\n",
      "given\n",
      "that\n",
      "they\n",
      "are\n",
      "quanta\n",
      ",\n",
      "the\n",
      "trade\n",
      "offs\n",
      "often\n",
      "take\n",
      "the\n",
      "form\n",
      "of\n",
      "either\n",
      "-\n",
      "or\n",
      "(\n",
      "as\n",
      "in\n",
      "Fourier\n",
      "analysis\n",
      ")\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "compromises\n",
      "and\n",
      "gray\n",
      "areas\n",
      "of\n",
      "time\n",
      "series\n",
      "analysis\n",
      ".\n",
      "Classical\n",
      "statistical\n",
      "mechanics\n",
      "requires\n",
      "the\n",
      "existence\n",
      "of\n",
      "h\n",
      "(\n",
      "but\n",
      "does\n",
      "not\n",
      "define\n",
      "its\n",
      "value\n",
      ")\n",
      ".\n",
      "Eventually\n",
      ",\n",
      "following\n",
      "upon\n",
      "Planck\n",
      "'s\n",
      "discovery\n",
      ",\n",
      "it\n",
      "was\n",
      "recognized\n",
      "that\n",
      "physical\n",
      "action\n",
      "can\n",
      "not\n",
      "take\n",
      "on\n",
      "an\n",
      "arbitrary\n",
      "value\n",
      ".\n",
      "Instead\n",
      ",\n",
      "it\n",
      "must\n",
      "be\n",
      "some\n",
      "multiple\n",
      "of\n",
      "a\n",
      "very\n",
      "small\n",
      "quantity\n",
      ",\n",
      "the\n",
      "\"\n",
      "quantum\n",
      "of\n",
      "action\n",
      "\"\n",
      ",\n",
      "now\n",
      "called\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ".\n",
      "Classical\n",
      "physics\n",
      "can\n",
      "not\n",
      "explain\n",
      "this\n",
      "fact\n",
      ".\n",
      "In\n",
      "many\n",
      "cases\n",
      ",\n",
      "such\n",
      "as\n",
      "for\n",
      "monochromatic\n",
      "light\n",
      "or\n",
      "for\n",
      "atoms\n",
      ",\n",
      "this\n",
      "quantum\n",
      "of\n",
      "action\n",
      "also\n",
      "implies\n",
      "that\n",
      "only\n",
      "certain\n",
      "energy\n",
      "levels\n",
      "are\n",
      "allowed\n",
      ",\n",
      "and\n",
      "values\n",
      "in\n",
      "between\n",
      "are\n",
      "forbidden\n",
      ".\n",
      "Niels\n",
      "Bohr\n",
      "introduced\n",
      "the\n",
      "first\n",
      "quantized\n",
      "model\n",
      "of\n",
      "the\n",
      "atom\n",
      "in\n",
      "1913\n",
      "1913 DATE\n",
      "In\n",
      "the\n",
      "last\n",
      "years\n",
      "of\n",
      "the\n",
      "nineteenth\n",
      "century\n",
      ",\n",
      "Planck\n",
      "was\n",
      "investigating\n",
      "the\n",
      "problem\n",
      "of\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "first\n",
      "posed\n",
      "by\n",
      "Kirchhoff\n",
      "Kirchhoff PERSON\n",
      "Bohr\n",
      "also\n",
      "introduced\n",
      "the\n",
      "quantity\n",
      ",\n",
      "now\n",
      "known\n",
      "as\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      ",\n",
      "as\n",
      "the\n",
      "quantum\n",
      "of\n",
      "angular\n",
      "momentum\n",
      ".\n",
      "At\n",
      "first\n",
      ",\n",
      "Bohr\n",
      "thought\n",
      "that\n",
      "this\n",
      "was\n",
      "the\n",
      "angular\n",
      "momentum\n",
      "of\n",
      "each\n",
      "electron\n",
      "in\n",
      "an\n",
      "atom\n",
      ":\n",
      "this\n",
      "proved\n",
      "incorrect\n",
      "and\n",
      ",\n",
      "despite\n",
      "developments\n",
      "by\n",
      "Sommerfeld\n",
      "and\n",
      "others\n",
      ",\n",
      "an\n",
      "accurate\n",
      "description\n",
      "of\n",
      "the\n",
      "electron\n",
      "angular\n",
      "momentum\n",
      "proved\n",
      "beyond\n",
      "the\n",
      "Bohr\n",
      "model\n",
      ".\n",
      "The\n",
      "correct\n",
      "quantization\n",
      "rules\n",
      "for\n",
      "electrons\n",
      "–\n",
      "in\n",
      "which\n",
      "the\n",
      "energy\n",
      "reduces\n",
      "to\n",
      "the\n",
      "Bohr\n",
      "model\n",
      "equation\n",
      "in\n",
      "the\n",
      "case\n",
      "of\n",
      "the\n",
      "hydrogen\n",
      "atom\n",
      "–\n",
      "were\n",
      "given\n",
      "by\n",
      "Heisenberg\n",
      "'s\n",
      "matrix\n",
      "mechanics\n",
      "in\n",
      "1925\n",
      "and\n",
      "the\n",
      "Schrödinger\n",
      "Schrödinger ORG\n",
      "Classical\n",
      "statistical\n",
      "mechanics\n",
      "requires\n",
      "the\n",
      "existence\n",
      "of\n",
      "h\n",
      "(\n",
      "but\n",
      "does\n",
      "not\n",
      "define\n",
      "its\n",
      "value\n",
      ")\n",
      ".\n",
      "Eventually\n",
      ",\n",
      "following\n",
      "upon\n",
      "Planck\n",
      "'s\n",
      "discovery\n",
      ",\n",
      "it\n",
      "was\n",
      "recognized\n",
      "that\n",
      "physical\n",
      "action\n",
      "can\n",
      "not\n",
      "take\n",
      "on\n",
      "an\n",
      "arbitrary\n",
      "value\n",
      ".\n",
      "Instead\n",
      ",\n",
      "it\n",
      "must\n",
      "be\n",
      "some\n",
      "multiple\n",
      "of\n",
      "a\n",
      "very\n",
      "small\n",
      "quantity\n",
      ",\n",
      "the\n",
      "\"\n",
      "quantum\n",
      "of\n",
      "action\n",
      "\"\n",
      ",\n",
      "now\n",
      "called\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ".\n",
      "Classical\n",
      "physics\n",
      "can\n",
      "not\n",
      "explain\n",
      "this\n",
      "fact\n",
      ".\n",
      "In\n",
      "many\n",
      "cases\n",
      ",\n",
      "such\n",
      "as\n",
      "for\n",
      "monochromatic\n",
      "light\n",
      "or\n",
      "for\n",
      "atoms\n",
      ",\n",
      "this\n",
      "quantum\n",
      "of\n",
      "action\n",
      "also\n",
      "implies\n",
      "that\n",
      "only\n",
      "certain\n",
      "energy\n",
      "levels\n",
      "are\n",
      "allowed\n",
      ",\n",
      "and\n",
      "values\n",
      "in\n",
      "between\n",
      "are\n",
      "forbidden\n",
      ".\n",
      "Classical\n",
      "statistical\n",
      "mechanics\n",
      "requires\n",
      "the\n",
      "existence\n",
      "of\n",
      "h\n",
      "(\n",
      "but\n",
      "does\n",
      "not\n",
      "define\n",
      "its\n",
      "value\n",
      ")\n",
      ".\n",
      "Eventually\n",
      ",\n",
      "following\n",
      "upon\n",
      "Planck\n",
      "'s\n",
      "discovery\n",
      ",\n",
      "it\n",
      "was\n",
      "recognized\n",
      "that\n",
      "physical\n",
      "action\n",
      "can\n",
      "not\n",
      "take\n",
      "on\n",
      "an\n",
      "arbitrary\n",
      "value\n",
      ".\n",
      "Instead\n",
      ",\n",
      "it\n",
      "must\n",
      "be\n",
      "some\n",
      "multiple\n",
      "of\n",
      "a\n",
      "very\n",
      "small\n",
      "quantity\n",
      ",\n",
      "the\n",
      "\"\n",
      "quantum\n",
      "of\n",
      "action\n",
      "\"\n",
      ",\n",
      "now\n",
      "called\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ".\n",
      "Classical\n",
      "physics\n",
      "can\n",
      "not\n",
      "explain\n",
      "this\n",
      "fact\n",
      ".\n",
      "In\n",
      "many\n",
      "cases\n",
      ",\n",
      "such\n",
      "as\n",
      "for\n",
      "monochromatic\n",
      "light\n",
      "or\n",
      "for\n",
      "atoms\n",
      ",\n",
      "this\n",
      "quantum\n",
      "of\n",
      "action\n",
      "also\n",
      "implies\n",
      "that\n",
      "only\n",
      "certain\n",
      "energy\n",
      "levels\n",
      "are\n",
      "allowed\n",
      ",\n",
      "and\n",
      "values\n",
      "in\n",
      "between\n",
      "are\n",
      "forbidden\n",
      ".\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "540\n",
      "THz\n",
      "(\n",
      "7014540000000000000\n",
      "♠\n",
      "540×1012\n",
      "Hz\n",
      ")\n",
      ".\n",
      "Each\n",
      "photon\n",
      "has\n",
      "an\n",
      "energy\n",
      "E\n",
      "=\n",
      "hf\n",
      "=\n",
      "6981358000000000000\n",
      "♠\n",
      "3.58×10−19\n",
      "J.\n",
      "That\n",
      "is\n",
      "a\n",
      "very\n",
      "small\n",
      "amount\n",
      "of\n",
      "energy\n",
      "in\n",
      "terms\n",
      "of\n",
      "everyday\n",
      "experience\n",
      ",\n",
      "but\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "with\n",
      "a\n",
      "\"\n",
      "quantum\n",
      "\"\n",
      "or\n",
      "minimal\n",
      "element\n",
      "of\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "electromagnetic\n",
      "wave\n",
      "itself\n",
      ".\n",
      "The\n",
      "light\n",
      "quantum\n",
      "behaved\n",
      "in\n",
      "some\n",
      "respects\n",
      "as\n",
      "an\n",
      "electrically\n",
      "neutral\n",
      "particle\n",
      ",\n",
      "as\n",
      "opposed\n",
      "to\n",
      "an\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "It\n",
      "was\n",
      "eventually\n",
      "called\n",
      "the\n",
      "photon\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      "1839 DATE\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      "1911 DATE\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "'s\n",
      "1905\n",
      "paper\n",
      "discussing\n",
      "the\n",
      "effect\n",
      "in\n",
      "terms\n",
      "of\n",
      "light\n",
      "quanta\n",
      "would\n",
      "earn\n",
      "him\n",
      "the\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "1921\n",
      ",\n",
      "when\n",
      "his\n",
      "predictions\n",
      "had\n",
      "been\n",
      "confirmed\n",
      "by\n",
      "the\n",
      "experimental\n",
      "work\n",
      "of\n",
      "Robert\n",
      "Andrews\n",
      "Millikan\n",
      ".\n",
      "The\n",
      "Nobel\n",
      "committee\n",
      "awarded\n",
      "the\n",
      "prize\n",
      "for\n",
      "his\n",
      "work\n",
      "on\n",
      "the\n",
      "photo\n",
      "-\n",
      "electric\n",
      "effect\n",
      ",\n",
      "rather\n",
      "than\n",
      "relativity\n",
      ",\n",
      "both\n",
      "because\n",
      "of\n",
      "a\n",
      "bias\n",
      "against\n",
      "purely\n",
      "theoretical\n",
      "physics\n",
      "not\n",
      "grounded\n",
      "in\n",
      "discovery\n",
      "or\n",
      "experiment\n",
      ",\n",
      "and\n",
      "dissent\n",
      "amongst\n",
      "its\n",
      "members\n",
      "as\n",
      "to\n",
      "the\n",
      "actual\n",
      "proof\n",
      "that\n",
      "relativity\n",
      "was\n",
      "real\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "'s\n",
      "1905\n",
      "paper\n",
      "discussing\n",
      "the\n",
      "effect\n",
      "in\n",
      "terms\n",
      "of\n",
      "light\n",
      "quanta\n",
      "would\n",
      "earn\n",
      "him\n",
      "the\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "1921\n",
      ",\n",
      "when\n",
      "his\n",
      "predictions\n",
      "had\n",
      "been\n",
      "confirmed\n",
      "by\n",
      "the\n",
      "experimental\n",
      "work\n",
      "of\n",
      "Robert\n",
      "Andrews\n",
      "Millikan\n",
      ".\n",
      "The\n",
      "Nobel\n",
      "committee\n",
      "awarded\n",
      "the\n",
      "prize\n",
      "for\n",
      "his\n",
      "work\n",
      "on\n",
      "the\n",
      "photo\n",
      "-\n",
      "electric\n",
      "effect\n",
      ",\n",
      "rather\n",
      "than\n",
      "relativity\n",
      ",\n",
      "both\n",
      "because\n",
      "of\n",
      "a\n",
      "bias\n",
      "against\n",
      "purely\n",
      "theoretical\n",
      "physics\n",
      "not\n",
      "grounded\n",
      "in\n",
      "discovery\n",
      "or\n",
      "experiment\n",
      ",\n",
      "and\n",
      "dissent\n",
      "amongst\n",
      "its\n",
      "members\n",
      "as\n",
      "to\n",
      "the\n",
      "actual\n",
      "proof\n",
      "that\n",
      "relativity\n",
      "was\n",
      "real\n",
      ".\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      ".\n",
      "They\n",
      "contributed\n",
      "greatly\n",
      "(\n",
      "along\n",
      "with\n",
      "Einstein\n",
      "'s\n",
      "work\n",
      "on\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      ")\n",
      "to\n",
      "convincing\n",
      "physicists\n",
      "that\n",
      "Planck\n",
      "'s\n",
      "postulate\n",
      "of\n",
      "quantized\n",
      "energy\n",
      "levels\n",
      "was\n",
      "more\n",
      "than\n",
      "a\n",
      "mere\n",
      "mathematical\n",
      "formalism\n",
      ".\n",
      "The\n",
      "very\n",
      "first\n",
      "Solvay\n",
      "Conference\n",
      "in\n",
      "1911\n",
      "was\n",
      "devoted\n",
      "to\n",
      "\"\n",
      "the\n",
      "theory\n",
      "of\n",
      "radiation\n",
      "and\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "Max\n",
      "Planck\n",
      "received\n",
      "the\n",
      "1918\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "Physics\n",
      "\"\n",
      "in\n",
      "recognition\n",
      "of\n",
      "the\n",
      "services\n",
      "he\n",
      "rendered\n",
      "to\n",
      "the\n",
      "advancement\n",
      "of\n",
      "Physics\n",
      "by\n",
      "his\n",
      "discovery\n",
      "of\n",
      "energy\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "The\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      "emitted\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "have\n",
      "a\n",
      "certain\n",
      "kinetic\n",
      "energy\n",
      ",\n",
      "which\n",
      "can\n",
      "be\n",
      "measured\n",
      ".\n",
      "This\n",
      "kinetic\n",
      "energy\n",
      "(\n",
      "for\n",
      "each\n",
      "photoelectron\n",
      ")\n",
      "is\n",
      "independent\n",
      "of\n",
      "the\n",
      "intensity\n",
      "of\n",
      "the\n",
      "light\n",
      ",\n",
      "but\n",
      "depends\n",
      "linearly\n",
      "on\n",
      "the\n",
      "frequency\n",
      ";\n",
      "and\n",
      "if\n",
      "the\n",
      "frequency\n",
      "is\n",
      "too\n",
      "low\n",
      "(\n",
      "corresponding\n",
      "to\n",
      "a\n",
      "photon\n",
      "energy\n",
      "that\n",
      "is\n",
      "less\n",
      "than\n",
      "the\n",
      "work\n",
      "function\n",
      "of\n",
      "the\n",
      "material\n",
      ")\n",
      ",\n",
      "no\n",
      "photoelectrons\n",
      "are\n",
      "emitted\n",
      "at\n",
      "all\n",
      ",\n",
      "unless\n",
      "a\n",
      "plurality\n",
      "of\n",
      "photons\n",
      ",\n",
      "whose\n",
      "energetic\n",
      "sum\n",
      "is\n",
      "greater\n",
      "than\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "photoelectrons\n",
      ",\n",
      "acts\n",
      "virtually\n",
      "simultaneously\n",
      "(\n",
      "multiphoton\n",
      "effect\n",
      ")\n",
      " \n",
      "Assuming\n",
      "the\n",
      "frequency\n",
      "is\n",
      "high\n",
      "enough\n",
      "to\n",
      "cause\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      ",\n",
      "a\n",
      "rise\n",
      "in\n",
      "intensity\n",
      "of\n",
      "the\n",
      "light\n",
      "source\n",
      "causes\n",
      "more\n",
      "photoelectrons\n",
      "to\n",
      "be\n",
      "emitted\n",
      "with\n",
      "the\n",
      "same\n",
      "kinetic\n",
      "energy\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "same\n",
      "number\n",
      "of\n",
      "photoelectrons\n",
      "to\n",
      "be\n",
      "emitted\n",
      "with\n",
      "higher\n",
      "kinetic\n",
      "energy\n",
      ".\n",
      "The\n",
      "Bohr\n",
      "magneton\n",
      "and\n",
      "the\n",
      "nuclear\n",
      "magneton\n",
      "are\n",
      "units\n",
      "which\n",
      "are\n",
      "used\n",
      "to\n",
      "describe\n",
      "the\n",
      "magnetic\n",
      "properties\n",
      "of\n",
      "the\n",
      "electron\n",
      "and\n",
      "atomic\n",
      "nuclei\n",
      "respectively\n",
      ".\n",
      "The\n",
      "Bohr\n",
      "magneton\n",
      "is\n",
      "the\n",
      "magnetic\n",
      "moment\n",
      "which\n",
      "would\n",
      "be\n",
      "expected\n",
      "for\n",
      "an\n",
      "electron\n",
      "if\n",
      "it\n",
      "behaved\n",
      "as\n",
      "a\n",
      "spinning\n",
      "charge\n",
      "according\n",
      "to\n",
      "classical\n",
      "electrodynamics\n",
      ".\n",
      "It\n",
      "is\n",
      "defined\n",
      "in\n",
      "terms\n",
      "of\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      ",\n",
      "the\n",
      "elementary\n",
      "charge\n",
      "and\n",
      "the\n",
      "electron\n",
      "mass\n",
      ",\n",
      "all\n",
      "of\n",
      "which\n",
      "depend\n",
      "on\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ":\n",
      "the\n",
      "final\n",
      "dependence\n",
      "on\n",
      "h1/2\n",
      "(\n",
      "r2\n",
      ">\n",
      "0.995\n",
      ")\n",
      "can\n",
      "be\n",
      "found\n",
      "by\n",
      "expanding\n",
      "the\n",
      "variables\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "Einstein ORG\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "540\n",
      "THz\n",
      "(\n",
      "7014540000000000000\n",
      "♠\n",
      "540×1012\n",
      "Hz\n",
      ")\n",
      ".\n",
      "Each\n",
      "photon\n",
      "has\n",
      "an\n",
      "energy\n",
      "E\n",
      "=\n",
      "hf\n",
      "=\n",
      "6981358000000000000\n",
      "♠\n",
      "3.58×10−19\n",
      "J.\n",
      "That\n",
      "is\n",
      "a\n",
      "very\n",
      "small\n",
      "amount\n",
      "of\n",
      "energy\n",
      "in\n",
      "terms\n",
      "of\n",
      "everyday\n",
      "experience\n",
      ",\n",
      "but\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "'s\n",
      "1905\n",
      "paper\n",
      "discussing\n",
      "the\n",
      "effect\n",
      "in\n",
      "terms\n",
      "of\n",
      "light\n",
      "quanta\n",
      "would\n",
      "earn\n",
      "him\n",
      "the\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "1921\n",
      ",\n",
      "when\n",
      "his\n",
      "predictions\n",
      "had\n",
      "been\n",
      "confirmed\n",
      "by\n",
      "the\n",
      "experimental\n",
      "work\n",
      "of\n",
      "Robert\n",
      "Andrews\n",
      "Millikan\n",
      ".\n",
      "The\n",
      "Nobel\n",
      "committee\n",
      "awarded\n",
      "the\n",
      "prize\n",
      "for\n",
      "his\n",
      "work\n",
      "on\n",
      "the\n",
      "photo\n",
      "-\n",
      "electric\n",
      "effect\n",
      ",\n",
      "rather\n",
      "than\n",
      "relativity\n",
      ",\n",
      "both\n",
      "because\n",
      "of\n",
      "a\n",
      "bias\n",
      "against\n",
      "purely\n",
      "theoretical\n",
      "physics\n",
      "not\n",
      "grounded\n",
      "in\n",
      "discovery\n",
      "or\n",
      "experiment\n",
      ",\n",
      "and\n",
      "dissent\n",
      "amongst\n",
      "its\n",
      "members\n",
      "as\n",
      "to\n",
      "the\n",
      "actual\n",
      "proof\n",
      "that\n",
      "relativity\n",
      "was\n",
      "real\n",
      ".\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      "1911 DATE\n",
      "In\n",
      "the\n",
      "last\n",
      "years\n",
      "of\n",
      "the\n",
      "nineteenth\n",
      "century\n",
      ",\n",
      "Planck\n",
      "was\n",
      "investigating\n",
      "the\n",
      "problem\n",
      "of\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "first\n",
      "posed\n",
      "by\n",
      "Kirchhoff\n",
      "some\n",
      "forty\n",
      "years\n",
      "earlier\n",
      ".\n",
      "It\n",
      "is\n",
      "well\n",
      "known\n",
      "that\n",
      "hot\n",
      "objects\n",
      "glow\n",
      ",\n",
      "and\n",
      "that\n",
      "hotter\n",
      "objects\n",
      "glow\n",
      "brighter\n",
      "than\n",
      "cooler\n",
      "ones\n",
      ".\n",
      "The\n",
      "electromagnetic\n",
      "field\n",
      "obeys\n",
      "laws\n",
      "of\n",
      "motion\n",
      "similarly\n",
      "to\n",
      "a\n",
      "mass\n",
      "on\n",
      "a\n",
      "spring\n",
      ",\n",
      "and\n",
      "can\n",
      "come\n",
      "to\n",
      "thermal\n",
      "equilibrium\n",
      "with\n",
      "hot\n",
      "atoms\n",
      ".\n",
      "The\n",
      "hot\n",
      "object\n",
      "in\n",
      "equilibrium\n",
      "with\n",
      "light\n",
      "absorbs\n",
      "just\n",
      "as\n",
      "much\n",
      "light\n",
      "as\n",
      "it\n",
      "emits\n",
      ".\n",
      "If\n",
      "the\n",
      "object\n",
      "is\n",
      "black\n",
      ",\n",
      "meaning\n",
      "it\n",
      "absorbs\n",
      "all\n",
      "the\n",
      "light\n",
      "that\n",
      "hits\n",
      "it\n",
      ",\n",
      "then\n",
      "its\n",
      "thermal\n",
      "light\n",
      "emission\n",
      "is\n",
      "maximized\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "Einstein ORG\n",
      "The\n",
      "assumption\n",
      "that\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "is\n",
      "thermal\n",
      "leads\n",
      "to\n",
      "an\n",
      "accurate\n",
      "prediction\n",
      ":\n",
      "the\n",
      "total\n",
      "amount\n",
      "of\n",
      "emitted\n",
      "energy\n",
      "goes\n",
      "up\n",
      "with\n",
      "the\n",
      "temperature\n",
      "according\n",
      "to\n",
      "a\n",
      "definite\n",
      "rule\n",
      ",\n",
      "the\n",
      "Stefan\n",
      "–\n",
      "Boltzmann\n",
      "law\n",
      "(\n",
      "1879–84\n",
      ")\n",
      ".\n",
      "But\n",
      "it\n",
      "was\n",
      "also\n",
      "known\n",
      "that\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "given\n",
      "off\n",
      "by\n",
      "a\n",
      "hot\n",
      "object\n",
      "changes\n",
      "with\n",
      "the\n",
      "temperature\n",
      ",\n",
      "so\n",
      "that\n",
      "\"\n",
      "white\n",
      "hot\n",
      "\"\n",
      "is\n",
      "hotter\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "proposed\n",
      "an\n",
      "approximation\n",
      "for\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "the\n",
      "object\n",
      ",\n",
      "which\n",
      "was\n",
      "correct\n",
      "at\n",
      "high\n",
      "frequencies\n",
      "(\n",
      "short\n",
      "wavelength\n",
      ")\n",
      "but\n",
      "not\n",
      "at\n",
      "low\n",
      "frequencies\n",
      "(\n",
      "long\n",
      "wavelength\n",
      ")\n",
      ".\n",
      "It\n",
      "still\n",
      "was\n",
      "not\n",
      "clear\n",
      "why\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "hot\n",
      "object\n",
      "had\n",
      "the\n",
      "form\n",
      "that\n",
      "it\n",
      "has\n",
      "(\n",
      "see\n",
      "diagram\n",
      ")\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "with\n",
      "a\n",
      "\"\n",
      "quantum\n",
      "\"\n",
      "or\n",
      "minimal\n",
      "element\n",
      "of\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "electromagnetic\n",
      "wave\n",
      "itself\n",
      ".\n",
      "The\n",
      "light\n",
      "quantum\n",
      "behaved\n",
      "in\n",
      "some\n",
      "respects\n",
      "as\n",
      "an\n",
      "electrically\n",
      "neutral\n",
      "particle\n",
      ",\n",
      "as\n",
      "opposed\n",
      "to\n",
      "an\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "It\n",
      "was\n",
      "eventually\n",
      "called\n",
      "the\n",
      "photon\n",
      ".\n",
      "Classical\n",
      "statistical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanics\n",
      "requires\n",
      "the\n",
      "existence\n",
      "of\n",
      "h\n",
      "(\n",
      "but\n",
      "does\n",
      "not\n",
      "define\n",
      "its\n",
      "value\n",
      ")\n",
      ".\n",
      "Eventually\n",
      ",\n",
      "following\n",
      "upon\n",
      "Planck\n",
      "'s\n",
      "discovery\n",
      ",\n",
      "it\n",
      "was\n",
      "recognized\n",
      "that\n",
      "physical\n",
      "action\n",
      "can\n",
      "not\n",
      "take\n",
      "on\n",
      "an\n",
      "arbitrary\n",
      "value\n",
      ".\n",
      "Instead\n",
      ",\n",
      "it\n",
      "must\n",
      "be\n",
      "some\n",
      "multiple\n",
      "of\n",
      "a\n",
      "very\n",
      "small\n",
      "quantity\n",
      ",\n",
      "the\n",
      "\"\n",
      "quantum\n",
      "of\n",
      "action\n",
      "\"\n",
      ",\n",
      "now\n",
      "called\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ".\n",
      "Classical\n",
      "physics\n",
      "can\n",
      "not\n",
      "explain\n",
      "this\n",
      "fact\n",
      ".\n",
      "In\n",
      "many\n",
      "cases\n",
      ",\n",
      "such\n",
      "as\n",
      "for\n",
      "monochromatic\n",
      "light\n",
      "or\n",
      "for\n",
      "atoms\n",
      ",\n",
      "this\n",
      "quantum\n",
      "of\n",
      "action\n",
      "also\n",
      "implies\n",
      "that\n",
      "only\n",
      "certain\n",
      "energy\n",
      "levels\n",
      "are\n",
      "allowed\n",
      ",\n",
      "and\n",
      "values\n",
      "in\n",
      "between\n",
      "are\n",
      "forbidden\n",
      ".\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "Prior\n",
      "to\n",
      "Einstein\n",
      "'s\n",
      "paper\n",
      ",\n",
      "electromagnetic\n",
      "radiation\n",
      "such\n",
      "as\n",
      "visible\n",
      "light\n",
      "was\n",
      "considered\n",
      "to\n",
      "behave\n",
      "as\n",
      "a\n",
      "wave\n",
      ":\n",
      "hence\n",
      "the\n",
      "use\n",
      "of\n",
      "the\n",
      "terms\n",
      "\"\n",
      "frequency\n",
      "\"\n",
      "and\n",
      "\"\n",
      "wavelength\n",
      "\"\n",
      "to\n",
      "characterise\n",
      "different\n",
      "types\n",
      "of\n",
      "radiation\n",
      ".\n",
      "The\n",
      "energy\n",
      "transferred\n",
      "by\n",
      "a\n",
      "wave\n",
      "in\n",
      "a\n",
      "given\n",
      "time\n",
      "is\n",
      "called\n",
      "its\n",
      "intensity\n",
      ".\n",
      "The\n",
      "light\n",
      "from\n",
      "a\n",
      "theatre\n",
      "spotlight\n",
      "is\n",
      "more\n",
      "intense\n",
      "than\n",
      "the\n",
      "light\n",
      "from\n",
      "a\n",
      "domestic\n",
      "lightbulb\n",
      ";\n",
      "that\n",
      "is\n",
      "to\n",
      "say\n",
      "that\n",
      "the\n",
      "spotlight\n",
      "gives\n",
      "out\n",
      "more\n",
      "energy\n",
      "per\n",
      "unit\n",
      "time\n",
      "and\n",
      "per\n",
      "unit\n",
      "space(and\n",
      "hence\n",
      "consumes\n",
      "more\n",
      "electricity\n",
      ")\n",
      "than\n",
      "the\n",
      "ordinary\n",
      "bulb\n",
      ",\n",
      "even\n",
      "though\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "might\n",
      "be\n",
      "very\n",
      "similar\n",
      ".\n",
      "Other\n",
      "waves\n",
      ",\n",
      "such\n",
      "as\n",
      "sound\n",
      "or\n",
      "the\n",
      "waves\n",
      "crashing\n",
      "against\n",
      "a\n",
      "seafront\n",
      ",\n",
      "also\n",
      "have\n",
      "their\n",
      "own\n",
      "intensity\n",
      ".\n",
      "However\n",
      ",\n",
      "the\n",
      "energy\n",
      "account\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "did\n",
      "n't\n",
      "seem\n",
      "to\n",
      "agree\n",
      "with\n",
      "the\n",
      "wave\n",
      "description\n",
      "of\n",
      "light\n",
      ".\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "540\n",
      "THz\n",
      "(\n",
      "7014540000000000000\n",
      "♠\n",
      "540×1012\n",
      "Hz\n",
      ")\n",
      ".\n",
      "Each\n",
      "photon\n",
      "has\n",
      "an\n",
      "energy\n",
      "E\n",
      "=\n",
      "hf\n",
      "=\n",
      "6981358000000000000\n",
      "♠\n",
      "3.58×10−19\n",
      "J.\n",
      "That\n",
      "is\n",
      "a\n",
      "very\n",
      "small\n",
      "amount\n",
      "of\n",
      "energy\n",
      "in\n",
      "terms\n",
      "of\n",
      "everyday\n",
      "experience\n",
      ",\n",
      "but\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      ".\n",
      "They\n",
      "contributed\n",
      "greatly\n",
      "(\n",
      "along\n",
      "with\n",
      "Einstein\n",
      "'s\n",
      "work\n",
      "on\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      ")\n",
      "to\n",
      "convincing\n",
      "physicists\n",
      "that\n",
      "Planck\n",
      "'s\n",
      "postulate\n",
      "of\n",
      "quantized\n",
      "energy\n",
      "levels\n",
      "was\n",
      "more\n",
      "than\n",
      "a\n",
      "mere\n",
      "mathematical\n",
      "formalism\n",
      ".\n",
      "The\n",
      "very\n",
      "first\n",
      "Solvay\n",
      "Conference\n",
      "in\n",
      "1911\n",
      "was\n",
      "devoted\n",
      "to\n",
      "\"\n",
      "the\n",
      "theory\n",
      "of\n",
      "radiation\n",
      "and\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "Max\n",
      "Planck\n",
      "received\n",
      "the\n",
      "1918\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "Physics\n",
      "\"\n",
      "in\n",
      "recognition\n",
      "of\n",
      "the\n",
      "services\n",
      "he\n",
      "rendered\n",
      "to\n",
      "the\n",
      "advancement\n",
      "of\n",
      "Physics\n",
      "by\n",
      "his\n",
      "discovery\n",
      "of\n",
      "energy\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "Einstein ORG\n",
      "The\n",
      "assumption\n",
      "that\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "is\n",
      "thermal\n",
      "leads\n",
      "to\n",
      "an\n",
      "accurate\n",
      "prediction\n",
      ":\n",
      "the\n",
      "total\n",
      "amount\n",
      "of\n",
      "emitted\n",
      "energy\n",
      "goes\n",
      "up\n",
      "with\n",
      "the\n",
      "temperature\n",
      "according\n",
      "to\n",
      "a\n",
      "definite\n",
      "rule\n",
      ",\n",
      "the\n",
      "Stefan\n",
      "–\n",
      "Boltzmann\n",
      "law\n",
      "(\n",
      "1879–84\n",
      ")\n",
      ".\n",
      "But\n",
      "it\n",
      "was\n",
      "also\n",
      "known\n",
      "that\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "given\n",
      "off\n",
      "by\n",
      "a\n",
      "hot\n",
      "object\n",
      "changes\n",
      "with\n",
      "the\n",
      "temperature\n",
      ",\n",
      "so\n",
      "that\n",
      "\"\n",
      "white\n",
      "hot\n",
      "\"\n",
      "is\n",
      "hotter\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "of\n",
      "the\n",
      "services\n",
      "he\n",
      "rendered\n",
      "to\n",
      "the\n",
      "advancement\n",
      "of\n",
      "Physics\n",
      "by\n",
      "his\n",
      "discovery\n",
      "of\n",
      "energy\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "There\n",
      "are\n",
      "a\n",
      "number\n",
      "of\n",
      "proposals\n",
      "to\n",
      "redefine\n",
      "certain\n",
      "of\n",
      "the\n",
      "SI\n",
      "base\n",
      "units\n",
      "in\n",
      "terms\n",
      "of\n",
      "fundamental\n",
      "physical\n",
      "constants\n",
      ".\n",
      "This\n",
      "has\n",
      "already\n",
      "been\n",
      "done\n",
      "for\n",
      "the\n",
      "metre\n",
      ",\n",
      "which\n",
      "is\n",
      "defined\n",
      "in\n",
      "terms\n",
      "of\n",
      "a\n",
      "fixed\n",
      "value\n",
      "of\n",
      "the\n",
      "speed\n",
      "of\n",
      "light\n",
      ".\n",
      "The\n",
      "most\n",
      "urgent\n",
      "unit\n",
      "on\n",
      "the\n",
      "list\n",
      "for\n",
      "redefinition\n",
      "is\n",
      "the\n",
      "kilogram\n",
      ",\n",
      "whose\n",
      "value\n",
      "has\n",
      "been\n",
      "fixed\n",
      "for\n",
      "all\n",
      "science\n",
      "(\n",
      "since\n",
      "1889\n",
      ")\n",
      "by\n",
      "the\n",
      "mass\n",
      "of\n",
      "a\n",
      "small\n",
      "cylinder\n",
      "of\n",
      "platinum\n",
      "–\n",
      "iridium\n",
      "alloy\n",
      "kept\n",
      "in\n",
      "a\n",
      "vault\n",
      "just\n",
      "outside\n",
      "Paris\n",
      ".\n",
      "While\n",
      "nobody\n",
      "knows\n",
      "if\n",
      "the\n",
      "mass\n",
      "of\n",
      "the\n",
      "International\n",
      "Prototype\n",
      "Kilogram\n",
      "has\n",
      "changed\n",
      "since\n",
      "1889\n",
      "–\n",
      "the\n",
      "value\n",
      "1\n",
      "kg\n",
      "of\n",
      "its\n",
      "mass\n",
      "expressed\n",
      "in\n",
      "kilograms\n",
      "is\n",
      "by\n",
      "definition\n",
      "unchanged\n",
      "and\n",
      "therein\n",
      "lies\n",
      "one\n",
      "of\n",
      "the\n",
      "problems\n",
      "–\n",
      "it\n",
      "is\n",
      "known\n",
      "that\n",
      "over\n",
      "such\n",
      "a\n",
      "timescale\n",
      "the\n",
      "many\n",
      "similar\n",
      "Pt\n",
      "–\n",
      "Ir\n",
      "alloy\n",
      "cylinders\n",
      "kept\n",
      "in\n",
      "national\n",
      "laboratories\n",
      "around\n",
      "the\n",
      "world\n",
      ",\n",
      "have\n",
      "changed\n",
      "their\n",
      "relative\n",
      "mass\n",
      "by\n",
      "several\n",
      "tens\n",
      "of\n",
      "parts\n",
      "per\n",
      "million\n",
      ",\n",
      "however\n",
      "carefully\n",
      "they\n",
      "are\n",
      "stored\n",
      ",\n",
      "and\n",
      "the\n",
      "more\n",
      "so\n",
      "the\n",
      "more\n",
      "they\n",
      "have\n",
      "been\n",
      "taken\n",
      "out\n",
      "and\n",
      "used\n",
      "as\n",
      "mass\n",
      "standards\n",
      ".\n",
      "A\n",
      "change\n",
      "of\n",
      "several\n",
      "tens\n",
      "of\n",
      "micrograms\n",
      "in\n",
      "one\n",
      "kilogram\n",
      "is\n",
      "equivalent\n",
      "to\n",
      "the\n",
      "current\n",
      "uncertainty\n",
      "in\n",
      "the\n",
      "value\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "in\n",
      "SI\n",
      "units\n",
      ".\n",
      "Prior\n",
      "to\n",
      "Einstein\n",
      "'s\n",
      "paper\n",
      ",\n",
      "electromagnetic\n",
      "radiation\n",
      "such\n",
      "as\n",
      "visible\n",
      "light\n",
      "was\n",
      "considered\n",
      "to\n",
      "behave\n",
      "as\n",
      "a\n",
      "wave\n",
      ":\n",
      "hence\n",
      "the\n",
      "use\n",
      "of\n",
      "the\n",
      "terms\n",
      "\"\n",
      "frequency\n",
      "\"\n",
      "and\n",
      "\"\n",
      "wavelength\n",
      "\"\n",
      "to\n",
      "characterise\n",
      "different\n",
      "types\n",
      "of\n",
      "radiation\n",
      ".\n",
      "The\n",
      "energy\n",
      "transferred\n",
      "by\n",
      "a\n",
      "wave\n",
      "in\n",
      "a\n",
      "given\n",
      "time\n",
      "is\n",
      "called\n",
      "its\n",
      "intensity\n",
      ".\n",
      "The\n",
      "light\n",
      "from\n",
      "a\n",
      "theatre\n",
      "spotlight\n",
      "is\n",
      "more\n",
      "intense\n",
      "than\n",
      "the\n",
      "light\n",
      "from\n",
      "a\n",
      "domestic\n",
      "lightbulb\n",
      ";\n",
      "that\n",
      "is\n",
      "to\n",
      "say\n",
      "that\n",
      "the\n",
      "spotlight\n",
      "gives\n",
      "out\n",
      "more\n",
      "energy\n",
      "per\n",
      "unit\n",
      "time\n",
      "and\n",
      "per\n",
      "unit\n",
      "space(and\n",
      "hence\n",
      "consumes\n",
      "more\n",
      "electricity\n",
      ")\n",
      "than\n",
      "the\n",
      "ordinary\n",
      "bulb\n",
      ",\n",
      "even\n",
      "though\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "might\n",
      "be\n",
      "very\n",
      "similar\n",
      ".\n",
      "Other\n",
      "waves\n",
      ",\n",
      "such\n",
      "as\n",
      "sound\n",
      "or\n",
      "the\n",
      "waves\n",
      "crashing\n",
      "against\n",
      "a\n",
      "seafront\n",
      ",\n",
      "also\n",
      "have\n",
      "their\n",
      "own\n",
      "intensity\n",
      ".\n",
      "However\n",
      ",\n",
      "the\n",
      "energy\n",
      "account\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "did\n",
      "n't\n",
      "seem\n",
      "to\n",
      "agree\n",
      "with\n",
      "the\n",
      "wave\n",
      "description\n",
      "of\n",
      "light\n",
      ".\n",
      "In\n",
      "principle\n",
      ",\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "could\n",
      "be\n",
      "determined\n",
      "by\n",
      "examining\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "black\n",
      "-\n",
      "body\n",
      "radiator\n",
      "or\n",
      "the\n",
      "kinetic\n",
      "energy\n",
      "of\n",
      "photoelectrons\n",
      ",\n",
      "and\n",
      "this\n",
      "is\n",
      "how\n",
      "its\n",
      "value\n",
      "was\n",
      "first\n",
      "calculated\n",
      "in\n",
      "the\n",
      "early\n",
      "twentieth\n",
      "century\n",
      ".\n",
      "In\n",
      "practice\n",
      ",\n",
      "these\n",
      "are\n",
      "no\n",
      "longer\n",
      "the\n",
      "most\n",
      "accurate\n",
      "methods\n",
      ".\n",
      "The\n",
      "CODATA\n",
      "value\n",
      "quoted\n",
      "here\n",
      "is\n",
      "based\n",
      "on\n",
      "three\n",
      "watt\n",
      "-\n",
      "balance\n",
      "measurements\n",
      "of\n",
      "KJ2RK\n",
      "and\n",
      "one\n",
      "inter\n",
      "-\n",
      "laboratory\n",
      "determination\n",
      "of\n",
      "the\n",
      "molar\n",
      "volume\n",
      "of\n",
      "silicon\n",
      ",\n",
      "but\n",
      "is\n",
      "mostly\n",
      "determined\n",
      "by\n",
      "a\n",
      "2007\n",
      "watt\n",
      "-\n",
      "balance\n",
      "measurement\n",
      "made\n",
      "at\n",
      "the\n",
      "U.S.\n",
      "National\n",
      "Institute\n",
      "of\n",
      "Standards\n",
      "and\n",
      "Technology\n",
      "(\n",
      "NIST\n",
      ")\n",
      ".\n",
      "Five\n",
      "other\n",
      "measurements\n",
      "by\n",
      "three\n",
      "different\n",
      "methods\n",
      "were\n",
      "initially\n",
      "considered\n",
      ",\n",
      "but\n",
      "not\n",
      "included\n",
      "in\n",
      "the\n",
      "final\n",
      "refinement\n",
      "as\n",
      "they\n",
      "were\n",
      "too\n",
      "imprecise\n",
      "to\n",
      "affect\n",
      "the\n",
      "result\n",
      ".\n",
      "The\n",
      "theoretical\n",
      "difficulties\n",
      "arise\n",
      "from\n",
      "the\n",
      "fact\n",
      "that\n",
      "all\n",
      "of\n",
      "the\n",
      "methods\n",
      "except\n",
      "the\n",
      "X\n",
      "-\n",
      "ray\n",
      "crystal\n",
      "density\n",
      "method\n",
      "rely\n",
      "on\n",
      "the\n",
      "theoretical\n",
      "basis\n",
      "of\n",
      "the\n",
      "Josephson\n",
      "effect\n",
      "and\n",
      "the\n",
      "quantum\n",
      "Hall\n",
      "effect\n",
      ".\n",
      "If\n",
      "these\n",
      "theories\n",
      "are\n",
      "slightly\n",
      "inaccurate\n",
      "–\n",
      "though\n",
      "there\n",
      "is\n",
      "no\n",
      "evidence\n",
      "at\n",
      "present\n",
      "to\n",
      "suggest\n",
      "they\n",
      "are\n",
      "–\n",
      "the\n",
      "methods\n",
      "would\n",
      "not\n",
      "give\n",
      "accurate\n",
      "values\n",
      "for\n",
      "the\n",
      "Planck\n",
      "constant\n",
      ".\n",
      "More\n",
      "importantly\n",
      ",\n",
      "the\n",
      "values\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "obtained\n",
      "in\n",
      "this\n",
      "way\n",
      "can\n",
      "not\n",
      "be\n",
      "used\n",
      "as\n",
      "tests\n",
      "of\n",
      "the\n",
      "theories\n",
      "without\n",
      "falling\n",
      "into\n",
      "a\n",
      "circular\n",
      "argument\n",
      ".\n",
      "Fortunately\n",
      ",\n",
      "there\n",
      "are\n",
      "other\n",
      "statistical\n",
      "ways\n",
      "of\n",
      "testing\n",
      "the\n",
      "theories\n",
      ",\n",
      "and\n",
      "the\n",
      "theories\n",
      "have\n",
      "yet\n",
      "to\n",
      "be\n",
      "refuted\n",
      ".\n",
      "The\n",
      "legal\n",
      "process\n",
      "to\n",
      "change\n",
      "the\n",
      "definition\n",
      "of\n",
      "the\n",
      "kilogram\n",
      "is\n",
      "already\n",
      "underway\n",
      ",\n",
      "but\n",
      "it\n",
      "had\n",
      "been\n",
      "decided\n",
      "that\n",
      "no\n",
      "final\n",
      "decision\n",
      "would\n",
      "be\n",
      "made\n",
      "before\n",
      "the\n",
      "next\n",
      "meeting\n",
      "of\n",
      "the\n",
      "General\n",
      "Conference\n",
      "on\n",
      "Weights\n",
      "and\n",
      "Measures\n",
      "in\n",
      "2011\n",
      ".\n",
      "(\n",
      "For\n",
      "more\n",
      "detailed\n",
      "information\n",
      ",\n",
      "see\n",
      "kilogram\n",
      "definitions\n",
      ".\n",
      ")\n",
      "The\n",
      "Planck\n",
      "constant\n",
      "is\n",
      "a\n",
      "leading\n",
      "contender\n",
      "to\n",
      "form\n",
      "the\n",
      "basis\n",
      "of\n",
      "the\n",
      "new\n",
      "definition\n",
      ",\n",
      "although\n",
      "not\n",
      "the\n",
      "only\n",
      "one\n",
      ".\n",
      "Possible\n",
      "new\n",
      "definitions\n",
      "include\n",
      "\"\n",
      "the\n",
      "mass\n",
      "of\n",
      "a\n",
      "body\n",
      "at\n",
      "rest\n",
      "whose\n",
      "equivalent\n",
      "energy\n",
      "equals\n",
      "the\n",
      "energy\n",
      "of\n",
      "photons\n",
      "whose\n",
      "frequencies\n",
      "sum\n",
      "to\n",
      "7050135639273999999\n",
      "♠\n",
      "135639274×1042\n",
      "Hz\n",
      "\"\n",
      ",\n",
      "or\n",
      "simply\n",
      "\"\n",
      "the\n",
      "kilogram\n",
      "is\n",
      "defined\n",
      "so\n",
      "that\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "equals\n",
      "6966662606895999999\n",
      "♠\n",
      "6.62606896×10−34\n",
      "J⋅s\n",
      "\"\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "with\n",
      "a\n",
      "\"\n",
      "quantum\n",
      "\"\n",
      "or\n",
      "minimal\n",
      "element\n",
      "of\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "electromagnetic\n",
      "wave\n",
      "itself\n",
      ".\n",
      "The\n",
      "light\n",
      "quantum\n",
      "behaved\n",
      "in\n",
      "some\n",
      "respects\n",
      "as\n",
      "an\n",
      "electrically\n",
      "neutral\n",
      "particle\n",
      ",\n",
      "as\n",
      "opposed\n",
      "to\n",
      "an\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "It\n",
      "was\n",
      "eventually\n",
      "called\n",
      "the\n",
      "photon\n",
      ".\n",
      "The\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      "emitted\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "have\n",
      "a\n",
      "certain\n",
      "kinetic\n",
      "energy\n",
      ",\n",
      "which\n",
      "can\n",
      "be\n",
      "measured\n",
      ".\n",
      "This\n",
      "kinetic\n",
      "energy\n",
      "(\n",
      "for\n",
      "each\n",
      "photoelectron\n",
      ")\n",
      "is\n",
      "independent\n",
      "of\n",
      "the\n",
      "intensity\n",
      "of\n",
      "the\n",
      "light\n",
      ",\n",
      "but\n",
      "depends\n",
      "linearly\n",
      "on\n",
      "the\n",
      "frequency\n",
      ";\n",
      "and\n",
      "if\n",
      "the\n",
      "frequency\n",
      "is\n",
      "too\n",
      "low\n",
      "(\n",
      "corresponding\n",
      "to\n",
      "a\n",
      "photon\n",
      "energy\n",
      "that\n",
      "is\n",
      "less\n",
      "than\n",
      "the\n",
      "work\n",
      "function\n",
      "of\n",
      "the\n",
      "material\n",
      ")\n",
      ",\n",
      "no\n",
      "photoelectrons\n",
      "are\n",
      "emitted\n",
      "at\n",
      "all\n",
      ",\n",
      "unless\n",
      "a\n",
      "plurality\n",
      "of\n",
      "photons\n",
      ",\n",
      "whose\n",
      "energetic\n",
      "sum\n",
      "is\n",
      "greater\n",
      "than\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "photoelectrons\n",
      ",\n",
      "acts\n",
      "virtually\n",
      "simultaneously\n",
      "(\n",
      "multiphoton\n",
      "effect\n",
      ")\n",
      " \n",
      "Assuming\n",
      "the\n",
      "frequency\n",
      "is\n",
      "high\n",
      "enough\n",
      "to\n",
      "cause\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      ",\n",
      "a\n",
      "rise\n",
      "in\n",
      "intensity\n",
      "of\n",
      "the\n",
      "light\n",
      "source\n",
      "causes\n",
      "more\n",
      "photoelectrons\n",
      "to\n",
      "be\n",
      "emitted\n",
      "with\n",
      "the\n",
      "same\n",
      "kinetic\n",
      "energy\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "same\n",
      "number\n",
      "of\n",
      "photoelectrons\n",
      "to\n",
      "be\n",
      "emitted\n",
      "with\n",
      "higher\n",
      "kinetic\n",
      "energy\n",
      ".\n",
      "First\n",
      "recognized\n",
      "in\n",
      "1900\n",
      "by\n",
      "Max\n",
      "Planck\n",
      ",\n",
      "it\n",
      "was\n",
      "originally\n",
      "the\n",
      "proportionality\n",
      "constant\n",
      "between\n",
      "the\n",
      "minimal\n",
      "increment\n",
      "of\n",
      "energy\n",
      ",\n",
      "E\n",
      ",\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "the\n",
      "value\n",
      "E\n",
      ",\n",
      "the\n",
      "minimal\n",
      "energy\n",
      "increment\n",
      "of\n",
      "a\n",
      "hypothetical\n",
      "oscillator\n",
      ",\n",
      "was\n",
      "theoretically\n",
      "associated\n",
      "by\n",
      "Einstein\n",
      "with\n",
      "a\n",
      "\"\n",
      "quantum\n",
      "\"\n",
      "or\n",
      "minimal\n",
      "element\n",
      "of\n",
      "the\n",
      "energy\n",
      "of\n",
      "the\n",
      "electromagnetic\n",
      "wave\n",
      "itself\n",
      ".\n",
      "The\n",
      "light\n",
      "quantum\n",
      "behaved\n",
      "in\n",
      "some\n",
      "respects\n",
      "as\n",
      "an\n",
      "electrically\n",
      "neutral\n",
      "particle\n",
      ",\n",
      "as\n",
      "opposed\n",
      "to\n",
      "an\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "It\n",
      "was\n",
      "eventually\n",
      "called\n",
      "the\n",
      "photon\n",
      ".\n",
      "The\n",
      "X\n",
      "-\n",
      "ray\n",
      "crystal\n",
      "density\n",
      "method\n",
      "is\n",
      "primarily\n",
      "a\n",
      "method\n",
      "for\n",
      "determining\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      "NA\n",
      "but\n",
      "as\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      "is\n",
      "related\n",
      "to\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "it\n",
      "also\n",
      "determines\n",
      "a\n",
      "value\n",
      "for\n",
      "h.\n",
      "The\n",
      "principle\n",
      "behind\n",
      "the\n",
      "method\n",
      "is\n",
      "to\n",
      "determine\n",
      "NA\n",
      "as\n",
      "the\n",
      "ratio\n",
      "between\n",
      "the\n",
      "volume\n",
      "of\n",
      "the\n",
      "unit\n",
      "cell\n",
      "of\n",
      "a\n",
      "crystal\n",
      ",\n",
      "measured\n",
      "by\n",
      "X\n",
      "-\n",
      "ray\n",
      "crystallography\n",
      ",\n",
      "and\n",
      "the\n",
      "molar\n",
      "volume\n",
      "of\n",
      "the\n",
      "substance\n",
      ".\n",
      "Crystals\n",
      "of\n",
      "silicon\n",
      "are\n",
      "used\n",
      ",\n",
      "as\n",
      "they\n",
      "are\n",
      "available\n",
      "in\n",
      "high\n",
      "quality\n",
      "and\n",
      "purity\n",
      "by\n",
      "the\n",
      "technology\n",
      "developed\n",
      "for\n",
      "the\n",
      "semiconductor\n",
      "industry\n",
      ".\n",
      "The\n",
      "unit\n",
      "cell\n",
      "volume\n",
      "is\n",
      "calculated\n",
      "from\n",
      "the\n",
      "spacing\n",
      "between\n",
      "two\n",
      "crystal\n",
      "planes\n",
      "referred\n",
      "to\n",
      "as\n",
      "d220\n",
      ".\n",
      "The\n",
      "molar\n",
      "volume\n",
      "Vm(Si\n",
      ")\n",
      "requires\n",
      "a\n",
      "knowledge\n",
      "of\n",
      "the\n",
      "density\n",
      "of\n",
      "the\n",
      "crystal\n",
      "and\n",
      "the\n",
      "atomic\n",
      "weight\n",
      "of\n",
      "the\n",
      "silicon\n",
      "used\n",
      ".\n",
      "The\n",
      "Planck\n",
      "constant\n",
      "is\n",
      "given\n",
      "by\n",
      "where\n",
      "the\n",
      "uncertainty\n",
      "is\n",
      "given\n",
      "as\n",
      "the\n",
      "standard\n",
      "deviation\n",
      "of\n",
      "the\n",
      "measured\n",
      "value\n",
      "from\n",
      "its\n",
      "expected\n",
      "value\n",
      ".\n",
      "There\n",
      "are\n",
      "a\n",
      "number\n",
      "of\n",
      "other\n",
      "such\n",
      "pairs\n",
      "of\n",
      "physically\n",
      "measurable\n",
      "values\n",
      "which\n",
      "obey\n",
      "a\n",
      "similar\n",
      "rule\n",
      ".\n",
      "One\n",
      "example\n",
      "is\n",
      "time\n",
      "vs.\n",
      "energy\n",
      ".\n",
      "The\n",
      "either\n",
      "-\n",
      "or\n",
      "nature\n",
      "of\n",
      "uncertainty\n",
      "forces\n",
      "measurement\n",
      "attempts\n",
      "to\n",
      "choose\n",
      "between\n",
      "trade\n",
      "offs\n",
      ",\n",
      "and\n",
      "given\n",
      "that\n",
      "they\n",
      "are\n",
      "quanta\n",
      ",\n",
      "the\n",
      "trade\n",
      "offs\n",
      "often\n",
      "take\n",
      "the\n",
      "form\n",
      "of\n",
      "either\n",
      "-\n",
      "or\n",
      "(\n",
      "as\n",
      "in\n",
      "Fourier\n",
      "analysis\n",
      ")\n",
      ",\n",
      "rather\n",
      "than\n",
      "the\n",
      "compromises\n",
      "and\n",
      "gray\n",
      "areas\n",
      "of\n",
      "time\n",
      "series\n",
      "analysis\n",
      ".\n",
      "Prior\n",
      "to\n",
      "Einstein\n",
      "'s\n",
      "paper\n",
      ",\n",
      "electromagnetic\n",
      "radiation\n",
      "such\n",
      "as\n",
      "visible\n",
      "light\n",
      "was\n",
      "considered\n",
      "to\n",
      "behave\n",
      "as\n",
      "a\n",
      "wave\n",
      ":\n",
      "hence\n",
      "the\n",
      "use\n",
      "of\n",
      "the\n",
      "terms\n",
      "\"\n",
      "frequency\n",
      "\"\n",
      "and\n",
      "\"\n",
      "wavelength\n",
      "\"\n",
      "to\n",
      "characterise\n",
      "different\n",
      "types\n",
      "of\n",
      "radiation\n",
      ".\n",
      "The\n",
      "energy\n",
      "transferred\n",
      "by\n",
      "a\n",
      "wave\n",
      "in\n",
      "a\n",
      "given\n",
      "time\n",
      "is\n",
      "called\n",
      "its\n",
      "intensity\n",
      ".\n",
      "The\n",
      "light\n",
      "from\n",
      "a\n",
      "theatre\n",
      "spotlight\n",
      "is\n",
      "more\n",
      "intense\n",
      "than\n",
      "the\n",
      "light\n",
      "from\n",
      "a\n",
      "domestic\n",
      "lightbulb\n",
      ";\n",
      "that\n",
      "is\n",
      "to\n",
      "say\n",
      "that\n",
      "the\n",
      "spotlight\n",
      "gives\n",
      "out\n",
      "more\n",
      "energy\n",
      "per\n",
      "unit\n",
      "time\n",
      "and\n",
      "per\n",
      "unit\n",
      "space(and\n",
      "hence\n",
      "consumes\n",
      "more\n",
      "electricity\n",
      ")\n",
      "than\n",
      "the\n",
      "ordinary\n",
      "bulb\n",
      ",\n",
      "even\n",
      "though\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "might\n",
      "be\n",
      "very\n",
      "similar\n",
      ".\n",
      "Other\n",
      "waves\n",
      ",\n",
      "such\n",
      "as\n",
      "sound\n",
      "or\n",
      "the\n",
      "waves\n",
      "crashing\n",
      "against\n",
      "a\n",
      "seafront\n",
      ",\n",
      "also\n",
      "have\n",
      "their\n",
      "own\n",
      "intensity\n",
      ".\n",
      "However\n",
      ",\n",
      "the\n",
      "energy\n",
      "account\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "did\n",
      "n't\n",
      "seem\n",
      "to\n",
      "agree\n",
      "with\n",
      "the\n",
      "wave\n",
      "description\n",
      "of\n",
      "light\n",
      ".\n",
      "The\n",
      "assumption\n",
      "that\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "is\n",
      "thermal\n",
      "leads\n",
      "to\n",
      "an\n",
      "accurate\n",
      "prediction\n",
      ":\n",
      "the\n",
      "total\n",
      "amount\n",
      "of\n",
      "emitted\n",
      "energy\n",
      "goes\n",
      "up\n",
      "with\n",
      "the\n",
      "temperature\n",
      "according\n",
      "to\n",
      "a\n",
      "definite\n",
      "rule\n",
      ",\n",
      "the\n",
      "Stefan\n",
      "–\n",
      "Boltzmann\n",
      "law\n",
      "(\n",
      "1879–84\n",
      ")\n",
      ".\n",
      "But\n",
      "it\n",
      "was\n",
      "also\n",
      "known\n",
      "that\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "given\n",
      "off\n",
      "by\n",
      "a\n",
      "hot\n",
      "object\n",
      "changes\n",
      "with\n",
      "the\n",
      "temperature\n",
      ",\n",
      "so\n",
      "that\n",
      "\"\n",
      "white\n",
      "hot\n",
      "\"\n",
      "is\n",
      "hotter\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "proposed\n",
      "an\n",
      "approximation\n",
      "for\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "the\n",
      "object\n",
      ",\n",
      "which\n",
      "was\n",
      "correct\n",
      "at\n",
      "high\n",
      "frequencies\n",
      "(\n",
      "short\n",
      "wavelength\n",
      ")\n",
      "but\n",
      "not\n",
      "at\n",
      "low\n",
      "frequencies\n",
      "(\n",
      "long\n",
      "wavelength\n",
      ")\n",
      ".\n",
      "It\n",
      "still\n",
      "was\n",
      "not\n",
      "clear\n",
      "why\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "hot\n",
      "object\n",
      "had\n",
      "the\n",
      "form\n",
      "that\n",
      "it\n",
      "has\n",
      "(\n",
      "see\n",
      "diagram\n",
      ")\n",
      ".\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "\n",
      "Equivalently\n",
      ",\n",
      "the\n",
      "smallness\n",
      "of\n",
      "the\n",
      "Planck\n",
      "constant\n",
      "reflects\n",
      "the\n",
      "fact\n",
      "that\n",
      "everyday\n",
      "objects\n",
      "and\n",
      "systems\n",
      "are\n",
      "made\n",
      "of\n",
      "a\n",
      "large\n",
      "number\n",
      "of\n",
      "particles\n",
      ".\n",
      "For\n",
      "example\n",
      ",\n",
      "green\n",
      "light\n",
      "with\n",
      "a\n",
      "wavelength\n",
      "of\n",
      "555\n",
      "nanometres\n",
      "(\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "540\n",
      "THz\n",
      "(\n",
      "7014540000000000000\n",
      "♠\n",
      "540×1012\n",
      "Hz\n",
      ")\n",
      ".\n",
      "Each\n",
      "photon\n",
      "has\n",
      "an\n",
      "energy\n",
      "E\n",
      "=\n",
      "hf\n",
      "=\n",
      "6981358000000000000\n",
      "♠\n",
      "3.58×10−19\n",
      "J.\n",
      "That\n",
      "is\n",
      "a\n",
      "very\n",
      "small\n",
      "amount\n",
      "of\n",
      "energy\n",
      "in\n",
      "terms\n",
      "of\n",
      "everyday\n",
      "experience\n",
      ",\n",
      "but\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "'s\n",
      "1905\n",
      "paper\n",
      "discussing\n",
      "the\n",
      "effect\n",
      "in\n",
      "terms\n",
      "of\n",
      "light\n",
      "quanta\n",
      "would\n",
      "earn\n",
      "him\n",
      "the\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "1921\n",
      ",\n",
      "when\n",
      "his\n",
      "predictions\n",
      "had\n",
      "been\n",
      "confirmed\n",
      "by\n",
      "the\n",
      "experimental\n",
      "work\n",
      "of\n",
      "Robert\n",
      "Andrews\n",
      "Millikan\n",
      ".\n",
      "The\n",
      "Nobel\n",
      "committee\n",
      "awarded\n",
      "the\n",
      "prize\n",
      "for\n",
      "his\n",
      "work\n",
      "on\n",
      "the\n",
      "photo\n",
      "-\n",
      "electric\n",
      "effect\n",
      ",\n",
      "rather\n",
      "than\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relativity\n",
      ",\n",
      "both\n",
      "because\n",
      "of\n",
      "a\n",
      "bias\n",
      "against\n",
      "purely\n",
      "theoretical\n",
      "physics\n",
      "not\n",
      "grounded\n",
      "in\n",
      "discovery\n",
      "or\n",
      "experiment\n",
      ",\n",
      "and\n",
      "dissent\n",
      "amongst\n",
      "its\n",
      "members\n",
      "as\n",
      "to\n",
      "the\n",
      "actual\n",
      "proof\n",
      "that\n",
      "relativity\n",
      "was\n",
      "real\n",
      ".\n",
      "Bohr\n",
      "also\n",
      "introduced\n",
      "the\n",
      "quantity\n",
      ",\n",
      "now\n",
      "known\n",
      "as\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      ",\n",
      "as\n",
      "the\n",
      "quantum\n",
      "of\n",
      "angular\n",
      "momentum\n",
      ".\n",
      "At\n",
      "first\n",
      ",\n",
      "Bohr\n",
      "thought\n",
      "that\n",
      "this\n",
      "was\n",
      "the\n",
      "angular\n",
      "momentum\n",
      "of\n",
      "each\n",
      "electron\n",
      "in\n",
      "an\n",
      "atom\n",
      ":\n",
      "this\n",
      "proved\n",
      "incorrect\n",
      "and\n",
      ",\n",
      "despite\n",
      "developments\n",
      "by\n",
      "Sommerfeld\n",
      "and\n",
      "others\n",
      ",\n",
      "an\n",
      "accurate\n",
      "description\n",
      "of\n",
      "the\n",
      "electron\n",
      "angular\n",
      "momentum\n",
      "proved\n",
      "beyond\n",
      "the\n",
      "Bohr\n",
      "model\n",
      ".\n",
      "The\n",
      "correct\n",
      "quantization\n",
      "rules\n",
      "for\n",
      "electrons\n",
      "–\n",
      "in\n",
      "which\n",
      "the\n",
      "energy\n",
      "reduces\n",
      "to\n",
      "the\n",
      "Bohr\n",
      "model\n",
      "equation\n",
      "in\n",
      "the\n",
      "case\n",
      "of\n",
      "the\n",
      "hydrogen\n",
      "atom\n",
      "–\n",
      "were\n",
      "given\n",
      "by\n",
      "Heisenberg\n",
      "'s\n",
      "matrix\n",
      "mechanics\n",
      "in\n",
      "1925\n",
      "and\n",
      "the\n",
      "Schrödinger\n",
      "wave\n",
      "equation\n",
      "in\n",
      "1926\n",
      ":\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      "remains\n",
      "the\n",
      "fundamental\n",
      "quantum\n",
      "of\n",
      "angular\n",
      "momentum\n",
      ".\n",
      "In\n",
      "modern\n",
      "terms\n",
      ",\n",
      "if\n",
      "J\n",
      "is\n",
      "the\n",
      "total\n",
      "angular\n",
      "momentum\n",
      "of\n",
      "a\n",
      "system\n",
      "with\n",
      "rotational\n",
      "invariance\n",
      ",\n",
      "and\n",
      "Jz\n",
      "the\n",
      "angular\n",
      "momentum\n",
      "measured\n",
      "along\n",
      "any\n",
      "given\n",
      "direction\n",
      ",\n",
      "these\n",
      "quantities\n",
      "can\n",
      "only\n",
      "take\n",
      "on\n",
      "the\n",
      "values\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "the\n",
      "approximate\n",
      "wavelength\n",
      "to\n",
      "which\n",
      "human\n",
      "eyes\n",
      "are\n",
      "most\n",
      "sensitive\n",
      ")\n",
      "has\n",
      "a\n",
      "frequency\n",
      "of\n",
      "7014540000000000000\n",
      "♠\n",
      "540\n",
      "THz\n",
      "(\n",
      "7014540000000000000\n",
      "♠\n",
      "540×1012\n",
      "Hz\n",
      ")\n",
      ".\n",
      "Each\n",
      "photon\n",
      "has\n",
      "an\n",
      "energy\n",
      "E\n",
      "=\n",
      "hf\n",
      "=\n",
      "6981358000000000000\n",
      "♠\n",
      "3.58×10−19\n",
      "J.\n",
      "That\n",
      "is\n",
      "a\n",
      "very\n",
      "small\n",
      "amount\n",
      "of\n",
      "energy\n",
      "in\n",
      "terms\n",
      "of\n",
      "everyday\n",
      "experience\n",
      ",\n",
      "but\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "not\n",
      "concerned\n",
      "with\n",
      "individual\n",
      "photons\n",
      "any\n",
      "more\n",
      "than\n",
      "with\n",
      "individual\n",
      "atoms\n",
      "or\n",
      "molecules\n",
      ".\n",
      "An\n",
      "amount\n",
      "of\n",
      "light\n",
      "compatible\n",
      "with\n",
      "everyday\n",
      "experience\n",
      "is\n",
      "the\n",
      "energy\n",
      "of\n",
      "one\n",
      "mole\n",
      "of\n",
      "photons\n",
      ";\n",
      "its\n",
      "energy\n",
      "can\n",
      "be\n",
      "computed\n",
      "by\n",
      "multiplying\n",
      "the\n",
      "photon\n",
      "energy\n",
      "by\n",
      "the\n",
      "Avogadro\n",
      "constant\n",
      ",\n",
      "NA\n",
      "≈\n",
      "7023602200000000000\n",
      "♠\n",
      "6.022×1023\n",
      "mol−1\n",
      ".\n",
      "The\n",
      "result\n",
      "is\n",
      "that\n",
      "green\n",
      "light\n",
      "of\n",
      "wavelength\n",
      "555\n",
      "nm\n",
      "has\n",
      "an\n",
      "energy\n",
      "of\n",
      "7005216000000000000\n",
      "♠\n",
      "216\n",
      "kJ\n",
      "/\n",
      "mol\n",
      ",\n",
      "a\n",
      "typical\n",
      "energy\n",
      "of\n",
      "everyday\n",
      "life\n",
      ".\n",
      "The\n",
      "assumption\n",
      "that\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "is\n",
      "thermal\n",
      "leads\n",
      "to\n",
      "an\n",
      "accurate\n",
      "prediction\n",
      ":\n",
      "the\n",
      "total\n",
      "amount\n",
      "of\n",
      "emitted\n",
      "energy\n",
      "goes\n",
      "up\n",
      "with\n",
      "the\n",
      "temperature\n",
      "according\n",
      "to\n",
      "a\n",
      "definite\n",
      "rule\n",
      ",\n",
      "the\n",
      "Stefan\n",
      "–\n",
      "Boltzmann\n",
      "law\n",
      "(\n",
      "1879–84\n",
      ")\n",
      ".\n",
      "But\n",
      "it\n",
      "was\n",
      "also\n",
      "known\n",
      "that\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "given\n",
      "off\n",
      "by\n",
      "a\n",
      "hot\n",
      "object\n",
      "changes\n",
      "with\n",
      "the\n",
      "temperature\n",
      ",\n",
      "so\n",
      "that\n",
      "\"\n",
      "white\n",
      "hot\n",
      "\"\n",
      "is\n",
      "hotter\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "proposed\n",
      "an\n",
      "approximation\n",
      "for\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "the\n",
      "object\n",
      ",\n",
      "which\n",
      "was\n",
      "correct\n",
      "at\n",
      "high\n",
      "frequencies\n",
      "(\n",
      "short\n",
      "wavelength\n",
      ")\n",
      "but\n",
      "not\n",
      "at\n",
      "low\n",
      "frequencies\n",
      "(\n",
      "long\n",
      "wavelength\n",
      ")\n",
      ".\n",
      "It\n",
      "still\n",
      "was\n",
      "not\n",
      "clear\n",
      "why\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "hot\n",
      "object\n",
      "had\n",
      "the\n",
      "form\n",
      "that\n",
      "it\n",
      "has\n",
      "(\n",
      "see\n",
      "diagram\n",
      ")\n",
      ".\n",
      "Bohr\n",
      "Bohr ORG\n",
      "Bohr\n",
      "also\n",
      "introduced\n",
      "the\n",
      "quantity\n",
      ",\n",
      "now\n",
      "known\n",
      "as\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      ",\n",
      "as\n",
      "the\n",
      "quantum\n",
      "of\n",
      "angular\n",
      "momentum\n",
      ".\n",
      "At\n",
      "first\n",
      ",\n",
      "Bohr\n",
      "thought\n",
      "that\n",
      "this\n",
      "was\n",
      "the\n",
      "angular\n",
      "momentum\n",
      "of\n",
      "each\n",
      "electron\n",
      "in\n",
      "an\n",
      "atom\n",
      ":\n",
      "this\n",
      "proved\n",
      "incorrect\n",
      "and\n",
      ",\n",
      "despite\n",
      "developments\n",
      "by\n",
      "Sommerfeld\n",
      "and\n",
      "others\n",
      ",\n",
      "an\n",
      "accurate\n",
      "description\n",
      "of\n",
      "the\n",
      "electron\n",
      "angular\n",
      "momentum\n",
      "proved\n",
      "beyond\n",
      "the\n",
      "Bohr\n",
      "model\n",
      ".\n",
      "The\n",
      "correct\n",
      "quantization\n",
      "rules\n",
      "for\n",
      "electrons\n",
      "–\n",
      "in\n",
      "which\n",
      "the\n",
      "energy\n",
      "reduces\n",
      "to\n",
      "the\n",
      "Bohr\n",
      "model\n",
      "equation\n",
      "in\n",
      "the\n",
      "case\n",
      "of\n",
      "the\n",
      "hydrogen\n",
      "atom\n",
      "–\n",
      "were\n",
      "given\n",
      "by\n",
      "Heisenberg\n",
      "Heisenberg ORG\n",
      "Prior\n",
      "to\n",
      "Planck\n",
      "'s\n",
      "work\n",
      ",\n",
      "it\n",
      "had\n",
      "been\n",
      "assumed\n",
      "that\n",
      "the\n",
      "energy\n",
      "of\n",
      "a\n",
      "body\n",
      "could\n",
      "take\n",
      "on\n",
      "any\n",
      "value\n",
      "whatsoever\n",
      "–\n",
      "that\n",
      "it\n",
      "was\n",
      "a\n",
      "continuous\n",
      "variable\n",
      ".\n",
      "The\n",
      "Rayleigh\n",
      "–\n",
      "Jeans\n",
      "law\n",
      "makes\n",
      "close\n",
      "predictions\n",
      "for\n",
      "a\n",
      "narrow\n",
      "range\n",
      "of\n",
      "values\n",
      "at\n",
      "one\n",
      "limit\n",
      "of\n",
      "temperatures\n",
      ",\n",
      "but\n",
      "the\n",
      "results\n",
      "diverge\n",
      "more\n",
      "and\n",
      "more\n",
      "strongly\n",
      "as\n",
      "temperatures\n",
      "increase\n",
      ".\n",
      "To\n",
      "make\n",
      "Planck\n",
      "'s\n",
      "law\n",
      ",\n",
      "which\n",
      "correctly\n",
      "predicts\n",
      "blackbody\n",
      "emissions\n",
      ",\n",
      "it\n",
      "was\n",
      "necessary\n",
      "to\n",
      "multiply\n",
      "the\n",
      "classical\n",
      "expression\n",
      "by\n",
      "a\n",
      "complex\n",
      "factor\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "proposed\n",
      "an\n",
      "approximation\n",
      "for\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "the\n",
      "object\n",
      ",\n",
      "which\n",
      "was\n",
      "correct\n",
      "at\n",
      "high\n",
      "frequencies\n",
      "(\n",
      "short\n",
      "wavelength\n",
      ")\n",
      "but\n",
      "not\n",
      "at\n",
      "low\n",
      "frequencies\n",
      "(\n",
      "long\n",
      "wavelength\n",
      ")\n",
      ".\n",
      "It\n",
      "still\n",
      "was\n",
      "not\n",
      "clear\n",
      "why\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "hot\n",
      "object\n",
      "had\n",
      "the\n",
      "form\n",
      "that\n",
      "it\n",
      "has\n",
      "(\n",
      "see\n",
      "diagram\n",
      ")\n",
      ".\n",
      "In\n",
      "the\n",
      "last\n",
      "years\n",
      "of\n",
      "the\n",
      "nineteenth\n",
      "century\n",
      ",\n",
      "Planck\n",
      "was\n",
      "investigating\n",
      "the\n",
      "problem\n",
      "of\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "first\n",
      "posed\n",
      "by\n",
      "Kirchhoff\n",
      "some\n",
      "forty\n",
      "years\n",
      "earlier\n",
      ".\n",
      "It\n",
      "is\n",
      "well\n",
      "known\n",
      "that\n",
      "hot\n",
      "objects\n",
      "glow\n",
      ",\n",
      "and\n",
      "that\n",
      "hotter\n",
      "objects\n",
      "glow\n",
      "brighter\n",
      "than\n",
      "cooler\n",
      "ones\n",
      ".\n",
      "The\n",
      "electromagnetic\n",
      "field\n",
      "obeys\n",
      "laws\n",
      "of\n",
      "motion\n",
      "similarly\n",
      "to\n",
      "a\n",
      "mass\n",
      "on\n",
      "a\n",
      "spring\n",
      ",\n",
      "and\n",
      "can\n",
      "come\n",
      "to\n",
      "thermal\n",
      "equilibrium\n",
      "with\n",
      "hot\n",
      "atoms\n",
      ".\n",
      "The\n",
      "hot\n",
      "object\n",
      "in\n",
      "equilibrium\n",
      "with\n",
      "light\n",
      "absorbs\n",
      "just\n",
      "as\n",
      "much\n",
      "light\n",
      "as\n",
      "it\n",
      "emits\n",
      ".\n",
      "If\n",
      "the\n",
      "object\n",
      "is\n",
      "black\n",
      ",\n",
      "meaning\n",
      "it\n",
      "absorbs\n",
      "all\n",
      "the\n",
      "light\n",
      "that\n",
      "hits\n",
      "it\n",
      ",\n",
      "then\n",
      "its\n",
      "thermal\n",
      "light\n",
      "emission\n",
      "is\n",
      "maximized\n",
      ".\n",
      "Prior\n",
      "to\n",
      "Einstein\n",
      "'s\n",
      "paper\n",
      ",\n",
      "electromagnetic\n",
      "radiation\n",
      "such\n",
      "as\n",
      "visible\n",
      "light\n",
      "was\n",
      "considered\n",
      "to\n",
      "behave\n",
      "as\n",
      "a\n",
      "wave\n",
      ":\n",
      "hence\n",
      "the\n",
      "use\n",
      "of\n",
      "the\n",
      "terms\n",
      "\"\n",
      "frequency\n",
      "\"\n",
      "and\n",
      "\"\n",
      "wavelength\n",
      "\"\n",
      "to\n",
      "characterise\n",
      "different\n",
      "types\n",
      "of\n",
      "radiation\n",
      ".\n",
      "The\n",
      "energy\n",
      "transferred\n",
      "by\n",
      "a\n",
      "wave\n",
      "in\n",
      "a\n",
      "given\n",
      "time\n",
      "is\n",
      "called\n",
      "its\n",
      "intensity\n",
      ".\n",
      "The\n",
      "light\n",
      "from\n",
      "a\n",
      "theatre\n",
      "spotlight\n",
      "is\n",
      "more\n",
      "intense\n",
      "than\n",
      "the\n",
      "light\n",
      "from\n",
      "a\n",
      "domestic\n",
      "lightbulb\n",
      ";\n",
      "that\n",
      "is\n",
      "to\n",
      "say\n",
      "that\n",
      "the\n",
      "spotlight\n",
      "gives\n",
      "out\n",
      "more\n",
      "energy\n",
      "per\n",
      "unit\n",
      "time\n",
      "and\n",
      "per\n",
      "unit\n",
      "space(and\n",
      "hence\n",
      "consumes\n",
      "more\n",
      "electricity\n",
      ")\n",
      "than\n",
      "the\n",
      "ordinary\n",
      "bulb\n",
      ",\n",
      "even\n",
      "though\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "might\n",
      "be\n",
      "very\n",
      "similar\n",
      ".\n",
      "Other\n",
      "waves\n",
      ",\n",
      "such\n",
      "as\n",
      "sound\n",
      "or\n",
      "the\n",
      "waves\n",
      "crashing\n",
      "against\n",
      "a\n",
      "seafront\n",
      ",\n",
      "also\n",
      "have\n",
      "their\n",
      "own\n",
      "intensity\n",
      ".\n",
      "However\n",
      ",\n",
      "the\n",
      "energy\n",
      "account\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "did\n",
      "n't\n",
      "seem\n",
      "to\n",
      "agree\n",
      "with\n",
      "the\n",
      "wave\n",
      "description\n",
      "of\n",
      "light\n",
      ".\n",
      "The\n",
      "photoelectric\n",
      "effect\n",
      "is\n",
      "the\n",
      "emission\n",
      "of\n",
      "electrons\n",
      "(\n",
      "called\n",
      "\"\n",
      "photoelectrons\n",
      "\"\n",
      ")\n",
      "from\n",
      "a\n",
      "surface\n",
      "when\n",
      "light\n",
      "is\n",
      "shone\n",
      "on\n",
      "it\n",
      ".\n",
      "It\n",
      "was\n",
      "first\n",
      "observed\n",
      "by\n",
      "Alexandre\n",
      "Edmond\n",
      "Becquerel\n",
      "in\n",
      "1839\n",
      ",\n",
      "although\n",
      "credit\n",
      "is\n",
      "usually\n",
      "reserved\n",
      "for\n",
      "Heinrich\n",
      "Hertz\n",
      ",\n",
      "who\n",
      "published\n",
      "the\n",
      "first\n",
      "thorough\n",
      "investigation\n",
      "in\n",
      "1887\n",
      ".\n",
      "Another\n",
      "particularly\n",
      "thorough\n",
      "investigation\n",
      "was\n",
      "published\n",
      "by\n",
      "Philipp\n",
      "Lenard\n",
      "in\n",
      "1902\n",
      ".\n",
      "Einstein\n",
      "'s\n",
      "1905\n",
      "paper\n",
      "discussing\n",
      "the\n",
      "effect\n",
      "in\n",
      "terms\n",
      "of\n",
      "light\n",
      "quanta\n",
      "would\n",
      "earn\n",
      "him\n",
      "the\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "1921\n",
      "1921 DATE\n",
      "Bohr\n",
      "also\n",
      "introduced\n",
      "the\n",
      "quantity\n",
      ",\n",
      "now\n",
      "known\n",
      "as\n",
      "the\n",
      "reduced\n",
      "Planck\n",
      "constant\n",
      ",\n",
      "as\n",
      "the\n",
      "quantum\n",
      "of\n",
      "angular\n",
      "momentum\n",
      ".\n",
      "At\n",
      "first\n",
      ",\n",
      "Bohr\n",
      "thought\n",
      "that\n",
      "this\n",
      "was\n",
      "the\n",
      "angular\n",
      "momentum\n",
      "of\n",
      "each\n",
      "electron\n",
      "in\n",
      "an\n",
      "atom\n",
      ":\n",
      "this\n",
      "proved\n",
      "incorrectof\n",
      "a\n",
      "hypothetical\n",
      "electrically\n",
      "charged\n",
      "oscillator\n",
      "in\n",
      "a\n",
      "cavity\n",
      "that\n",
      "contained\n",
      "black\n",
      "body\n",
      "radiation\n",
      ",\n",
      "and\n",
      "the\n",
      "frequency\n",
      ",\n",
      "f\n",
      ",\n",
      "of\n",
      "its\n",
      "associated\n",
      "electromagnetic\n",
      "wave\n",
      ".\n",
      "In\n",
      "1905\n",
      "1905 DATE\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      ".\n",
      "They\n",
      "contributed\n",
      "greatly\n",
      "(\n",
      "along\n",
      "with\n",
      "Einstein\n",
      "'s\n",
      "work\n",
      "on\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      ")\n",
      "to\n",
      "convincing\n",
      "physicists\n",
      "that\n",
      "Planck\n",
      "'s\n",
      "postulate\n",
      "of\n",
      "quantized\n",
      "energy\n",
      "levels\n",
      "was\n",
      "more\n",
      "than\n",
      "a\n",
      "mere\n",
      "mathematical\n",
      "formalism\n",
      ".\n",
      "The\n",
      "very\n",
      "first\n",
      "Solvay\n",
      "Conference\n",
      "in\n",
      "1911\n",
      "was\n",
      "devoted\n",
      "to\n",
      "\"\n",
      "the\n",
      "theory\n",
      "of\n",
      "radiation\n",
      "and\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "Max\n",
      "Planck\n",
      "received\n",
      "the\n",
      "1918\n",
      "Nobel\n",
      "Prize\n",
      "in\n",
      "Physics\n",
      "\"\n",
      "in\n",
      "recognition\n",
      "of\n",
      "the\n",
      "services\n",
      "he\n",
      "rendered\n",
      "to\n",
      "the\n",
      "advancement\n",
      "of\n",
      "Physics\n",
      "by\n",
      "his\n",
      "discovery\n",
      "of\n",
      "energy\n",
      "quanta\n",
      "\"\n",
      ".\n",
      "Prior\n",
      "to\n",
      "Einstein\n",
      "'s\n",
      "paper\n",
      ",\n",
      "electromagnetic\n",
      "radiation\n",
      "such\n",
      "as\n",
      "visible\n",
      "light\n",
      "was\n",
      "considered\n",
      "to\n",
      "behave\n",
      "as\n",
      "a\n",
      "wave\n",
      ":\n",
      "hence\n",
      "the\n",
      "use\n",
      "of\n",
      "the\n",
      "terms\n",
      "\"\n",
      "frequency\n",
      "\"\n",
      "and\n",
      "\"\n",
      "wavelength\n",
      "\"\n",
      "to\n",
      "characterise\n",
      "different\n",
      "types\n",
      "of\n",
      "radiation\n",
      ".\n",
      "The\n",
      "energy\n",
      "transferred\n",
      "by\n",
      "a\n",
      "wave\n",
      "in\n",
      "a\n",
      "given\n",
      "time\n",
      "is\n",
      "called\n",
      "its\n",
      "intensity\n",
      ".\n",
      "The\n",
      "light\n",
      "from\n",
      "a\n",
      "theatre\n",
      "spotlight\n",
      "is\n",
      "more\n",
      "intense\n",
      "than\n",
      "the\n",
      "light\n",
      "from\n",
      "a\n",
      "domestic\n",
      "lightbulb\n",
      ";\n",
      "that\n",
      "is\n",
      "to\n",
      "say\n",
      "that\n",
      "the\n",
      "spotlight\n",
      "gives\n",
      "out\n",
      "more\n",
      "energy\n",
      "per\n",
      "unit\n",
      "time\n",
      "and\n",
      "per\n",
      "unit\n",
      "space(and\n",
      "hence\n",
      "consumes\n",
      "more\n",
      "electricity\n",
      ")\n",
      "than\n",
      "the\n",
      "ordinary\n",
      "bulb\n",
      ",\n",
      "even\n",
      "though\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "might\n",
      "be\n",
      "very\n",
      "similar\n",
      ".\n",
      "Other\n",
      "waves\n",
      ",\n",
      "such\n",
      "as\n",
      "sound\n",
      "or\n",
      "the\n",
      "waves\n",
      "crashing\n",
      "against\n",
      "a\n",
      "seafront\n",
      ",\n",
      "also\n",
      "have\n",
      "their\n",
      "own\n",
      "intensity\n",
      ".\n",
      "However\n",
      ",\n",
      "the\n",
      "energy\n",
      "account\n",
      "of\n",
      "the\n",
      "photoelectric\n",
      "effect\n",
      "did\n",
      "n't\n",
      "seem\n",
      "to\n",
      "agree\n",
      "with\n",
      "the\n",
      "wave\n",
      "description\n",
      "of\n",
      "light\n",
      ".\n",
      "In\n",
      "the\n",
      "last\n",
      "years\n",
      "of\n",
      "the\n",
      "nineteenth\n",
      "century\n",
      ",\n",
      "Planck\n",
      "was\n",
      "investigating\n",
      "the\n",
      "problem\n",
      "of\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "first\n",
      "posed\n",
      "by\n",
      "Kirchhoff\n",
      "some\n",
      "forty\n",
      "forty DATE\n",
      "The\n",
      "black\n",
      "-\n",
      "body\n",
      "problem\n",
      "was\n",
      "revisited\n",
      "in\n",
      "1905\n",
      ",\n",
      "when\n",
      "Rayleigh\n",
      "and\n",
      "Jeans\n",
      "(\n",
      "on\n",
      "the\n",
      "one\n",
      "hand\n",
      ")\n",
      "and\n",
      "Einstein\n",
      "(\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      ")\n",
      "independently\n",
      "proved\n",
      "that\n",
      "classical\n",
      "electromagnetism\n",
      "could\n",
      "never\n",
      "account\n",
      "for\n",
      "the\n",
      "observed\n",
      "spectrum\n",
      ".\n",
      "These\n",
      "proofs\n",
      "are\n",
      "commonly\n",
      "known\n",
      "as\n",
      "the\n",
      "\"\n",
      "ultraviolet\n",
      "catastrophe\n",
      "\"\n",
      ",\n",
      "a\n",
      "name\n",
      "coined\n",
      "by\n",
      "Paul\n",
      "Ehrenfest\n",
      "in\n",
      "1911\n",
      "1911 DATE\n",
      "In\n",
      "the\n",
      "last\n",
      "years\n",
      "of\n",
      "the\n",
      "nineteenth\n",
      "century\n",
      ",\n",
      "Planck\n",
      "was\n",
      "investigating\n",
      "the\n",
      "problem\n",
      "of\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "first\n",
      "posed\n",
      "by\n",
      "Kirchhoff\n",
      "some\n",
      "forty\n",
      "years\n",
      "earlier\n",
      ".\n",
      "It\n",
      "is\n",
      "well\n",
      "known\n",
      "that\n",
      "hot\n",
      "objects\n",
      "glow\n",
      ",\n",
      "and\n",
      "that\n",
      "hotter\n",
      "objects\n",
      "glow\n",
      "brighter\n",
      "than\n",
      "cooler\n",
      "ones\n",
      ".\n",
      "The\n",
      "electromagnetic\n",
      "field\n",
      "obeys\n",
      "laws\n",
      "of\n",
      "motion\n",
      "similarly\n",
      "to\n",
      "a\n",
      "mass\n",
      "on\n",
      "a\n",
      "spring\n",
      ",\n",
      "and\n",
      "can\n",
      "come\n",
      "to\n",
      "thermal\n",
      "equilibrium\n",
      "with\n",
      "hot\n",
      "atoms\n",
      ".\n",
      "The\n",
      "hot\n",
      "object\n",
      "in\n",
      "equilibrium\n",
      "with\n",
      "light\n",
      "absorbs\n",
      "just\n",
      "as\n",
      "The\n",
      "assumption\n",
      "that\n",
      "black\n",
      "-\n",
      "body\n",
      "radiation\n",
      "is\n",
      "thermal\n",
      "leads\n",
      "to\n",
      "an\n",
      "accurate\n",
      "prediction\n",
      ":\n",
      "the\n",
      "total\n",
      "amount\n",
      "of\n",
      "emitted\n",
      "energy\n",
      "goes\n",
      "up\n",
      "with\n",
      "the\n",
      "temperature\n",
      "according\n",
      "to\n",
      "a\n",
      "definite\n",
      "rule\n",
      ",\n",
      "the\n",
      "Stefan\n",
      "–\n",
      "Boltzmann\n",
      "law\n",
      "(\n",
      "1879–84\n",
      ")\n",
      ".\n",
      "But\n",
      "it\n",
      "was\n",
      "also\n",
      "known\n",
      "that\n",
      "the\n",
      "colour\n",
      "of\n",
      "the\n",
      "light\n",
      "given\n",
      "off\n",
      "by\n",
      "a\n",
      "hot\n",
      "object\n",
      "changes\n",
      "with\n",
      "the\n",
      "temperature\n",
      ",\n",
      "so\n",
      "that\n",
      "\"\n",
      "white\n",
      "hot\n",
      "\"\n",
      "is\n",
      "hotter\n",
      "than\n",
      "\"\n",
      "red\n",
      "hot\n",
      "\"\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "Wilhelm\n",
      "Wien\n",
      "discovered\n",
      "the\n",
      "mathematical\n",
      "relationship\n",
      "between\n",
      "the\n",
      "peaks\n",
      "of\n",
      "the\n",
      "curves\n",
      "at\n",
      "different\n",
      "temperatures\n",
      ",\n",
      "by\n",
      "using\n",
      "the\n",
      "principle\n",
      "of\n",
      "adiabatic\n",
      "invariance\n",
      ".\n",
      "At\n",
      "each\n",
      "different\n",
      "temperature\n",
      ",\n",
      "the\n",
      "curve\n",
      "is\n",
      "moved\n",
      "over\n",
      "by\n",
      "Wien\n",
      "'s\n",
      "displacement\n",
      "law\n",
      "(\n",
      "1893\n",
      ")\n",
      ".\n",
      "Wien\n",
      "also\n",
      "proposed\n",
      "an\n",
      "approximation\n",
      "for\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "the\n",
      "object\n",
      ",\n",
      "which\n",
      "was\n",
      "correct\n",
      "at\n",
      "high\n",
      "frequencies\n",
      "(\n",
      "short\n",
      "wavelength\n",
      ")\n",
      "but\n",
      "not\n",
      "at\n",
      "low\n",
      "frequencies\n",
      "(\n",
      "long\n",
      "wavelength\n",
      ")\n",
      ".\n",
      "It\n",
      "still\n",
      "was\n",
      "not\n",
      "clear\n",
      "why\n",
      "the\n",
      "spectrum\n",
      "of\n",
      "a\n",
      "hot\n",
      "object\n",
      "had\n",
      "the\n",
      "form\n",
      "that\n",
      "it\n",
      "has\n",
      "(\n",
      "see\n",
      "diagram\n",
      ")\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "second\n",
      "-\n",
      "generation\n",
      "renewables\n",
      ",\n",
      "such\n",
      "as\n",
      "wind\n",
      "power\n",
      ",\n",
      "have\n",
      "high\n",
      "potential\n",
      "and\n",
      "have\n",
      "already\n",
      "realised\n",
      "relatively\n",
      "low\n",
      "production\n",
      "costs\n",
      ".\n",
      "Global\n",
      "wind\n",
      "power\n",
      "installations\n",
      "increased\n",
      "by\n",
      "35,800\n",
      "MW\n",
      "in\n",
      "2010\n",
      ",\n",
      "bringing\n",
      "total\n",
      "installed\n",
      "capacity\n",
      "up\n",
      "to\n",
      "194,400\n",
      "MW\n",
      ",\n",
      "a\n",
      "22.5\n",
      "%\n",
      "increase\n",
      "on\n",
      "the\n",
      "158,700\n",
      "MW\n",
      "installed\n",
      "at\n",
      "the\n",
      "end\n",
      "of\n",
      "2009\n",
      ".\n",
      "The\n",
      "increase\n",
      "for\n",
      "2010\n",
      "represents\n",
      "investments\n",
      "totalling\n",
      "€\n",
      "47.3\n",
      "billion\n",
      "(\n",
      "US$\n",
      "65\n",
      "billion\n",
      ")\n",
      "and\n",
      "for\n",
      "the\n",
      "first\n",
      "time\n",
      "more\n",
      "than\n",
      "half\n",
      "of\n",
      "all\n",
      "new\n",
      "wind\n",
      "power\n",
      "was\n",
      "added\n",
      "outside\n",
      "of\n",
      "the\n",
      "traditional\n",
      "markets\n",
      "of\n",
      "Europe\n",
      "and\n",
      "North\n",
      "America\n",
      ",\n",
      "mainly\n",
      "driven\n",
      ",\n",
      "by\n",
      "the\n",
      "continuing\n",
      "boom\n",
      "in\n",
      "China\n",
      "which\n",
      "accounted\n",
      "for\n",
      "nearly\n",
      "half\n",
      "of\n",
      "all\n",
      "of\n",
      "the\n",
      "installations\n",
      "at\n",
      "16,500\n",
      "MW\n",
      ".\n",
      "China\n",
      "now\n",
      "has\n",
      "42,300\n",
      "MW\n",
      "of\n",
      "wind\n",
      "power\n",
      "installed\n",
      ".\n",
      "Wind\n",
      "power\n",
      "accounts\n",
      "for\n",
      "approximately\n",
      "19\n",
      "%\n",
      "of\n",
      "electricity\n",
      "generated\n",
      "in\n",
      "Denmark\n",
      ",\n",
      "9\n",
      "%\n",
      "in\n",
      "Spain\n",
      "and\n",
      "Portugal\n",
      ",\n",
      "and\n",
      "6\n",
      "%\n",
      "in\n",
      "Germany\n",
      "and\n",
      "the\n",
      "Republic\n",
      "of\n",
      "Ireland\n",
      ".\n",
      "In\n",
      "Australian\n",
      "state\n",
      "of\n",
      "South\n",
      "Australia\n",
      "wind\n",
      "power\n",
      ",\n",
      "championed\n",
      "by\n",
      "Premier\n",
      "Mike\n",
      "Rann\n",
      "(\n",
      "2002–2011\n",
      ")\n",
      ",\n",
      "now\n",
      "comprises\n",
      "26\n",
      "%\n",
      "of\n",
      "the\n",
      "state\n",
      "'s\n",
      "electricity\n",
      "generation\n",
      ",\n",
      "edging\n",
      "out\n",
      "coal\n",
      "fired\n",
      "power\n",
      ".\n",
      "At\n",
      "the\n",
      "end\n",
      "of\n",
      "2011\n",
      "South\n",
      "Australia\n",
      ",\n",
      "with\n",
      "7.2\n",
      "%\n",
      "of\n",
      "Australia\n",
      "'s\n",
      "population\n",
      ",\n",
      "had\n",
      "54%of\n",
      "the\n",
      "nation\n",
      "'s\n",
      "installed\n",
      "wind\n",
      "power\n",
      "capacity\n",
      ".\n",
      "Wind\n",
      "power\n",
      "'s\n",
      "share\n",
      "of\n",
      "worldwide\n",
      "electricity\n",
      "usage\n",
      "at\n",
      "the\n",
      "end\n",
      "of\n",
      "2014\n",
      "was\n",
      "3.1\n",
      "%\n",
      ".\n",
      "These\n",
      "are\n",
      "some\n",
      "of\n",
      "the\n",
      "largest\n",
      "wind\n",
      "farms\n",
      "in\n",
      "the\n",
      "world\n",
      ":\n",
      "According\n",
      "to\n",
      "a\n",
      "2011\n",
      "projection\n",
      "by\n",
      "the\n",
      "International\n",
      "Energy\n",
      "Agency\n",
      ",\n",
      "solar\n",
      "power\n",
      "plants\n",
      "may\n",
      "produce\n",
      "most\n",
      "of\n",
      "the\n",
      "world\n",
      "'s\n",
      "electricity\n",
      "within\n",
      "50\n",
      "years\n",
      ",\n",
      "significantly\n",
      "reducing\n",
      "the\n",
      "emissions\n",
      "of\n",
      "greenhouse\n",
      "gases\n",
      "that\n",
      "harm\n",
      "the\n",
      "environment\n",
      ".\n",
      "The\n",
      "IEA\n",
      "has\n",
      "said\n",
      ":\n",
      "\"\n",
      "Photovoltaic\n",
      "and\n",
      "solar\n",
      "-\n",
      "thermal\n",
      "plants\n",
      "may\n",
      "meet\n",
      "most\n",
      "of\n",
      "the\n",
      "world\n",
      "'s\n",
      "demand\n",
      "for\n",
      "electricity\n",
      "by\n",
      "2060\n",
      "–\n",
      "and\n",
      "half\n",
      "of\n",
      "all\n",
      "energy\n",
      "polled\n",
      "the\n",
      "twenty\n",
      "-\n",
      "seven\n",
      "EU\n",
      "member\n",
      "states\n",
      "about\n",
      "the\n",
      "target\n",
      "\"\n",
      "to\n",
      "increase\n",
      "the\n",
      "share\n",
      "of\n",
      "renewable\n",
      "energy\n",
      "in\n",
      "the\n",
      "EU\n",
      "by\n",
      "20\n",
      "percent\n",
      "by\n",
      "2020\n",
      "\"\n",
      ".\n",
      "Most\n",
      "people\n",
      "in\n",
      "all\n",
      "twenty\n",
      "-\n",
      "seven\n",
      "countries\n",
      "either\n",
      "approved\n",
      "of\n",
      "the\n",
      "target\n",
      "or\n",
      "called\n",
      "for\n",
      "it\n",
      "to\n",
      "go\n",
      "further\n",
      ".\n",
      "Across\n",
      "the\n",
      "EU\n",
      ",\n",
      "57\n",
      "percent\n",
      "thought\n",
      "the\n",
      "proposed\n",
      "goal\n",
      "was\n",
      "\"\n",
      "about\n",
      "right\n",
      "\"\n",
      "and\n",
      "16\n",
      "percent\n",
      "thought\n",
      "it\n",
      "was\n",
      "\"\n",
      "too\n",
      "modest\n",
      ".\n",
      "\"\n",
      "In\n",
      "comparison\n",
      ",\n",
      "19\n",
      "percent\n",
      "said\n",
      "it\n",
      "was\n",
      "\"\n",
      "too\n",
      "ambitious\n",
      "\"\n",
      ".\n",
      "A\n",
      "number\n",
      "of\n",
      "events\n",
      "in\n",
      "2006\n",
      "2006 DATE\n",
      "New\n",
      "government\n",
      "spending\n",
      ",\n",
      "regulation\n",
      ",\n",
      "and\n",
      "policies\n",
      "helped\n",
      "the\n",
      "industry\n",
      "weather\n",
      "the\n",
      "2009\n",
      "economic\n",
      "crisis\n",
      "better\n",
      "than\n",
      "many\n",
      "other\n",
      "sectors\n",
      ".\n",
      "Most\n",
      "notably\n",
      ",\n",
      "U.S.\n",
      "President\n",
      "Barack\n",
      "Obama\n",
      "'s\n",
      "American\n",
      "Recovery\n",
      "and\n",
      "Reinvestment\n",
      "Act\n",
      "of\n",
      "2009\n",
      "included\n",
      "more\n",
      "than\n",
      "$\n",
      "70\n",
      "billion\n",
      "in\n",
      "direct\n",
      "spending\n",
      "and\n",
      "tax\n",
      "credits\n",
      "for\n",
      "clean\n",
      "energy\n",
      "and\n",
      "associated\n",
      "transportation\n",
      "programs\n",
      ".\n",
      "This\n",
      "policy\n",
      "-\n",
      "stimulus\n",
      "combination\n",
      "represents\n",
      "the\n",
      "largest\n",
      "federal\n",
      "commitment\n",
      "in\n",
      "U.S.\n",
      "history\n",
      "for\n",
      "renewables\n",
      ",\n",
      "advanced\n",
      "transportation\n",
      ",\n",
      "and\n",
      "energy\n",
      "conservation\n",
      "initiatives\n",
      ".\n",
      "Based\n",
      "on\n",
      "these\n",
      "new\n",
      "rules\n",
      ",\n",
      "many\n",
      "more\n",
      "utilities\n",
      "strengthened\n",
      "their\n",
      "clean\n",
      "-\n",
      "energy\n",
      "programs\n",
      ".\n",
      "Clean\n",
      "Edge\n",
      "suggests\n",
      "that\n",
      "the\n",
      "commercialization\n",
      "of\n",
      "clean\n",
      "energy\n",
      "will\n",
      "help\n",
      "countries\n",
      "around\n",
      "the\n",
      "world\n",
      "deal\n",
      "with\n",
      "the\n",
      "current\n",
      "economic\n",
      "malaise\n",
      ".\n",
      "Once\n",
      "-\n",
      "promising\n",
      "solar\n",
      "energy\n",
      "company\n",
      ",\n",
      "Solyndra\n",
      "Solyndra PERSON\n",
      "Worldwide\n",
      "use\n",
      "of\n",
      "solar\n",
      "power\n",
      "and\n",
      "wind\n",
      "power\n",
      "continued\n",
      "to\n",
      "grow\n",
      "significantly\n",
      "in\n",
      "2012\n",
      ".\n",
      "Solar\n",
      "electricity\n",
      "consumption\n",
      "increased\n",
      "by\n",
      "58\n",
      "percent\n",
      ",\n",
      "to\n",
      "93\n",
      "terawatt\n",
      "-\n",
      "hours\n",
      "(\n",
      "TWh\n",
      ")\n",
      ".\n",
      "Use\n",
      "of\n",
      "wind\n",
      "power\n",
      "in\n",
      "2012\n",
      "increased\n",
      "by\n",
      "18.1\n",
      "percent\n",
      ",\n",
      "to\n",
      "521.3\n",
      "TWh\n",
      ".\n",
      "Global\n",
      "solar\n",
      "and\n",
      "wind\n",
      "energy\n",
      "installed\n",
      "capacities\n",
      "continued\n",
      "to\n",
      "expand\n",
      "even\n",
      "though\n",
      "new\n",
      "investments\n",
      "in\n",
      "these\n",
      "technologies\n",
      "declined\n",
      "during\n",
      "2012\n",
      ".\n",
      "Worldwide\n",
      "investment\n",
      "in\n",
      "solar\n",
      "power\n",
      "in\n",
      "2012\n",
      "was\n",
      "$\n",
      "140.4\n",
      "billion\n",
      ",\n",
      "an\n",
      "11\n",
      "percent\n",
      "decline\n",
      "from\n",
      "2011\n",
      ",\n",
      "and\n",
      "wind\n",
      "power\n",
      "investment\n",
      "was\n",
      "down\n",
      "10.1\n",
      "percent\n",
      ",\n",
      "to\n",
      "$\n",
      "80.3\n",
      "billion\n",
      ".\n",
      "But\n",
      "due\n",
      "to\n",
      "lower\n",
      "production\n",
      "costs\n",
      "for\n",
      "both\n",
      "technologies\n",
      ",\n",
      "total\n",
      "installed\n",
      "capacities\n",
      "grew\n",
      "sharply\n",
      ".\n",
      "This\n",
      "investment\n",
      "decline\n",
      ",\n",
      "but\n",
      "growth\n",
      "in\n",
      "installed\n",
      "capacity\n",
      ",\n",
      "may\n",
      "again\n",
      "occur\n",
      "in\n",
      "2013\n",
      ".\n",
      "Analysts\n",
      "expect\n",
      "the\n",
      "market\n",
      "to\n",
      "triple\n",
      "by\n",
      "2030\n",
      ".\n",
      "In\n",
      "2015\n",
      ",\n",
      "investment\n",
      "in\n",
      "renewables\n",
      "exceeded\n",
      "fossils\n",
      ".\n",
      "The\n",
      "incentive\n",
      "to\n",
      "use\n",
      "100\n",
      "%\n",
      "renewable\n",
      "energy\n",
      ",\n",
      "for\n",
      "electricity\n",
      ",\n",
      "transport\n",
      ",\n",
      "or\n",
      "even\n",
      "total\n",
      "primary\n",
      "energy\n",
      "supply\n",
      "globally\n",
      ",\n",
      "has\n",
      "been\n",
      "motivated\n",
      "by\n",
      "global\n",
      "warming\n",
      "and\n",
      "other\n",
      "ecological\n",
      "as\n",
      "well\n",
      "as\n",
      "economic\n",
      "concerns\n",
      ".\n",
      "The\n",
      "Intergovernmental\n",
      "Panel\n",
      "on\n",
      "Climate\n",
      "Change\n",
      "has\n",
      "said\n",
      "that\n",
      "there\n",
      "are\n",
      "few\n",
      "fundamental\n",
      "technological\n",
      "limits\n",
      "to\n",
      "integrating\n",
      "a\n",
      "portfolio\n",
      "of\n",
      "renewable\n",
      "energy\n",
      "technologies\n",
      "to\n",
      "meet\n",
      "most\n",
      "of\n",
      "total\n",
      "global\n",
      "energy\n",
      "demand\n",
      ".\n",
      "In\n",
      "reviewing\n",
      "164\n",
      "recent\n",
      "scenarios\n",
      "of\n",
      "future\n",
      "renewable\n",
      "energy\n",
      "growth\n",
      ",\n",
      "the\n",
      "report\n",
      "noted\n",
      "that\n",
      "the\n",
      "majority\n",
      "expected\n",
      "renewable\n",
      "sources\n",
      "to\n",
      "supply\n",
      "more\n",
      "than\n",
      "17\n",
      "%\n",
      "of\n",
      "total\n",
      "energy\n",
      "by\n",
      "2030\n",
      ",\n",
      "and\n",
      "27\n",
      "%\n",
      "by\n",
      "2050\n",
      ";\n",
      "the\n",
      "highest\n",
      "forecast\n",
      "projected\n",
      "43\n",
      "%\n",
      "supplied\n",
      "by\n",
      "renewables\n",
      "by\n",
      "2030\n",
      "and\n",
      "77\n",
      "%\n",
      "by\n",
      "2050\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "\n",
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "f2.close()\n",
    "doc_dict = json.loads(a)\n",
    "\n",
    "f4 = open(\"./assignment_group/project_files/training.json\")\n",
    "a = f4.readline()\n",
    "f4.close()\n",
    "trains = json.loads(a)\n",
    "print (len(trains))\n",
    "# print (trains[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "    model='en'\n",
    "    print(\"asdfasdf\")\n",
    "    nlp = spacy.load(model)\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "    print(\"Processing %d texts\" % len(TEXTS))\n",
    "\n",
    "    for text in TEXTS:\n",
    "        doc = nlp(text)\n",
    "        relations = extract_currency_relations(doc)\n",
    "        for r1, r2 in relations:\n",
    "            print('{:<10}\\t{}\\t{}'.format(r1.text, r2.ent_type_, r2.text))\n",
    "\n",
    "\n",
    "def extract_currency_relations(doc):\n",
    "    print(doc)\n",
    "    # merge entities and noun chunks into one token\n",
    "    print(doc.ents)\n",
    "    print(doc.noun_chunks)\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    print(spans)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = []\n",
    "    for money in doc:\n",
    "        if money.ent_type_ != \"\":\n",
    "#             print(money.text, money.pos_, money.dep_)\n",
    "            print(money,\"-------------\",money.head,\"------\",list(money.head.lefts))\n",
    "#         print(money,money.ent_type_)\n",
    "    \n",
    "\n",
    "    \n",
    "#     for money in filter(lambda w: w.ent_type_ == 'MONEY', doc):\n",
    "#         if money.dep_ in ('attr', 'dobj'):\n",
    "#             subject = [w for w in money.head.lefts if w.dep_ == 'nsubj']\n",
    "#             if subject:\n",
    "#                 subject = subject[0]\n",
    "#                 relations.append((subject, money))\n",
    "#         elif money.dep_ == 'pobj' and money.head.dep_ == 'prep':\n",
    "#             relations.append((money.head.head, money))\n",
    "    return relations\n",
    "\n",
    "text = \"The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum.\"\n",
    "model='en'\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "for train in trains:\n",
    "    question = train[\"question\"]\n",
    "    paraid = train[\"answer_paragraph\"]\n",
    "    docid = train[\"docid\"]\n",
    "    answer = train[\"text\"]\n",
    "    para = doc_dict[docid][\"text\"][paraid]\n",
    "    \n",
    "#     print (question,answer)\n",
    "#     print(para)\n",
    "    doc = nlp(para)\n",
    "    for token in doc:\n",
    "        print(token.text)\n",
    "        if token.text.lower() == answer:\n",
    "            if token.dep_ in ('attr', 'dobj'):\n",
    "                subject = [w for w in token.head.lefts if w.dep_ == 'nsubj']\n",
    "                if subject:\n",
    "    #                 print(subject)\n",
    "                    subject = subject[0]\n",
    "#                     relations.append((subject, token))\n",
    "#                     print(subject, token)\n",
    "                count4+=1\n",
    "            elif token.dep_ == 'pobj' and token.head.dep_ == 'prep':\n",
    "#                 relations.append((token.head.head, token))\n",
    "#                 print(token.head.head, token)\n",
    "                count4+=1\n",
    "#             print(token,token.pos_,token.dep_)\n",
    "#             print(token,\"-------------\",token.head,\"------\",list(token.head.lefts))\n",
    "            count3+=1\n",
    "#             break\n",
    "            if token.ent_type_!=\"\":\n",
    "                print(token,token.ent_type_)\n",
    "                count2+=1\n",
    "                break\n",
    "#             if token.ent_type_ != \"\":\n",
    "#         #             print(money.text, money.pos_, money.dep_)\n",
    "#                 print(token,\"-------------\",token.head,\"------\",list(token.head.lefts))\n",
    "    \n",
    "#     temp_tag_para = pos_tag(word_tokenize(para))\n",
    "#     root = nltk.ne_chunk(temp_tag_para)\n",
    "    \n",
    "    count+=1\n",
    "    if count >100:\n",
    "        break\n",
    "print(count2)\n",
    "print(count3)\n",
    "print(count4)\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43379\n",
      "schrödinger Bohr\n",
      "Who helped to give the correct quantization rules for electrons in 1926?\n",
      " The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum\n",
      "heinrich hertz Alexandre Edmond Becquerel\n",
      "Who published the first thorough investigation of the photoelectric effect?\n",
      " It was first observed by Alexandre Edmond Becquerel in 1839, although credit is usually reserved for Heinrich Hertz, who published the first thorough investigation in 1887\n",
      "alexandre edmond becquerel\n",
      "paul ehrenfest Rayleigh\n",
      "Who came up with the term, \"ultraviolet catastrophe\"?\n",
      "The black-body problem was revisited in 1905, when Rayleigh and Jeans (on the one hand) and Einstein (on the other hand) independently proved that classical electromagnetism could never account for the observed spectrum\n",
      "alexandre edmond becquerel\n",
      "heisenberg Bohr\n",
      "Who helped to give the correct quantization rules for electrons in 1925?\n",
      " The correct quantization rules for electrons – in which the energy reduces to the Bohr model equation in the case of the hydrogen atom – were given by Heisenberg's matrix mechanics in 1925 and the Schrödinger wave equation in 1926: the reduced Planck constant remains the fundamental quantum of angular momentum\n",
      "0\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('D:/websearch/stanford/stanford-ner-2015-12-09/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "                       ,'D:/websearch/stanford/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "\n",
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "f2.close()\n",
    "doc_dict = json.loads(a)\n",
    "\n",
    "f4 = open(\"./assignment_group/project_files/training.json\")\n",
    "a = f4.readline()\n",
    "f4.close()\n",
    "trains = json.loads(a)\n",
    "print (len(trains))\n",
    "\n",
    "model='en'\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "for train in trains:\n",
    "    question = train[\"question\"]\n",
    "    paraid = train[\"answer_paragraph\"]\n",
    "    docid = train[\"docid\"]\n",
    "    answer = train[\"text\"]\n",
    "    para = doc_dict[docid][\"text\"][paraid]\n",
    "    \n",
    "    ques =  nlp(question)\n",
    "    for word in ques:\n",
    "        if word.text.lower() == \"who\":\n",
    "#             doc = nlp(para)\n",
    "#             for token in doc:\n",
    "#                 if token.ent_type_ == \"PERSON\":\n",
    "#                     if token.text.lower() == answer:\n",
    "#                         count2+=1\n",
    "#                 if token.text.lower() == answer:\n",
    "# #                     print(token.text,token.ent_type_)\n",
    "#                     break\n",
    "\n",
    "\n",
    "            words = re.split(\",|\\.| |\\?|!\",question)\n",
    "            num_question = []\n",
    "            for word in words:\n",
    "                if word.isalnum():\n",
    "                    tempword = myLemmatize(lemmatizer,word.lower())\n",
    "                    if tempword not in stopWords:\n",
    "                        num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "            matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "            matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "            cos_sims = cosine_similarity(matr,matr_para)\n",
    "            sentenceid = np.argmax(cos_sims[0])\n",
    "            tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "            classified_text = st.tag(tokenized_text)\n",
    "    \n",
    "#             tokenized_text = word_tokenize(para)\n",
    "#             classified_text = st.tag(tokenized_text)\n",
    "            new_classified_text = []\n",
    "            temp = classified_text[0][0]\n",
    "            lastNer = classified_text[0][1]\n",
    "            for i in range(1,len(classified_text)):\n",
    "                if classified_text[i][1] == lastNer:\n",
    "                    temp+=(\" \"+classified_text[i][0])\n",
    "                else:\n",
    "                    new_classified_text.append((temp,lastNer))\n",
    "                    temp = classified_text[i][0]\n",
    "                    lastNer = classified_text[i][1]\n",
    "            else:\n",
    "                new_classified_text.append((temp,lastNer))\n",
    "            for tup in new_classified_text:\n",
    "                if tup[1] == \"PERSON\":\n",
    "#                     print(tup[0])\n",
    "                    if tup[0].lower() == answer:\n",
    "                        count3+=1\n",
    "                        break\n",
    "                    else:\n",
    "                        print(answer,tup[0])\n",
    "                        print(question)\n",
    "                        print(doct_para_sentence[docid][paraid][sentenceid])\n",
    "                        break\n",
    "            else:\n",
    "                print(answer)\n",
    "            count+=1\n",
    "    if count>10:\n",
    "        break\n",
    "print(count2)\n",
    "print(count3)\n",
    "print(count4)\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "count_doc = 0\n",
    "count_para = 0\n",
    "print (len(devel))\n",
    "for j,qa in enumerate(devel[:100]):\n",
    "    question = qa[\"question\"]\n",
    "    paraid = qa[\"answer_paragraph\"]\n",
    "    docid = qa[\"docid\"]\n",
    "    answer = qa[\"text\"]\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_para)\n",
    "    sentenceid = np.argmax(cos_sims[0])\n",
    "    tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    \n",
    "    \n",
    "\n",
    "    if j%30==0:\n",
    "        print (j)\n",
    "print (count_doc)\n",
    "print (count_para)\n",
    "print (len(devel))\n",
    "#     print cos_sims[0][paraindex:paraindex+10]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "a = f3.readline()\n",
    "f3.close()\n",
    "devel = json.loads(a)\n",
    "count_doc = 0\n",
    "count_para = 0\n",
    "print (len(devel))\n",
    "for j,qa in enumerate(devel[:100]):\n",
    "    question = qa[\"question\"]\n",
    "    paraid = qa[\"answer_paragraph\"]\n",
    "    docid = qa[\"docid\"]\n",
    "    answer = qa[\"text\"]\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_doc)\n",
    "    paraindex = np.argmax(cos_sims[0])\n",
    "    for wi in num_question:\n",
    "        if wi in keyword_para_numset:\n",
    "            if docid ==  wordnum_freq_para[wi][0][0]:\n",
    "                count_doc+=1\n",
    "                if paraid == wordnum_freq_para[wi][0][1]:\n",
    "                    paraindex = wordnum_freq_para[wi][0][1]\n",
    "                    count_para+=1\n",
    "            break\n",
    "    else:\n",
    "        start = doc_para[docid][0]\n",
    "        end = doc_para[docid][1]\n",
    "        paraindex = np.argmax(cos_sims[0][start:end])\n",
    "        if paraid == para_doc[paraindex+start][1]:\n",
    "            count_para+=1\n",
    "        paraindex = para_doc[paraindex+start][1]\n",
    "    \n",
    "    \n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_para)\n",
    "    sentenceid = np.argmax(cos_sims[0])\n",
    "    tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "\n",
    "    new_classified_text = []\n",
    "    temp = classified_text[0][0]\n",
    "    lastNer = classified_text[0][1]\n",
    "    for i in range(1,len(classified_text)):\n",
    "        if classified_text[i][1] == lastNer:\n",
    "            temp+=(\" \"+classified_text[i][0])\n",
    "        else:\n",
    "            new_classified_text.append((temp,lastNer))\n",
    "            temp = classified_text[i][0]\n",
    "            lastNer = classified_text[i][1]\n",
    "    else:\n",
    "        new_classified_text.append((temp,lastNer))\n",
    "    for tup in new_classified_text:\n",
    "        if tup[1] == \"PERSON\":\n",
    "#                     print(tup[0])\n",
    "            if tup[0].lower() == answer:\n",
    "                count3+=1\n",
    "                break\n",
    "            else:\n",
    "                print(answer,tup[0])\n",
    "                print(question)\n",
    "                print(doct_para_sentence[docid][paraid][sentenceid])\n",
    "                break\n",
    "    else:\n",
    "        print(answer)\n",
    "\n",
    "\n",
    "\n",
    "    if j%30==0:\n",
    "        print (j)\n",
    "print (count_doc)\n",
    "print (count_para)\n",
    "print (len(devel))\n",
    "#     print cos_sims[0][paraindex:paraindex+10]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sentence', 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "def rankByAppendDistance(question, sentence):    \n",
    "    question_words_set = set()\n",
    "    for word in question:\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        if tempword not in stopWords:\n",
    "            question_words_set.add(tempword)\n",
    "    \n",
    "    question_words_index_in_sentence = []\n",
    "    for i,word in enumerate(sentence):\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        if tempword in question_words_set:\n",
    "            question_words_index_in_sentence.append(i)\n",
    "    \n",
    "    distances = []\n",
    "    for i,word in enumerate(sentence):\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        distance = 0\n",
    "        if tempword not in question_words_set:\n",
    "            for index in question_words_index_in_sentence:\n",
    "                if index < i:\n",
    "                    distance+=(i-index)\n",
    "                else:\n",
    "                    distance+=(index-i)\n",
    "            distances.append((word,distance,i))\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return distances\n",
    "\n",
    "def rankByAppendDistance2(ques, sent):    \n",
    "    question_words_set = set()\n",
    "    question = [c.text for c in ques]\n",
    "    sentence = [c.text for c in sent]\n",
    "    \n",
    "    for word in question:\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        if tempword not in stopWords:\n",
    "            question_words_set.add(tempword)\n",
    "    \n",
    "    question_words_index_in_sentence = []\n",
    "    for i,word in enumerate(sentence):\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        if tempword in question_words_set:\n",
    "            question_words_index_in_sentence.append(i)\n",
    "    \n",
    "    distances = []\n",
    "    for i,word in enumerate(sentence):\n",
    "        tempword = myLemmatize(lemmatizer,word.lower())\n",
    "        distance = 0\n",
    "        if tempword not in question_words_set:\n",
    "            if sent[i].tag_.startswith(\"NN\") or sent[i].tag_ == \"XX\":\n",
    "                if i < len(sent)-1 and sent[i+1].text == \"of\":\n",
    "                    continue\n",
    "                for index in question_words_index_in_sentence:\n",
    "                    if index < i:\n",
    "                        distance+=(i-index)\n",
    "                    else:\n",
    "                        distance+=(index-i)\n",
    "                distances.append((word,distance,i))\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return distances\n",
    "\n",
    "\n",
    "print (rankByAppendDistance([\"question\"], [\"sentence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_list = [\n",
    "            ('person','PERSON'),\n",
    "            ('location', 'LOCATION'),            \n",
    "            ('from', 'LOCATION'),\n",
    "            ('country', 'LOCATION'),\n",
    "            ('capital', 'LOCATION'),\n",
    "            ('city', 'LOCATION'),\n",
    "            ('many', 'NUMBER'),\n",
    "            ('long','NUMBER'),\n",
    "            ('high', 'NUMBER'),\n",
    "            ('year', 'NUMBER'),\n",
    "            ('decade', 'NUMBER'),\n",
    "            ('time', 'NUMBER'),\n",
    "            ('cost', 'NUMBER'),\n",
    "            ('population', 'NUMBER'),\n",
    "            ('number','NUMBER'),\n",
    "            ('size','NUMBER'),\n",
    "            ('much','NUMBER'),\n",
    "            ('value','NUMBER')\n",
    "        ]\n",
    "\n",
    "\n",
    "rules = [{},{},{}]\n",
    "rules[0][\"who\"] = \"PERSON\";\n",
    "rules[0][\"where\"] = \"LOCATION\"\n",
    "rules[0][\"when\"] = \"NUMBER\"\n",
    "rules[0][\"why\"] = \"OTHER\"\n",
    "\n",
    "\n",
    "\n",
    "for tup in rules_list:\n",
    "    rules[1][tup[0]] = tup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParaIndex(question,docid):\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_doc)\n",
    "    paraindex = np.argmax(cos_sims[0])\n",
    "    for wi in num_question:\n",
    "        if wi in keyword_para_numset:\n",
    "            if wordnum_freq_para[wi][0][0] == docid:\n",
    "                paraindex = wordnum_freq_para[wi][0][1]\n",
    "                break\n",
    "    else:\n",
    "        start = doc_para[docid][0]\n",
    "        end = doc_para[docid][1]\n",
    "        paraindex = np.argmax(cos_sims[0][start:end])\n",
    "        paraindex = para_doc[paraindex+start][1]\n",
    "    return paraindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43379\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('D:/websearch/stanford/stanford-ner-2015-12-09/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "                       ,'D:/websearch/stanford/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "\n",
    "f2 = open(\"./assignment_group/project_files/documents.json\")\n",
    "a = f2.readline()\n",
    "f2.close()\n",
    "doc_dict = json.loads(a)\n",
    "\n",
    "f4 = open(\"./assignment_group/project_files/training.json\")\n",
    "a = f4.readline()\n",
    "f4.close()\n",
    "trains = json.loads(a)\n",
    "print (len(trains))\n",
    "\n",
    "model='en'\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "answerTypeSet = set([\"NUMBER\",\"LOCATION\",\"PERSON\"])\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "for train in trains:\n",
    "    question = train[\"question\"]\n",
    "    paraid = train[\"answer_paragraph\"]\n",
    "    docid = train[\"docid\"]\n",
    "    answer = train[\"text\"]\n",
    "    para = doc_dict[docid][\"text\"][paraid]\n",
    "    \n",
    "    paraid = getParaIndex(question,docid)\n",
    "    ques =  nlp(question)\n",
    "    for word in ques:\n",
    "        if word.text.lower() in rules[0]:\n",
    "            answerType = rules[0][word.text.lower()]\n",
    "            break\n",
    "    else:\n",
    "        for word in ques:\n",
    "            if word.text.lower() in rules[1]:\n",
    "                answerType = rules[1][word.text.lower()]\n",
    "                break\n",
    "        else:\n",
    "            answerType = \"OTHER\"\n",
    "\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "    matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_para)\n",
    "    sentenceid = np.argmax(cos_sims[0])\n",
    "    \n",
    "    if answerType == \"OTHER\":\n",
    "        \n",
    "        \n",
    "        sent = nlp(doct_para_sentence[docid][paraid][sentenceid])\n",
    "        insent_distances = rankByAppendDistance2(ques,sent)\n",
    "        for temp in insent_distances:\n",
    "            if sent[temp[2]].ent_type_ not in answerTypeSet:  \n",
    "                chunk_start = sent[temp[2]].left_edge.i\n",
    "                chunk_end = sent[temp[2]].right_edge.i + 1  \n",
    "                tempanswer = []\n",
    "                for i in range(chunk_start,chunk_end):\n",
    "                    tempanswer.append(sent[i].text)\n",
    "                    tempanswer.append(\" \")\n",
    "                tempanswer.pop()\n",
    "#                 tempanswer = \"\".join(tempanswer)\n",
    "                \n",
    "                for i in range(max(0,chunk_start-2),chunk_start):\n",
    "                    if sent[i].text == \"of\":\n",
    "                        temp2 = []\n",
    "                        for j in range(i+1,chunk_start):\n",
    "                            temp2.append(sent[j].text)\n",
    "                            temp2.append(\" \")\n",
    "                        tempanswer =temp2+tempanswer\n",
    "                        break\n",
    "                if tempanswer[0] in [\"the\",\"a\",\"an\"]:\n",
    "#                     print(\"asdfasdfasdfasdfasdf\")\n",
    "                    tempanswer =tempanswer[2:]\n",
    "                tempanswer = \"\".join(tempanswer)\n",
    "#                 tempanswer = \"\".join(temp2)\n",
    "#                 temp3 = [-1]\n",
    "#                 for i in range(tempanswer):\n",
    "#                     if tempanswer[i] in [':',',','(',')','.','-','[', ']','\\`','\\\"','%',\"'\"]:\n",
    "#                         temp3.append(i)\n",
    "#                 temp3.append(len(tempanswer))\n",
    "#                 tempmax = 0\n",
    "#                 myanswer = [0,1]\n",
    "#                 for i in range(1,temp3):\n",
    "#                     if temp[i] - temp[i-1]-1 > tempmax:\n",
    "#                         tempmax = temp[i] - temp[i-1]-1\n",
    "#                         myanswer = [temp[i-1]+1,temp[i]]\n",
    "#                 myanswer = tempanswer[myanswer[0],myanswer[1]]\n",
    "#                 myanswer = myanswer.strip()\n",
    "                if tempanswer.lower() == answer:\n",
    "                    count3+=1\n",
    "#                 print(question)\n",
    "#                 print(answer,\"----------\",tempanswer.lower(),sent[temp[2]].tag_,\"------------\",temp2)\n",
    "#                 print(insent_distances)\n",
    "# #                 print(classified_text)\n",
    "#                 print([(c.text,c.tag_) for c in sent])\n",
    "                break\n",
    "        \n",
    "    else:\n",
    "#         continue\n",
    "        tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "        classified_text = st.tag(tokenized_text)\n",
    "\n",
    "        temp = []\n",
    "        for tup in classified_text:\n",
    "            if tup[0].isdigit():\n",
    "                temp.append((tup[0],\"NUMBER\"))\n",
    "            else:\n",
    "                temp.append(tup)\n",
    "        classified_text = temp\n",
    "        \n",
    "        new_classified_text = []\n",
    "        temp = classified_text[0][0]\n",
    "        lastNer = classified_text[0][1]\n",
    "        for i in range(1,len(classified_text)):\n",
    "            if classified_text[i][1] in ['PERSON','LOCATION','NUMBER'] and classified_text[i][1] == lastNer:\n",
    "                temp+=(\" \"+classified_text[i][0])\n",
    "            else:\n",
    "                new_classified_text.append((temp,lastNer))\n",
    "                temp = classified_text[i][0]\n",
    "                lastNer = classified_text[i][1]\n",
    "        else:\n",
    "            new_classified_text.append((temp,lastNer))\n",
    "        classified_text = new_classified_text\n",
    "        insent_distances = rankByAppendDistance(word_tokenize(question),[c[0] for c in classified_text])\n",
    "\n",
    "        for temp in insent_distances:\n",
    "            if classified_text[temp[2]][1] == answerType:\n",
    "                if classified_text[temp[2]][0].lower() == answer:\n",
    "                    count3+=1\n",
    "#                 print(question)\n",
    "#                 print(answer,\"----------\",classified_text[temp[2]],temp[2])\n",
    "#                 print(classified_text)\n",
    "#                 print(spacy_ner)\n",
    "                break\n",
    "                    \n",
    "    count+=1\n",
    "    print(count)\n",
    "    if count>10:\n",
    "        break\n",
    "print(count3)\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3618\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n"
     ]
    }
   ],
   "source": [
    "f4 = open(\"./assignment_group/project_files/testing.json\")\n",
    "a = f4.readline()\n",
    "f4.close()\n",
    "trains = json.loads(a)\n",
    "print (len(trains))\n",
    "\n",
    "import codecs\n",
    "\n",
    "# file = codecs.open(\"lol\", \"w\", \"utf-8\")\n",
    "# file.write(u'\\ufeff')\n",
    "# file.close()\n",
    "\n",
    "\n",
    "f5 = codecs.open(\"./assignment_group/project_files/lalala.csv\",\"w\",\"utf-8\")\n",
    "# f5.writelines(\"id,answer\\n\")\n",
    "\n",
    "count = 0\n",
    "for i in range(0,len(trains)):\n",
    "    question = trains[i][\"question\"]\n",
    "#     paraid = train[\"answer_paragraph\"]\n",
    "    docid = trains[i][\"docid\"]\n",
    "    testid = trains[i][\"id\"]\n",
    "#     answer = train[\"text\"]\n",
    "#     para = doc_dict[docid][\"text\"][paraid]\n",
    "    \n",
    "    paraid = getParaIndex(question,docid)\n",
    "    ques =  nlp(question)\n",
    "    for word in ques:\n",
    "        if word.text.lower() in rules[0]:\n",
    "            answerType = rules[0][word.text.lower()]\n",
    "            break\n",
    "    else:\n",
    "        for word in ques:\n",
    "            if word.text.lower() in rules[1]:\n",
    "                answerType = rules[1][word.text.lower()]\n",
    "                break\n",
    "        else:\n",
    "            answerType = \"OTHER\"\n",
    "\n",
    "    words = re.split(\",|\\.| |\\?|!\",question)\n",
    "    num_question = []\n",
    "    for word in words:\n",
    "        if word.isalnum():\n",
    "            tempword = myLemmatize(lemmatizer,word.lower())\n",
    "            if tempword not in stopWords:\n",
    "                num_question.append(word_numbers.get(tempword,len(word_numbers)))\n",
    "    matr = getSparseMatrix([num_question],len(word_numbers))\n",
    "#     print (doc_para_sentence_number[docid])\n",
    "#     print (paraid)\n",
    "#     print(len(doc_para_sentence_number[docid]))\n",
    "#     print (docid)\n",
    "#     print (doc_para_sentence_number[docid][paraid])\n",
    "    matr_para = getSparseMatrix(doc_para_sentence_number[docid][paraid],len(word_numbers))\n",
    "    cos_sims = cosine_similarity(matr,matr_para)\n",
    "    sentenceid = np.argmax(cos_sims[0])\n",
    "    \n",
    "    tempanswer = \"unk\"\n",
    "    if answerType == \"OTHER\":\n",
    "        sent = nlp(doct_para_sentence[docid][paraid][sentenceid])\n",
    "        insent_distances = rankByAppendDistance2(ques,sent)\n",
    "        for temp in insent_distances:\n",
    "            if sent[temp[2]].ent_type_ not in answerTypeSet:  \n",
    "                chunk_start = sent[temp[2]].left_edge.i\n",
    "                chunk_end = sent[temp[2]].right_edge.i + 1  \n",
    "                tempanswer = []\n",
    "                for i in range(chunk_start,chunk_end):\n",
    "                    tempanswer.append(sent[i].text)\n",
    "                    tempanswer.append(\" \")\n",
    "                tempanswer.pop()\n",
    "#                 tempanswer = \"\".join(tempanswer)\n",
    "                \n",
    "                for i in range(max(0,chunk_start-2),chunk_start):\n",
    "                    if sent[i].text == \"of\":\n",
    "                        temp2 = []\n",
    "                        for j in range(i+1,chunk_start):\n",
    "                            temp2.append(sent[j].text)\n",
    "                            temp2.append(\" \")\n",
    "                        tempanswer =temp2+tempanswer\n",
    "                        break\n",
    "                if tempanswer[0] in [\"the\",\"a\",\"an\"]:\n",
    "#                     print(\"asdfasdfasdfasdfasdf\")\n",
    "                    tempanswer =tempanswer[2:]\n",
    "                tempanswer = \"\".join(tempanswer)\n",
    "#                 tempanswer = \"\".join(temp2)\n",
    "#                 temp3 = [-1]\n",
    "#                 for i in range(tempanswer):\n",
    "#                     if tempanswer[i] in [':',',','(',')','.','-','[', ']','\\`','\\\"','%',\"'\"]:\n",
    "#                         temp3.append(i)\n",
    "#                 temp3.append(len(tempanswer))\n",
    "#                 tempmax = 0\n",
    "#                 myanswer = [0,1]\n",
    "#                 for i in range(1,temp3):\n",
    "#                     if temp[i] - temp[i-1]-1 > tempmax:\n",
    "#                         tempmax = temp[i] - temp[i-1]-1\n",
    "#                         myanswer = [temp[i-1]+1,temp[i]]\n",
    "#                 myanswer = tempanswer[myanswer[0],myanswer[1]]\n",
    "#                 myanswer = myanswer.strip()\n",
    "                tempanswer = tempanswer.lower()\n",
    "#                 if tempanswer == answer:\n",
    "#                     count3+=1\n",
    "#                 print(question)\n",
    "#                 print(answer,\"----------\",tempanswer.lower(),sent[temp[2]].tag_,\"------------\",temp2)\n",
    "#                 print(insent_distances)\n",
    "# #                 print(classified_text)\n",
    "#                 print([(c.text,c.tag_) for c in sent])\n",
    "                break\n",
    "        \n",
    "    else:\n",
    "#         continue\n",
    "        tokenized_text = word_tokenize(doct_para_sentence[docid][paraid][sentenceid])\n",
    "        classified_text = st.tag(tokenized_text)\n",
    "\n",
    "        temp = []\n",
    "        for tup in classified_text:\n",
    "            if tup[0].isdigit():\n",
    "                temp.append((tup[0],\"NUMBER\"))\n",
    "            else:\n",
    "                temp.append(tup)\n",
    "        classified_text = temp\n",
    "        \n",
    "        new_classified_text = []\n",
    "        temp = classified_text[0][0]\n",
    "        lastNer = classified_text[0][1]\n",
    "        for i in range(1,len(classified_text)):\n",
    "            if classified_text[i][1] in ['PERSON','LOCATION','NUMBER'] and classified_text[i][1] == lastNer:\n",
    "                temp+=(\" \"+classified_text[i][0])\n",
    "            else:\n",
    "                new_classified_text.append((temp,lastNer))\n",
    "                temp = classified_text[i][0]\n",
    "                lastNer = classified_text[i][1]\n",
    "        else:\n",
    "            new_classified_text.append((temp,lastNer))\n",
    "        classified_text = new_classified_text\n",
    "        insent_distances = rankByAppendDistance(word_tokenize(question),[c[0] for c in classified_text])\n",
    "\n",
    "        for temp in insent_distances:\n",
    "            if classified_text[temp[2]][1] == answerType:\n",
    "                tempanswer = classified_text[temp[2]][0].lower()\n",
    "#                 if classified_text[temp[2]][0].lower() == answer:\n",
    "#                     count3+=1\n",
    "#                 print(question)\n",
    "#                 print(answer,\"----------\",classified_text[temp[2]],temp[2])\n",
    "#                 print(classified_text)\n",
    "#                 print(spacy_ner)\n",
    "                break\n",
    "    f5.writelines(str(testid)+\",\"+tempanswer+\"\\n\");\n",
    "#     if count == 2:\n",
    "#         break\n",
    "    print(count)\n",
    "    count+=1\n",
    "f5.close()\n",
    "# print(count3)\n",
    "\n",
    "# f3 = open(\"./assignment_group/project_files/devel.json\")\n",
    "# a = f3.readline()\n",
    "# f3.close()\n",
    "# devels = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web-----------------\n",
      "web-----------------\n",
      "unk-----------------\n",
      "a browser extension-----------------\n",
      "1-----------------\n",
      "unk-----------------\n",
      "1990-----------------\n",
      "most browsers-----------------\n",
      "marc andreessen-----------------\n",
      "unk-----------------\n",
      "microsoft corp v commission-----------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-3c83659dedfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\")\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "f = codecs.open(\"./assignment_group/project_files/lalala.csv\",\"r\",\"utf-8\")\n",
    "strings = []\n",
    "while True:\n",
    "    temp = f.readline()\n",
    "    if not temp:\n",
    "        break\n",
    "    strings.append(temp)\n",
    "for i in range(1,len(strings)):\n",
    "    start = strings[i].index(\",\")\n",
    "    temp = strings[i][start+1:]\n",
    "    temp = temp.replace(\"\\\"\",\"\").replace(\":\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").strip()\n",
    "    \n",
    "    temp2 = [temp[0]]\n",
    "    for j in range(1,len(temp)):\n",
    "        if temp[j] == temp[j-1] and temp[j] == \" \":\n",
    "            continue\n",
    "        else:\n",
    "            temp2.append(temp[j])\n",
    "    temp = \"\".join(temp2)\n",
    "#     print(temp+\"-----------------\")\n",
    "    strings[i] =  strings[i][:start+1]+temp+\"\\n\"\n",
    "f.close()\n",
    "\n",
    "f = codecs.open(\"./assignment_group/project_files/lalala2.csv\",\"w\",\"utf-8\")\n",
    "for temp in strings:\n",
    "    f.writelines(temp)\n",
    "f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
